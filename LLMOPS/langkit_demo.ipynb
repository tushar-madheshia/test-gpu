{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff729ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /home/mosaic-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "/tmp/pip_packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 09:57:23,146] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from langkit import llm_metrics, extract\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "headers_openllm = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\",\"AUTHORIZATION\": \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"}\n",
    "url_openllm = 'https://refract.fosfor.com/vllm/mistral/v1/completions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891e9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrative_generation_with_openllm(intermediate_result, question):\n",
    "  \n",
    "  data_openllm = {\"prompt\": prompt,\n",
    "                  \"max_tokens\": 200,\n",
    "                  \"temperature\": 0.01,\n",
    "                  \"model\": \"/llmmodels/NLG_FINETUNEDMODELS/DATASET_MODELS/FINETUNED_MISTRALV2_V5/MISTRAL_MERGED_MODEL_JAN30_V3_0021\",\n",
    "                  \"stop\": \"[\"}\n",
    "  start = time.time()\n",
    "  response = requests.post(url_openllm, json=data_openllm, headers=headers_openllm)\n",
    "  end = time.time()\n",
    "  open_llm_narrative_json = json.loads(response.text)\n",
    "  open_llm_narrative = re.search(r'\\n([^|\\n]*)', open_llm_narrative_json[\"choices\"][0][\"text\"]).group(1)\n",
    "  open_llm_response_time = str(end - start) + str(\" seconds\")\n",
    "\n",
    "  output_dict = {\n",
    "    \"opensource_llm_narrative\":open_llm_narrative,\n",
    "    \"opensource_llm_response_time\":open_llm_response_time\n",
    "  }\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833fe539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the questionyou are ugly fellow\n",
      "Enter the intermediate_resultugly ugly ugly\n",
      "\n",
      "\n",
      "Prompt Metrices\n",
      "toxicity level of prompt: 0.9538238644599915\n",
      "Patterns in prompt: None\n",
      "Sentiment level of prompt: -0.5106\n",
      "flesch_reading_ease of prompt: 75.88\n",
      "automated_readability_index of prompt: -0.7\n",
      "aggregate_reading_level of prompt: 0.0\n",
      "syllable_count of prompt: 6\n",
      "lexicon_count of prompt: 4\n",
      "sentence_count of prompt: 1\n",
      "character_count of prompt: 16\n",
      "polysyllable_count of prompt: 0\n",
      "monosyllable_count of prompt: 2\n",
      "difficult_words of prompt: 0\n",
      "jailbreak_similarity of prompt: 0.2062259465456009\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter the question\")\n",
    "intermediate_result = input(\"Enter the intermediate_result\")\n",
    "prompt = \"\"\"Given the input :\\n\"\"\"+str(intermediate_result)+\"\"\"\\nAnd the query: \"\"\"+ str(question)+\"\"\"\\n is converted into below narrative.\\n[Narrative]\"\"\"\n",
    "#Prompt validation\n",
    "data = [[question,\"\"]]\n",
    "prompt_response = pd.DataFrame(data, columns=['prompt', 'response'])\n",
    "metrics_df = extract(prompt_response)\n",
    "\n",
    "print(\"\\n\\nPrompt Metrices\")\n",
    "\n",
    "print(\"toxicity level of prompt:\" , metrics_df['prompt.toxicity'].values[0])\n",
    "print(\"Patterns in prompt:\" , metrics_df['prompt.has_patterns'].values[0])\n",
    "print(\"Sentiment level of prompt:\" , metrics_df['prompt.sentiment_nltk'].values[0])\n",
    "print(\"flesch_reading_ease of prompt:\" , metrics_df['prompt.flesch_reading_ease'].values[0])\n",
    "print(\"automated_readability_index of prompt:\" , metrics_df['prompt.automated_readability_index'].values[0])\n",
    "print(\"aggregate_reading_level of prompt:\" , metrics_df['prompt.aggregate_reading_level'].values[0])\n",
    "print(\"syllable_count of prompt:\" , metrics_df['prompt.syllable_count'].values[0])\n",
    "print(\"lexicon_count of prompt:\" , metrics_df['prompt.lexicon_count'].values[0])\n",
    "print(\"sentence_count of prompt:\" , metrics_df['prompt.sentence_count'].values[0])\n",
    "print(\"character_count of prompt:\" , metrics_df['prompt.character_count'].values[0])\n",
    "print(\"polysyllable_count of prompt:\" , metrics_df['prompt.polysyllable_count'].values[0])\n",
    "print(\"monosyllable_count of prompt:\" , metrics_df['prompt.monosyllable_count'].values[0])\n",
    "print(\"difficult_words of prompt:\" , metrics_df['prompt.difficult_words'].values[0])\n",
    "print(\"jailbreak_similarity of prompt:\" , metrics_df['prompt.jailbreak_similarity'].values[0])\n",
    "\n",
    "output_dict = narrative_generation_with_openllm(intermediate_result,question)\n",
    "\n",
    "prompt_response = pd.DataFrame(data, columns=['prompt', 'response'])\n",
    "metrics_df = extract(prompt_response)\n",
    "\n",
    "print(\"\\n\\nResponse Metrices\")\n",
    "print(\"Time taken\" , output_dict[\"opensource_llm_response_time\"])\n",
    "print(\"toxicity level of response:\" , metrics_df['response.toxicity'].values[0])\n",
    "print(\"Patterns in response:\" , metrics_df['response.has_patterns'].values[0])\n",
    "print(\"Sentiment level of response:\" , metrics_df['response.sentiment_nltk'].values[0])\n",
    "print(\"flesch_reading_ease of response:\" , metrics_df['response.flesch_reading_ease'].values[0])\n",
    "print(\"automated_readability_index of response:\" , metrics_df['response.automated_readability_index'].values[0])\n",
    "print(\"aggregate_reading_level of response:\" , metrics_df['response.aggregate_reading_level'].values[0])\n",
    "print(\"syllable_count of response:\" , metrics_df['response.syllable_count'].values[0])\n",
    "print(\"lexicon_count of response:\" , metrics_df['response.lexicon_count'].values[0])\n",
    "print(\"sentence_count of response:\" , metrics_df['response.sentence_count'].values[0])\n",
    "print(\"character_count of response:\" , metrics_df['response.character_count'].values[0])\n",
    "print(\"polysyllable_count of response:\" , metrics_df['response.polysyllable_count'].values[0])\n",
    "print(\"monosyllable_count of response:\" , metrics_df['response.monosyllable_count'].values[0])\n",
    "print(\"difficult_words of response:\" , metrics_df['response.difficult_words'].values[0])\n",
    "print(\"refusal_similarity of response:\" , metrics_df['response.refusal_similarity'].values[0])\n",
    "print(\"relevance_to_prompt of response:\" , metrics_df['response.relevance_to_prompt'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac698d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
