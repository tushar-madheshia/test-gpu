{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ab011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /home/mosaic-\n",
      "[nltk_data]     ai/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "/tmp/pip_packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 09:36:03,378] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from langkit import llm_metrics, extract\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "headers_openllm = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\",\"AUTHORIZATION\": \"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJ4WTdTd3k5UE1xaXRDQmNSMm5qcVl6bmoxS3NqZzV3TmdOV0xDVzdyUkhvIn0.eyJleHAiOjE3MzA4ODM3MzgsImlhdCI6MTY5OTI2MTMzOCwiYXV0aF90aW1lIjoxNjk5MjUyMDQ0LCJqdGkiOiJmN2EzMzQwYy1kNDQwLTRlMzUtYjk2ZS04YzBiMTc0Y2RhODAiLCJpc3MiOiJodHRwczovL3JlZnJhY3QtbG9naW4uZm9zZm9yLmNvbS9hdXRoL3JlYWxtcy9tb3NhaWMiLCJhdWQiOlsibW9zYWljLWdhdGVrZWVwZXIiLCJhY2NvdW50Il0sInN1YiI6IjZjMjU4MWU3LWZmMTItNDljNy04MDJmLWI2ZjQzOWQxZDIwMSIsInR5cCI6IkJlYXJlciIsImF6cCI6Im1vc2FpYy1nYXRla2VlcGVyIiwic2Vzc2lvbl9zdGF0ZSI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJNTE9QUyIsImxvbmdfbGl2ZWRfdG9rZW4iLCJzcGVjdHJhLWRldmVsb3BlciIsImRlZmF1bHQtcm9sZXMtbW9zYWljIiwicmVmcmFjdC1kZXZlbG9wZXIiLCJvZmZsaW5lX2FjY2VzcyIsImFkbWluIiwidW1hX2F1dGhvcml6YXRpb24iLCJyZWZyYWN0LWFkbWluIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgZW1haWwgcHJvZmlsZSIsInNpZCI6IjBhY2Y3YWZhLTVmMzMtNGRhZS05OGM3LTQyZDQwYTdlZTM2NiIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJuYW1lIjoiUmVmcmFjdCBCRlNJIiwicHJlZmVycmVkX3VzZXJuYW1lIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20iLCJnaXZlbl9uYW1lIjoiUmVmcmFjdCIsImZhbWlseV9uYW1lIjoiQkZTSSIsImVtYWlsIjoicmVmcmFjdC5iZnNpQGZvc2Zvci5jb20ifQ.b6SYLgjo9Veo3GmJ8eZjCTNupQjpfMhzsoXdYjWwRtvRnNjBfx0gOqcugO9OcGn-mm8wwpSGI5uiL30-I6SdWBjsf1ur6GztoX7j-nP_3SrJJn3UhNNqIO8LbsPi5gGRTzWtnfjz92BF1YaCXxQwPY0P_aa8vJ6JxZz5Uctn9aIPIJZZnnjC_GPXtXurmshM_tEN2kwCjhEyr7wYzRqUoMtBGfpLjZREBzgZY-x6JyYiXNtycb1d6PFcCXf7nJVV8ienEC_x7OuciDzfeqd-SQnImvAHH7rqFdi9smBN08AbkDS2uAbMrokHrmbiBpaimrR013VwCWz2KL5QYlWleA\"}\n",
    "url_openllm = 'https://refract.fosfor.com/vllm/mistral/v1/completions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c82e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def narrative_generation_with_openllm(intermediate_result, question):\n",
    "  data_openllm = {\"prompt\": prompt,\n",
    "                  \"max_tokens\": 200,\n",
    "                  \"temperature\": 0.01,\n",
    "                  \"model\": \"/llmmodels/NLG_FINETUNEDMODELS/DATASET_MODELS/FINETUNED_MISTRALV2_V5/MISTRAL_MERGED_MODEL_JAN30_V3_0021\",\n",
    "                  \"stop\": \"[\"}\n",
    "  start = time.time()\n",
    "  response = requests.post(url_openllm, json=data_openllm, headers=headers_openllm)\n",
    "  end = time.time()\n",
    "  open_llm_narrative_json = json.loads(response.text)\n",
    "  open_llm_narrative = re.search(r'\\n([^|\\n]*)', open_llm_narrative_json[\"choices\"][0][\"text\"]).group(1)\n",
    "  open_llm_response_time = str(end - start) + str(\" seconds\")\n",
    "\n",
    "  output_dict = {\n",
    "    \"opensource_llm_narrative\":open_llm_narrative,\n",
    "    \"opensource_llm_response_time\":open_llm_response_time\n",
    "  }\n",
    "  print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd585c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = input(\"Enter the question\")\n",
    "intermediate_result = input(\"Enter the intermediate_result\")\n",
    "prompt = \"\"\"Given the input :\\n\"\"\"+str(intermediate_result)+\"\"\"\\nAnd the query: \"\"\"+ str(question)+\"\"\"\\n is converted into below narrative.\\n[Narrative]\"\"\"\n",
    "#Prompt validation\n",
    "data = [[question,\"\"]]\n",
    "prompt_response = pd.DataFrame(data, columns=['prompt', 'response'])\n",
    "metrics_df = extract(prompt_response)\n",
    "print(\"toxicity level of prompt\" , metrics_df['prompt.toxicity'].values[0])\n",
    "print(\"Patterns in prompt\" , metrics_df['prompt.has_patterns'].values[0])\n",
    "print(\"Sentiment level of prompt\" , metrics_df['prompt.sentiment_nltk'].values[0])\n",
    "print(\"flesch_reading_ease of prompt\" , metrics_df['prompt.flesch_reading_ease'].values[0])\n",
    "print(\"automated_readability_index of prompt\" , metrics_df['prompt.automated_readability_index'].values[0])\n",
    "print(\"aggregate_reading_level of prompt\" , metrics_df['prompt.aggregate_reading_level'].values[0])\n",
    "print(\"syllable_count of prompt\" , metrics_df['prompt.syllable_count'].values[0])\n",
    "print(\"lexicon_count of prompt\" , metrics_df['prompt.lexicon_count'].values[0])\n",
    "print(\"toxicity of prompt\" , metrics_df['prompt.toxicity'].values[0])\n",
    "print(\"toxicity of prompt\" , metrics_df['prompt.toxicity'].values[0])\n",
    "print(\"toxicity of prompt\" , metrics_df['prompt.toxicity'].values[0])\n",
    "print(\"toxicity of prompt\" , metrics_df['prompt.toxicity'].values[0])\n",
    "\n",
    "#narrative_generation_with_openllm(intermediate_result,question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b4cc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007538795471191406"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df['prompt.toxicity'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d7cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
