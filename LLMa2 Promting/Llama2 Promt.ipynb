{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c1ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: transformers in /opt/conda/lib/python3.8/site-packages (4.34.1)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied, skipping upgrade: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0305521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "import json\n",
    "#from Gpt4_OpenAI_Prompt import system_msg,context,postprocess\n",
    "#from prompt1 import system_msg\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f535e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "                         \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "                        {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "                        {\"ENTITY\": \"contribution_to_growth\",\n",
    "                         \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"kda_transactional\",\n",
    "                         \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "                        {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"correlation\",\n",
    "                         \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\",\n",
    "                                         \"correlated\",\n",
    "                                         \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                                         \"relationship\",\n",
    "                                         \"relationships\"]}\n",
    "                        ],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}\n",
    "\n",
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}\n",
    "\n",
    "system_msg = \"\"\"\n",
    "You are an assistant that helps map user questions to a \"CONTEXT\" for a question-answering system. The \"CONTEXT\" is provided as a JSON data lookup, containing information about \"MEASURE,\" \"DIMENSION,\" \"FILTER,\" \"DERIVED MEASURE,\" and more.\n",
    "\n",
    "### Step 1: Identify N-Grams Match\n",
    "\n",
    "Your first task is to identify and map n-grams from the user's question to the data in the \"CONTEXT\". This involves looking for matches between the user's question and the \"other names\" field for each ENTITY key in the \"CONTEXT\" data . \n",
    "You should always prioritize the longest n-gram match and avoid sub-string matches. \n",
    "If multiple matches exist for an n-gram with the \"CONTEXT,\" return all such ENTITY values in the \"CONTEXT\" data in the response.\n",
    "If you return a match that isn't exactly present in the \"other names\" field in \"CONTEXT\", ensure that it is a noun phrase and shows a high similarity to the matched \"ENTITY\".\n",
    "\n",
    "### Step 2: Applying Other Conditions\n",
    "\n",
    "After matching \"ENTITY\", apply the following conditions from the user's question:\n",
    "\n",
    "1. **METRIC CONSTRAINT:** Determine if the user has specified a comparison limit (METRIC CONSTRAINT) on the METRIC. METRIC can be a MEASURE or DERIVED MEASURE. METRIC CONSTRAINT consists of two parts: \"COMPARISON VALUE\" and \"COMPARISON OPERATOR\" (that are in symbols).\n",
    "\n",
    "2. **ADJECTIVE and TONE:** Identify any adjectives (e.g., \"least,\" \"highest performing\") applied to the matched ENTITY, along with their intent or TONE, which can be positive or negative.\n",
    "\n",
    "3. **EXCEPTION:** Look for any excluded FILTERS of a DIMENSION mentioned in the user's question. The DIMENSION should be the parent of the FILTER. Include a \"PARENT\" field for the parent DIMENSION and set \"EXCLUDE\" to \"True\" for such excluded FILTERS.\n",
    "\n",
    "4. **RANK:** Identify if the user has applied a rank to a DIMENSION, such as \"top 5\" or \"bottom 3.\" Include \"RANK ADJECTIVE\" and \"RANK VALUE\" if specified. If no explicit RANK VALUE is in the question, assume it to be 1.\n",
    "\n",
    "5. **RATIO FILTERS:** This condition applies only to the ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTERS on which the Ratio needs to be calculated. Provide the FILTERS in a structured format.\n",
    "\n",
    "6. **APPLIED MEASURES:** This condition is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. This information should be structured within the response.\n",
    "\n",
    "### Step 3: Applying time tagger rules only if time elements are present in question\n",
    "\n",
    "    1. If the user's question includes time-related elements, apply the time tagging rules to convert and calculate date ranges.\n",
    "    2. Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. \n",
    "    3. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
    "    4. TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
    " \n",
    " Calculate date range for each time points based on the following conditions:\n",
    "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the \"end_date\" in this \"date input\" data : \"\"\" '\\n' + str(\n",
    "    date_input) + '\\n' \"\"\"\n",
    "    2. To calculate the date range for \"last X years\", strictly follow the below conditions where \"X\" is variable you think of in the follwong steps:\n",
    "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
    "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
    "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
    "            Consider the reference month as the month in reference date\n",
    "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
    "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
    "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
    "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
    "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
    "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
    "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
    "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
    "    6. Provide the date range of each time point in start date - end date format always.\n",
    "\n",
    "### Step 4: Creating the Response JSON\n",
    "\n",
    "Your final task is to create a response in a JSON format. Use the following structured format to organize the information you have identified in previous steps. If JSON capabilities are limited, provide the response as atleast as text.\n",
    "\n",
    "Keys and values in the response JSON format enclosed in \"<>\" are like an instructions to you where you should be replace those with values from your findings from the above steps with instructions your finding from the above steps.\n",
    "and remenber in the response JSON no need to keep any information that is not detected as ENTITY from the user's questions.\n",
    "Only keep the reponse limited to the ENTITY Matches that you have identified from above steps in a given user's question. \n",
    "No need to return the data from \"CONTEXT\" if there are no Matches from the user's question n-grams.\n",
    "\n",
    "Here is the response JSON format:\n",
    "\n",
    "{\n",
    "\"MEASURE\": {\n",
    "\"<replace with matched n-gram in Step 1 that is matched from user's question to MEASURE, only if match is found then only replace and return these key value>\": [\n",
    "{\n",
    "\"ENTITY\": \"<replace with the Matched MEASURE from the CONTEXT data, if no match found do not return this key value pair >\",\n",
    "\"MEASURE CONSTRAINT\": [\n",
    "{\n",
    "\"COMPARISON VALUE\": \"\",\n",
    "\"COMPARISON OPERATOR\": \"\"\n",
    "}\n",
    "],\n",
    "\"ADJECTIVE\": [],\n",
    "\"TONE\": \"\"\n",
    "}\n",
    "]\n",
    "},\n",
    "\"DIMENSION\": {\n",
    "\"<replace with matched n-gram in Step 1 that is matched from user's question to  DIMENSION , only if match is found then only replace and return these key value>\": [\n",
    "{\n",
    "\"ENTITY\": \"<replace with the Matched MEASURE from the CONTEXT data, only if match is found then only replace and return these key value>\",\n",
    "\"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
    "\"ADJECTIVE\": [],\n",
    "\"TONE\": \"\"\n",
    "}\n",
    "]\n",
    "},\n",
    "\"FILTER\": {\n",
    "\"<replace with matched n-gram in Step 1 that is matched from user's question to FILTER, only if match is found then only replace and return these key value>\": [\n",
    "{\n",
    "\"ENTITY\": \"<replace with the Matched FILTER from the CONTEXT data,if no match found do not return this key value pair>\",\n",
    "\"PARENT\": \"<replace with the Matched parent of the Matched FILTER from the CONTEXT data,if no match found do not return this key value pair>\",\n",
    "\"EXCLUDE\": \"\"\n",
    "}\n",
    "]\n",
    "},\n",
    "\"DERIVED MEASURE\": {\n",
    "\"<replace with matched n-gram in Step 1 that is matched from user's question to DERIVED MEASURE, only if match is found then only replace and return these key value>\": [\n",
    "{\n",
    "\"ENTITY\": \"<replace with the Matched DERIVED MEASURE from the CONTEXT data,if no match found do not return this key value pair>\",\n",
    "\"RATIO FILTER\": [{}],\n",
    "\"APPLIED MEASURE\": [{\"<replace with matched n-gram in Step 1 that is matched from user's question to MEASURE, only if match is found then only replace and return these key value>\": \"<replace with the Matched MEASURE from the CONTEXT data, if no match found do not return this key value pair>\"}],\n",
    "\"DERIVED MEASURE CONSTRAINT\": [\n",
    "{\n",
    "\"COMPARISON VALUE\": \"\",\n",
    "\"COMPARISON OPERATOR\": \"\"\n",
    "}\n",
    "],\n",
    "\"ADJECTIVE\": [],\n",
    "\"TONE\": \"\"\n",
    "}\n",
    "]\n",
    "},\n",
    "\"DATE VARIABLE\": {\n",
    "\"asked time element\": [{\"ENTITY\": \"<replace with matched n-gram in Step 1 that is matched from user's question to DATE VARIABLE,only if match is found then only replace and return these key value>\",\n",
    "\"DATE RANGE\": \"date range\",\n",
    "\"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
    "}]\n",
    "}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdcb45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87ac33",
   "metadata": {},
   "source": [
    "### LLAMA 2 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3957d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6d6830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"NousResearch/llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,\n",
    "    device_map=device_map)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121ba1af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gereneate_output_llama2(prompt):\n",
    "    #prompt = json.dumps(prompt)\n",
    "    model_input = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #model.eval()\n",
    "    response = tokenizer.decode(model.generate(**model_input, max_length=4069*2)[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3891448",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Setting the same prompt which is used for GPT4 open AI\n",
    "################################################################################\n",
    "\n",
    "def get_user_question_for_open_ai_prompt(question):\n",
    "    return \"\"\"Now Based on this following \"CONTEXT\" data lookup:\\n\"\"\" + str(context) + \"\\n return a response for the question:\\n\" + question + \"\\n\"\n",
    "    #return \"\\n Now return a response for this question:\\n\" + question + \"\\n\"\n",
    "\n",
    "def compose_prompt_open_ai_prompt(question,base_prompt=system_msg):\n",
    "    return f\"\"\"[INST]<<SYS>>\n",
    "            {base_prompt}\n",
    "            <</SYS>>\n",
    "            {get_user_question_for_open_ai_prompt(question)}\n",
    "            [/INST]\n",
    "            [END]\"\"\"\n",
    "\n",
    "def post_process_open_ai_prompt_response(output):\n",
    "    mql = output.split(\"[END]\")[1].split(\"\\n\\nReasoning:\\n\\n\")[0]\n",
    "    reason = output.split(\"[END]\")[1].split(\"\\n\\nReasoning:\\n\\n\")[1]\n",
    "    print(\"*\"*50+\"MQL\"+\"*\"*50)\n",
    "    print(mql)\n",
    "    print(\"\\n\"+\"*\"*50+\"Reason\"+\"*\"*50)\n",
    "    print(reason)\n",
    "    #return mql,reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7a18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing prompt\n",
    "\n",
    "# question = \"what are the sales in africa\"\n",
    "# prompt = f\"\"\"[INST]<<SYS>>\n",
    "# Assume you are a system that detects the month and year in the given secentance, user will give only provide the input in english.\n",
    "# For example if user gives \"top  orders in march 2020\", you should only return march 2020.\n",
    "\n",
    "# <</SYS>>\n",
    "# {question}\n",
    "# [/INST]\n",
    "# [END]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8e1081",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2415: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In this response, we will identify the n-grams in the user's question and map them to the \"CONTEXT\" data. We will also apply the conditions from the user's question to the identified ENTITIES and provide the date range for each time element.\n",
      "\n",
      "ENTITIES:\n",
      "\n",
      "* Discount\n",
      "* Purchase Vol\n",
      "* Quantity\n",
      "* Sales\n",
      "\n",
      "DIMENSION:\n",
      "\n",
      "* Sub-Category\n",
      "* Segment\n",
      "* Parts\n",
      "* Country\n",
      "\n",
      "FILTER:\n",
      "\n",
      "* Consumer\n",
      "* Phone\n",
      "* Binder\n",
      "* Corporate\n",
      "* India\n",
      "* Dubai\n",
      "\n",
      "DERIVED MEASURE:\n",
      "\n",
      "* Ratio\n",
      "* Why\n",
      "* contribution to growth\n",
      "* kda_transactional\n",
      "* Growth Rate\n",
      "* correlation\n",
      "\n",
      "DATE VARIABLE:\n",
      "\n",
      "* Order Date\n",
      "\n",
      "Now, let's apply the conditions from the user's question to the identified ENTITIES:\n",
      "\n",
      "1. MEASURE CONSTRAINT:\n",
      "\t* Comparison value: Discount\n",
      "\t* Comparison operator: >\n",
      "2. ADJECTIVE and TONE:\n",
      "\t* Adjective: Top\n",
      "\t* Tone: Positive\n",
      "3. EXCLUDE:\n",
      "\t* Exclude: False\n",
      "4. RANK:\n",
      "\t* Rank: 5\n",
      "5. FILTER:\n",
      "\t* Filter: Segment\n",
      "\t* Parent: Segment\n",
      "6. DERIVED MEASURE CONSTRAINT:\n",
      "\t* Comparison value: Discount\n",
      "\t* Comparison operator: >\n",
      "7. DATE VARIABLE:\n",
      "\t* Asked time element: Order Date\n",
      "\t* Date range: [2020-01-01, 2023-09-15]\n",
      "\n",
      "Based on the above information, the response for the question \"top 5 segments basis discount\" is:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"Discount\": [\n",
      "{\n",
      "\"ENTITY\": \"Discount\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DIMENSION\": {\n",
      "\"Sub-Category\": [\n",
      "{\n",
      "\"ENTITY\": \"Sub-Category\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"Segment\": [\n",
      "{\n",
      "\"ENTITY\": \"Segment\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"Parts\": [\n",
      "{\n",
      "\"ENTITY\": \"Parts\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"Country\": [\n",
      "{\n",
      "\"ENTITY\": \"Country\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"FILTER\": {\n",
      "\"Consumer\": [\n",
      "{\n",
      "\"ENTITY\": \"Consumer\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"Phone\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"Binder\": [\n",
      "{\n",
      "\"ENTITY\": \"Binder\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"Corporate\": [\n",
      "{\n",
      "\"ENTITY\": \"Corporate\",\n",
      "\"RANK\": 5,\n",
      "\"ADJECTIVE\": [\"Top\"],\n",
      "\"TONE\": \"Positive\"\n",
      "}\n",
      "],\n",
      "\"India\": [\n",
      "{\n",
      "\"ENTITY\": \"India\",\n",
      "\n",
      "CPU times: user 1min 5s, sys: 1.03 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 5 segments basis discount\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=system_msg))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[END]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc56902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "To answer the user's question, \"When was quantity greater than 10k for phone?\", we need to identify the n-grams in the user's question that match with the data in the \"CONTEXT\" data lookup. Based on the provided \"CONTEXT\" data, we identify the following matches:\n",
      "\n",
      "* MEASURE: Discount\n",
      "* DIMENSION: Sub-Category\n",
      "* FILTER: Consumer\n",
      "* ENTITY: Phone\n",
      "\n",
      "From the user's question, we identify the n-gram \"quantity greater than 10k\" and match it with the \"ENTITY\" field in the \"CONTEXT\" data. The matched ENTITY is \"Phone.\"\n",
      "\n",
      "Based on the \"CONTEXT\" data, we know that the measure for \"Phone\" is \"Discount.\" Therefore, the answer to the user's question is:\n",
      "\n",
      "\"The quantity of phones was greater than 10k in [insert date range here], based on the discount measure.\"\n",
      "\n",
      "In the response, we provide the date range based on the \"last X years\" condition, where X is the number of years specified in the user's question. For example, if the user asks for \"last 3 years,\" we provide the date range from the current date three years ago to the current date.\n",
      "\n",
      "Here is the complete response in JSON format:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"Discount\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"\",\n",
      "\"COMPARISON OPERATOR\": \"\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DIMENSION\": {\n",
      "\"Sub-Category\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"RANK\": [{\"RANK ADJECTIVE\": \"\", \"RANK VALUE\": \"\"}],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"FILTER\": {\n",
      "\"Consumer\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"PARENT\": \"\",\n",
      "\"EXCLUDE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DERIVED MEASURE\": {\n",
      "\"Ratio\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"RATIO FILTER\": [{}],\n",
      "\"APPLIED MEASURE\": [{\"Discount\": [{\"ENTITY\": \"Phone\", \"MEASURE CONSTRAINT\": [{}], \"ADJECTIVE\": [], \"TONE\": \"\"}]}],\n",
      "\"DERIVED MEASURE CONSTRAINT\": [{}],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DATE VARIABLE\": {\n",
      "\"Asked Time Element\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\",\n",
      "\"DATE RANGE\": \"last 3 years\",\n",
      "\"CONVERTED TIME ELEMENT\": \"3 years ago\"\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "In this response, we have provided the matched ENTITY, MEASURE CONSTRAINT, DIMENSION, FILTER, DERIVED MEASURE, and DATE VARIABLE information based on the user's question and the \"CONTEXT\" data.\n"
     ]
    }
   ],
   "source": [
    "question = \"when was quantity greater than 10k for phone\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=system_msg))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[END]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6ef16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2415: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "As an assistant, I have identified the following n-grams from the user's question:\n",
      "\n",
      "1. Quantity\n",
      "2. Category\n",
      "3. Phone\n",
      "4. Corporate\n",
      "\n",
      "Based on the identified n-grams, I have applied the following conditions from the user's question:\n",
      "\n",
      "1. MEASURE CONSTRAINT: No matches found.\n",
      "2. DIMENSION: No matches found.\n",
      "3. FILTER: No matches found.\n",
      "4. DERIVED MEASURE: No matches found.\n",
      "5. DATE VARIABLE: No matches found.\n",
      "\n",
      "Since no matches were found, I have not provided any information in the response.\n",
      "\n",
      "The response for the question \"quantity across category except phone in corporate\" is:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"<replace with matched n-gram in Step 1 that is matched from user's question to MEASURE, if no match found do not return this key value pair>\": [\n",
      "{\n",
      "\"ENTITY\": \"<replace with the Matched MEASURE from the CONTEXT data, if no match found do not return this key value pair>\",\n",
      "\"MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"\",\n",
      "\"COMPARISON OPERATOR\": \"\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "}\n",
      "\n",
      "Please note that the response is empty as no matches were found in the user's question.\n"
     ]
    }
   ],
   "source": [
    "question = \"quantity across category except phone in corporate\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=system_msg))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[END]\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2754cb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "As an assistant, I will identify and map n-grams from the user's question to the data in the \"CONTEXT.\" I will prioritize the longest n-gram match and avoid sub-string matches. If multiple matches exist for an n-gram with the \"CONTEXT,\" I will return all such ENTITY values in the \"CONTEXT\" data in the response.\n",
      "\n",
      "For the question \"segment with lesser phone,\" I will identify the following n-grams and their corresponding ENTITY values from the \"CONTEXT\" data:\n",
      "\n",
      "* \"segment\" - \"Sub-Category\"\n",
      "* \"phone\" - \"Parts\"\n",
      "* \"lesser\" - \"Ratio\"\n",
      "\n",
      "Based on the identified n-grams, I will provide the following response:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"Discount\": [\n",
      "{\n",
      "\"ENTITY\": \"Discount\",\n",
      "\"MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"\",\n",
      "\"COMPARISON OPERATOR\": \"\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DIMENSION\": {\n",
      "\"Sub-Category\": [\n",
      "{\n",
      "\"ENTITY\": \"Sub-Category\",\n",
      "\"RANK\": [{\"RANK ADJECTIVE\": \"\", \"RANK VALUE\": \"\"}],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"FILTER\": {\n",
      "\"Consumer\": [\n",
      "{\n",
      "\"ENTITY\": \"Consumer\",\n",
      "\"PARENT\": \"Segment\",\n",
      "\"EXCLUDE\": \"\"\n",
      "}\n",
      "],\n",
      "\"Phone\": [\n",
      "{\n",
      "\"ENTITY\": \"Parts\",\n",
      "\"PARENT\": \"Sub-Category\",\n",
      "\"EXCLUDE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DERIVED MEASURE\": {\n",
      "\"Ratio\": [\n",
      "{\n",
      "\"ENTITY\": \"Ratio\",\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DATE VARIABLE\": {\n",
      "\"Asked Time Element\": [\n",
      "{\n",
      "\"ENTITY\": \"Date\",\n",
      "\"DATE RANGE\": \"date range\",\n",
      "\"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "In this response, I have identified the n-grams from the user's question and matched them to the corresponding ENTITY values in the \"CONTEXT\" data. I have also provided the measure constraint, rank, and date range for each ENTITY value.\n",
      "\n",
      "Note that if no match is found for a given n-gram, I will not include it in the response. Also, if the \"CONTEXT\" data does not contain the requested ENTITY value, I will not include it in the response.\n"
     ]
    }
   ],
   "source": [
    "question = \"segment with lesser phone\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=system_msg))\n",
    "#post_process_open_ai_prompt_response(output)\n",
    "print(output.split(\"[END]\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d09584",
   "metadata": {},
   "source": [
    "### Mistral 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84de6680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.34.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46329b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb8c5961f5d433ea3b0ba3ce9f7678b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_mistral = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,\n",
    "    device_map=device_map)\n",
    "tokenizer_mistral = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1218eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-v0.1\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ae6f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system_msg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msystem_msg\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'system_msg' is not defined"
     ]
    }
   ],
   "source": [
    "print(system_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd0aeaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compose_prompt_open_ai_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop 5 segments basis discount\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m query({\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcompose_prompt_open_ai_prompt\u001b[49m(question,base_prompt\u001b[38;5;241m=\u001b[39msystem_msg),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m4096\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m0.8\u001b[39m}\n\u001b[1;32m      6\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compose_prompt_open_ai_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"top 5 segments basis discount\"\n",
    "\n",
    "output = query({\n",
    "    \"inputs\": compose_prompt_open_ai_prompt(question,base_prompt=system_msg),\n",
    "    \"params\": {\"max_tokens\":4096*2,\"temperature\":0.8}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73b64684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "            \n",
      "You are an assistant that helps map user questions to a \"CONTEXT\" for a question-answering system. The \"CONTEXT\" is provided as a JSON data lookup, containing information about \"MEASURE,\" \"DIMENSION,\" \"FILTER,\" \"DERIVED MEASURE,\" and more.\n",
      "\n",
      "### Step 1: Identify N-Grams Match\n",
      "\n",
      "Your first task is to identify and map n-grams from the user's question to the data in the \"CONTEXT\". This involves looking for matches between the user's question and the \"other names\" field for each ENTITY key in the \"CONTEXT\" data . \n",
      "You should always prioritize the longest n-gram match and avoid sub-string matches. \n",
      "If multiple matches exist for an n-gram with the \"CONTEXT,\" return all such ENTITY values in the \"CONTEXT\" data in the response.\n",
      "If you return a match that isn't exactly present in the \"other names\" field in \"CONTEXT\", ensure that it is a noun phrase and shows a high similarity to the matched \"ENTITY\".\n",
      "\n",
      "### Step 2: Applying Other Conditions\n",
      "\n",
      "After matching \"ENTITY\", apply the following conditions from the user's question:\n",
      "\n",
      "1. **METRIC CONSTRAINT:** Determine if the user has specified a comparison limit (METRIC CONSTRAINT) on the METRIC. METRIC can be a MEASURE or DERIVED MEASURE. METRIC CONSTRAINT consists of two parts: \"COMPARISON VALUE\" and \"COMPARISON OPERATOR\" (that are in symbols).\n",
      "\n",
      "2. **ADJECTIVE and TONE:** Identify any adjectives (e.g., \"least,\" \"highest performing\") applied to the matched ENTITY, along with their intent or TONE, which can be positive or negative.\n",
      "\n",
      "3. **EXCEPTION:** Look for any excluded FILTERS of a DIMENSION mentioned in the user's question. The DIMENSION should be the parent of the FILTER. Include a \"PARENT\" field for the parent DIMENSION and set \"EXCLUDE\" to \"True\" for such excluded FILTERS.\n",
      "\n",
      "4. **RANK:** Identify if the user has applied a rank to a DIMENSION, such as \"top 5\" or \"bottom 3.\" Include \"RANK ADJECTIVE\" and \"RANK VALUE\" if specified. If no explicit RANK VALUE is in the question, assume it to be 1.\n",
      "\n",
      "5. **RATIO FILTERS:** This condition applies only to the ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTERS on which the Ratio needs to be calculated. Provide the FILTERS in a structured format.\n",
      "\n",
      "6. **APPLIED MEASURES:** This condition is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. This information should be structured within the response.\n",
      "\n",
      "### Step 3: Applying time tagger rules only if time elements are present in question\n",
      "\n",
      "    1. If the user's question includes time-related elements, apply the time tagging rules to convert and calculate date ranges.\n",
      "    2. Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. \n",
      "    3. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
      "    4. TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
      " \n",
      " Calculate date range for each time points based on the following conditions:\n",
      "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the \"end_date\" in this \"date input\" data : \n",
      "{'start_date': '01/01/2020', 'end_date': '15/09/2023'}\n",
      "\n",
      "    2. To calculate the date range for \"last X years\", strictly follow the below conditions where \"X\" is variable you think of in the follwong steps:\n",
      "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
      "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
      "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
      "            Consider the reference month as the month in reference date\n",
      "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
      "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
      "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
      "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
      "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
      "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
      "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
      "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
      "    6. Provide the date range of each time point in start date - end date format always.\n",
      "\n",
      "### Step 4: Creating the Response JSON\n",
      "\n",
      "Your final task is to create a response in a JSON format. Use the following structured format to organize the information you have identified in previous steps. If JSON capabilities are limited, provide the response as atleast as text.\n",
      "\n",
      "Keys and values in the response JSON format enclosed in \"<>\" are like an instructions to you where you should be replace those with values from your findings from the above steps with instructions your finding from the above steps.\n",
      "and remenber in the response JSON no need to keep any information that is not detected as ENTITY from the user's questions.\n",
      "Only keep the reponse limited to the ENTITY Matches that you have identified from above steps in a given user's question. \n",
      "No need to return the data from \"CONTEXT\" if there are no Matches from the user's question n-grams.\n",
      "\n",
      "Here is the response JSON format:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"<replace with matched n-gram in Step 1 that is matched from user's question to MEASURE, only if match is found then only replace and return these key value>\": [\n",
      "{\n",
      "\"ENTITY\": \"<replace with the Matched MEASURE from the CONTEXT data, if no match found do not return this key value pair >\",\n",
      "\"MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"\",\n",
      "\"COMPARISON OPERATOR\": \"\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DIMENSION\": {\n",
      "\"<replace with matched n-gram in Step 1 that is matched from user's question to  DIMENSION , only if match is found then only replace and return these key value>\": [\n",
      "{\n",
      "\"ENTITY\": \"<replace with the Matched MEASURE from the CONTEXT data, only if match is found then only replace and return these key value>\",\n",
      "\"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"FILTER\": {\n",
      "\"<replace with matched n-gram in Step 1 that is matched from user's question to FILTER, only if match is found then only replace and return these key value>\": [\n",
      "{\n",
      "\"ENTITY\": \"<replace with the Matched FILTER from the CONTEXT data,if no match found do not return this key value pair>\",\n",
      "\"PARENT\": \"<replace with the Matched parent of the Matched FILTER from the CONTEXT data,if no match found do not return this key value pair>\",\n",
      "\"EXCLUDE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DERIVED MEASURE\": {\n",
      "\"<replace with matched n-gram in Step 1 that is matched from user's question to DERIVED MEASURE, only if match is found then only replace and return these key value>\": [\n",
      "{\n",
      "\"ENTITY\": \"<replace with the Matched DERIVED MEASURE from the CONTEXT data,if no match found do not return this key value pair>\",\n",
      "\"RATIO FILTER\": [{}],\n",
      "\"APPLIED MEASURE\": [{\"<replace with matched n-gram in Step 1 that is matched from user's question to MEASURE, only if match is found then only replace and return these key value>\": \"<replace with the Matched MEASURE from the CONTEXT data, if no match found do not return this key value pair>\"}],\n",
      "\"DERIVED MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"\",\n",
      "\"COMPARISON OPERATOR\": \"\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DATE VARIABLE\": {\n",
      "\"asked time element\": [{\"ENTITY\": \"<replace with matched n-gram in Step 1 that is matched from user's question to DATE VARIABLE,only if match is found then only replace and return these key value>\",\n",
      "\"DATE RANGE\": \"date range\",\n",
      "\"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "}]\n",
      "}\n",
      "}\n",
      "\n",
      "            <</SYS>>\n",
      "            Now Based on this following \"CONTEXT\" data lookup:\n",
      "{'MEASURE': [{'ENTITY': 'Discount', 'other names': ['discount', 'discount rate', 'discount value', 'deduction']}, {'ENTITY': 'Purchase Vol', 'other names': ['purchase', 'purchase value', 'purchase model']}, {'ENTITY': 'Quantity', 'other names': ['quantity', 'volume']}, {'ENTITY': 'Sales', 'other names': ['sales', 'sale']}], 'DIMENSION': [{'ENTITY': 'Sub-Category', 'other names': ['sub-category', 'sub category', 'categories', 'section']}, {'ENTITY': 'Segment', 'other names': ['segment', 'segments', 'units', 'divisions']}, {'ENTITY': 'Parts', 'other names': ['parts', 'part', 'section', 'divisions']}, {'ENTITY': 'Country', 'other names': ['country', 'countries']}], 'FILTER': [{'ENTITY': 'Consumer', 'other names': ['consumers', 'consumer'], 'parent': 'Segment'}, {'ENTITY': 'Phone', 'other names': ['phone', 'phones', 'mobile phones'], 'parent': 'Sub-Category'}, {'ENTITY': 'Binder', 'other names': ['binders', 'binder'], 'parent': 'Sub-Category'}, {'ENTITY': 'Corporate', 'other names': ['corporates', 'corporate'], 'parent': 'Segment'}, {'ENTITY': 'India', 'other names': ['india'], 'parent': 'Country'}, {'ENTITY': 'Dubai', 'other names': ['dubai'], 'parent': 'Country'}], 'DERIVED MEASURE': [{'ENTITY': 'Ratio', 'other names': ['ratio', 'share', 'contribution', 'percentage', 'proportion', 'contributing']}, {'ENTITY': 'Why', 'other names': ['why', 'cause of', 'reason for', 'diagnose']}, {'ENTITY': 'contribution_to_growth', 'other names': ['contribution to growth', 'growth', 'grown']}, {'ENTITY': 'kda_transactional', 'other names': ['kda', 'key drivers', 'key driver', 'drivers', 'driver']}, {'ENTITY': 'Growth Rate', 'other names': ['growth rate', 'growth', 'grown']}, {'ENTITY': 'correlation', 'other names': ['associate', 'associated', 'association', 'associations', 'correlate', 'correlated', 'correlation', 'correlations', 'relate', 'related', 'relation', 'relations', 'relationship', 'relationships']}], 'DATE VARIABLE': [{'ENTITY': 'Order Date', 'other names': ['order date', 'date', 'trend', 'time', 'when', 'mom', 'yoy']}]}\n",
      " return a response for the question:\n",
      "top 5 segments basis discount\n",
      "\n",
      "            [/INST]\n",
      "            [END]\n"
     ]
    }
   ],
   "source": [
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f85e7b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "The response for the question \"top 5 segments basis discount\" is as follows:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"n-gram matched to MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched MEASURE\",\n",
      "\"MEASURE CONSTRAINT\": [\n",
      "{\n",
      "\"COMPARISON VALUE\": \"top 5\",\n",
      "\"COMPARISION OPERATOR\": \"=\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "],\n",
      "\"DIMENSION\": {\n",
      "\"n-gram matched to DIMENSION\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched DIMENSION\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"5\"\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "],\n",
      "\"FILTER\": {\n",
      "\"n-gram matched to FILTER\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched FILTER\",\n",
      "\"PARENT\": \"Segment\",\n",
      "\"EXCLUDE\": \"\"\n",
      "}\n",
      "],\n",
      "\"DERIVED MEASURE\": {\n",
      "\"n-gram matched to DERIVED MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "\"RATIO FILTER\": [\n",
      "{}\n",
      "],\n",
      "\"APPLIED MEASURE\": [\n",
      "{\n",
      "\"n-gram matched to MEASURE\": [\n",
      "{\n",
      "\"ENTITY\": \"Discount\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"5\"\n",
      "}\n",
      "]\n",
      "}\n",
      "],\n",
      "\"ADJECTIVE\": [],\n",
      "\"TONE\": \"\"\n",
      "}\n",
      "],\n",
      "\"DATE VARIABLE\": {\n",
      "\"asked time element\": [\n",
      "{\n",
      "\"ENTITY\": \"Matched DATE VARIABLE\",\n",
      "\"DATE RANGE\": \"last 3 months\",\n",
      "\"CONVERTED TIME ELEMENT\": \"01/01/2020 - 15/09/2023\"\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "Based on the context provided, the top 5 segments for discount are:\n",
      "\n",
      "1. Segment - Consumer: This is the most likely segment for discount, as consumers are the primary users of discounts.\n",
      "2. Segment - Phone: This segment is likely to have a high discount rate, as phones are a common product with frequent discounts.\n",
      "3. Segment - Binder: Binder is a sub-category of Sub-Category, and it is likely to have a high discount rate, as binders are often used for various purposes.\n",
      "4. Segment - Parts: Parts is a sub-category of Sub-Category, and it is likely to have a high discount rate, as parts are frequently discounted.\n",
      "5. Segment - Country - India: India is a country with a high discount rate, as there are frequent discounts offered by retailers and manufacturers.\n",
      "\n",
      "The response is based on the n-gram matching and context analysis, which identified the most likely segments for discount. The response also includes the date range for the discount, which is last 3 months from the end date of the context.\n",
      "CPU times: user 50.5 s, sys: 828 ms, total: 51.4 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 5 segments basis discount\"\n",
    "output=gereneate_output_llama2(compose_prompt_open_ai_prompt(question))\n",
    "post_process_open_ai_prompt_response(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8324dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "newprompt1 = \"\"\"You are an assistant for a question answering system that analyzes user questions. Your task is to identify and extract various entities from the user's input and provide a structured response.\n",
    "\n",
    "**Step 1: Entity Identification**\n",
    "Your first task is to identify entities in the user's question. These entities include dimensions (e.g., \"segments,\" \"products\"), measures (e.g., \"sales,\" \"discount\"), adjectives (e.g., \"top,\" \"bottom\"), ranks (e.g., \"top 5,\" \"bottom 3\"), and other relevant elements.\n",
    "\n",
    "**Step 2: Entity Relationships**\n",
    "Once you identify these entities, determine any relationships between them. For instance, if the user asks for the \"top 5 segments by sales,\" you should recognize \"top\" as the adjective, \"5\" as the rank value, \"segments\" as the dimension, and \"sales\" as the measure. Ensure that the relationships between these entities are correctly understood.\n",
    "\n",
    "**Step 3: Generate a Structured Response**\n",
    "Based on the entities identified and their relationships, construct a structured response. If adjectives, ranks, or other modifiers are present, include them in the response. The response should be structured into categories for dimensions, measures, and any other relevant details.\n",
    "\n",
    "**Example:**\n",
    "- User Input: \"Show me the top 5 segments by sales.\"\n",
    "- Expected Response: \n",
    "  {\n",
    "      \"DIMENSION\": {\n",
    "          \"segments\": [\n",
    "              {\n",
    "                  \"ENTITY\": \"Segment\",\n",
    "                  \"RANK\": {\n",
    "                      \"RANK ADJECTIVE\": \"top\",\n",
    "                      \"RANK VALUE\": \"5\"\n",
    "                  }\n",
    "              }\n",
    "          ]\n",
    "      },\n",
    "      \"MEASURE\": {\n",
    "          \"sales\": [\n",
    "              {\n",
    "                  \"ENTITY\": \"Sales\"\n",
    "              }\n",
    "          ]\n",
    "      }\n",
    "  }\n",
    "\n",
    "**Remember:**\n",
    "- Be attentive to modifiers, ranks, and relationships between entities.\n",
    "- Ensure the response is structured and contains relevant information based on the user's input.\n",
    "- And your response should be in strictly in a Json format (which I have mentioned in the example)\n",
    "\n",
    "Provide your response.\n",
    "Also provide the reasoning\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63afd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newprompt2 = \"\"\"You are an assistant that helps to map the user question to the context for a question answering system. You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
    "\n",
    "Step 1: Identify the n-grams match between the question and context\n",
    "Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context. Always consider the longest n-gram match, not the sub-string. If there are multiple matches for an n-gram with context, return all such ENTITY in response. If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\".\n",
    "\n",
    "Step 2: Applying other conditions\n",
    "Once the match is identified, the next step is to identify other conditions from the user question and apply them to the identified matches. Refer to the following statements to understand different types of conditions to be applied:\n",
    "\n",
    "1. METRIC CONSTRAINT: METRIC can be MEASURE or DERIVED MEASURE. The user is asking for a comparison limit to be applied to the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied to a METRIC, and \"COMPARISON OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
    "\n",
    "2. ADJECTIVE and TONE: Identify the adjectives (like least, highest performing, etc.) applied to the matched ENTITY. TONE is the intent of the adjective and can be positive or negative.\n",
    "\n",
    "3. EXCEPTION: Excluded FILTER of a DIMENSION asked in the question, if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
    "\n",
    "4. RANK: Rank applied to a DIMENSION, if any, like top 5, bottom 3, etc. It has two parts: \"RANK ADJECTIVE,\" the adjective like top, bottom, etc., and \"RANK VALUE,\" a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in the question, make it 1. Based on the meaning of the RANK ADJECTIVE, make it either \"top\" or \"bottom.\"\n",
    "\n",
    "5. RATIO FILTERS: This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated.\n",
    "\n",
    "6. APPLIED MEASURES: This is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated.\n",
    "\n",
    "Step 3: Applying time tagger rules (ONLY IF time elements are present in the question)\n",
    "Identify the TIME ELEMENTS in the input question and convert them to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it. TIME ELEMENT can be either a temporal interval (across months, YoY, MoM, QoQ, WoW, quarterly, etc.) or a temporal expression (time points such as specific dates, relative expressions, etc.). Calculate date ranges for each time point based on specific conditions.\n",
    "\n",
    "Step 4: Creating the response JSON\n",
    "Strictly return the response in the exact same JSON format as follows, filling in the information identified from the previous steps. The keys mentioned in upper case in the response are constant.\n",
    "\n",
    "Example 1 - User input: \"show me the 2 top segments basis sales\"\n",
    "- Your response should be:\n",
    "{\n",
    "    \"DIMENSION\": {\n",
    "        \"segments\": [\n",
    "            {\n",
    "                \"ENTITY\": \"Segment\",\n",
    "                \"RANK\": [\n",
    "                    {\n",
    "                        \"RANK ADJECTIVE\": \"top\",\n",
    "                        \"RANK VALUE\": \"2\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"MEASURE\": {\n",
    "        \"sales\": [\n",
    "            {\n",
    "                \"ENTITY\": \"Sales\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "Provide reasoning for the response.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ae6a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "**Step 1: Entity Identification**\n",
      "\n",
      "* \"top\" - adjective\n",
      "* \"5\" - rank value\n",
      "* \"segments\" - dimension\n",
      "* \"discount\" - measure\n",
      "\n",
      "**Step 2: Entity Relationships**\n",
      "\n",
      "* \"top\" and \"5\" are related as the adjective and rank value, respectively.\n",
      "* \"segments\" and \"discount\" are related as the dimension and measure, respectively.\n",
      "\n",
      "**Step 3: Generate a Structured Response**\n",
      "\n",
      "{\n",
      "    \"DIMENSION\": {\n",
      "        \"segments\": [\n",
      "            {\n",
      "                \"ENTITY\": \"Segment\",\n",
      "                \"RANK\": {\n",
      "                    \"RANK ADJECTIVE\": \"top\",\n",
      "                    \"RANK VALUE\": \"5\"\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"MEASURE\": {\n",
      "        \"discount\": [\n",
      "            {\n",
      "                \"ENTITY\": \"Discount\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "* The user has asked for the top 5 segments based on discount.\n",
      "* The adjective \"top\" modifies the rank value \"5\", indicating that the top 5 segments should be ranked based on the discount.\n",
      "* The dimension \"segments\" is related to the measure \"discount\" as the user has asked for the top segments based on discount.\n",
      "* The response is structured to include the relevant information based on the user's input.\n",
      "CPU times: user 15.4 s, sys: 187 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 5 segments basis discount\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=newprompt1))\n",
    "try:\n",
    "    post_process_open_ai_prompt_response(output)\n",
    "except Exception as e:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a15645a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "For the question \"top 5 segments basis discount,\" the assistant would follow the same steps as before to identify the relevant entities, measures, and conditions. Here's the response in JSON format:\n",
      "\n",
      "{\n",
      "    \"DIMENSION\": {\n",
      "        \"segments\": [\n",
      "            {\n",
      "                \"ENTITY\": \"Segment\",\n",
      "                \"RANK\": [\n",
      "                    {\n",
      "                        \"RANK ADJECTIVE\": \"top\",\n",
      "                        \"RANK VALUE\": \"5\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"MEASURE\": {\n",
      "        \"discount\": [\n",
      "            {\n",
      "                \"ENTITY\": \"Discount\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "* Identified n-gram match: \"top 5 segments\"\n",
      "* Applied conditions:\n",
      "\t+ METRIC CONSTRAINT: The comparison value is \"top\" and the operator is \" \".\n",
      "\t+ ADJECTIVE: \"discount\"\n",
      "\t+ EXCEPTION: No excluded filters.\n",
      "\t+ RANK: \"top 5\"\n",
      "\t+ RATIO FILTERS: No filters to calculate the ratio.\n",
      "\t+ APPLIED MEASURES: No measures to apply.\n",
      "* Converted time elements: None (as there are no time elements in the question).\n",
      "\n",
      "In this response, the assistant has identified the relevant entities and measures based on the user's question, and applied the appropriate conditions to rank the segments. The response is structured in the same JSON format as before, with the relevant entities and measures identified and the conditions applied.\n",
      "CPU times: user 18.2 s, sys: 299 ms, total: 18.5 s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 5 segments basis discount\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=newprompt2))\n",
    "try:\n",
    "    post_process_open_ai_prompt_response(output)\n",
    "except Exception as e:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d638bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "            You are an assistant that helps to map the user question to the context for a question answering system.\n",
      " You might also need to act as a time tagger expert to convert the date elements present in the question to a standard \n",
      " format and to find possible date ranges for the same.\n",
      "Step 1: Identify the n-grams match between question and context\n",
      "Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
      "Always consider the longest n-gram match, not the sub-string.\n",
      "If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
      "If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
      "Step 2: Applying other conditions\n",
      "Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
      "Refer to the following statements to understand about different types of conditions to be applied:\n",
      "    1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
      "    2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
      "    3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
      "    4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
      "    5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
      "    6. APPLIED MEASURES: This is applicable only for DERVIED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
      "    \n",
      "    Step 3: Applying time tagger rules only if time elements are present in question\n",
      "    \n",
      "    Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
      "    TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
      "    Calculate date range for each time points based on the following conditions:\n",
      "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \n",
      "{'start_date': '01/01/2020', 'end_date': '15/09/2023'}\n",
      "\n",
      "    2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
      "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
      "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
      "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
      "            Consider the reference month as the month in reference date\n",
      "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
      "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
      "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
      "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
      "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
      "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
      "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
      "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
      "    6. Provide the date range of each time point in start date - end date format always.\n",
      "    \n",
      "    Step 4: Creating the response JSON\n",
      "    Strictly return the response in the exact same JSON format as follows. \n",
      "    Fill the information identified from above steps in the JSON. \n",
      "    The keys mentioned in upper case in the response are constant.\n",
      "    Return only if match is found from the context and non empty values are present\n",
      "    and remember \"n-gram matched to MEASURE\", \"n-gram matched to MEASURE\",\"n-gram matched to DIMENSION\",\n",
      "    \"n-gram matched to FILTER\" and \"n-gram matched to DERIVED MEASURE\"\n",
      "    in the following json structure should be the place holders, these keys you should be replacing with \n",
      "    if you have any the n-grams matched with the MEASURE, FILTER,  DERIVED MEASURE , DIMENSION entities in the step 2\n",
      "    {\n",
      "        \"MEASURE\": {\n",
      "            \"n-gram matched to MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched MEASURE\",\n",
      "                    \"MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DIMENSION\": {\n",
      "            \"n-gram matched to DIMENSION\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DIMENSION\",\n",
      "                    \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"FILTER\": {\n",
      "            \"n-gram matched to FILTER\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched FILTER\",\n",
      "                    \"PARENT\": \"parent of the Matched FILTER\",\n",
      "                    \"EXCLUDE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DERIVED MEASURE\": {\n",
      "            \"n-gram matched to DERIVED MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "                    \"RATIO FILTER\": [{}],\n",
      "                    \"APPLIED MEASURE\": [{\"n-gram matched to MEASURE\": Matched MEASURE}],\n",
      "                    \"DERIVED MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DATE VARIABLE\": {\n",
      "            \"asked time element\": [{\"ENTITY\": \"Matched DATE VARIABLE\"\n",
      "                \"DATE RANGE\": \"date range\",\n",
      "                \"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "                }]\n",
      "        }\n",
      "    }\n",
      "    and provide reasoning.\n",
      "    \n",
      "     \n",
      "    Example 1 - user input :  \"show me the 2 top segments basis sales\"\n",
      "               - your response should be : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "with provided reasoning by you.\n",
      "\n",
      "  Example 2 - user input : \"top 2 and bottom 3 segments by sales\"\n",
      "  your response should be in this case : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"bottom\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"3\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "and respective reasoning   \n",
      "    \n",
      "            <</SYS>>\n",
      "            \n",
      " Now return a response for this question:\n",
      "top 2 segments and bottom 3 sub-category basis quantity\n",
      "\n",
      "            [/INST]\n",
      "            [END]\n",
      "\n",
      "The assistant understands the question and identifies the n-grams matches in the context. Based on the identified matches, the assistant applies the conditions specified in the question to find the relevant information.\n",
      "\n",
      "For the question \"top 2 segments and bottom 3 sub-category basis quantity,\" the assistant identifies the following n-gram matches in the context:\n",
      "\n",
      "* \"top\" matches with the DIMENSION \"RANK\" ADJECTIVE \"top\" and RANK VALUE \"2\"\n",
      "* \"bottom\" matches with the DIMENSION \"RANK\" ADJECTIVE \"bottom\" and RANK VALUE \"3\"\n",
      "\n",
      "Based on the identified matches, the assistant applies the conditions specified in the question:\n",
      "\n",
      "* For the top 2 segments, the assistant finds the ENTITY \"Segment\" with a RANK of 2.\n",
      "* For the bottom 3 sub-categories, the assistant finds the ENTITY \"Sub-category\" with a RANK of 3.\n",
      "\n",
      "The assistant then provides the response in the expected format:\n",
      "\n",
      "{\n",
      "\"DIMENSION\": {\n",
      "\"segments\": [\n",
      "{\n",
      "\"ENTITY\": \"Segment\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"2\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Sub-category\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"bottom\",\n",
      "\"RANK VALUE\": \"3\"\n",
      "}\n",
      "]\n",
      "}\n",
      "],\n",
      "\"MEASURE\": {\n",
      "\"quantity\": [\n",
      "{\n",
      "\"ENTITY\": \"Quantity\",\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "Reasoning:\n",
      "The assistant uses the identified n-gram matches to find the relevant information in the context. The assistant applies the conditions specified in the question to find the top 2 segments and bottom 3 sub-categories based on the quantity. The assistant provides the response in the expected format with the identified entities and their ranks.\n",
      "CPU times: user 29 s, sys: 704 ms, total: 29.7 s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"top 2 segments and bottom 3 sub-category basis quantity\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=newprompt))\n",
    "try:\n",
    "    post_process_open_ai_prompt_response(output)\n",
    "except Exception as e:\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fc67192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[INST]<<SYS>>\\n            You are an assistant that helps to map the user question to the context for a question answering system. You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\\n\\nStep 1: Identify the n-grams match between the question and context\\nMap the n-gram or their lemma or their inflections from the question with the \\'other names\\' in the passed context. Always consider the longest n-gram match, not the sub-string. If there are multiple matches for an n-gram with context, return all such ENTITY in response. If you are returning any match which is not exactly present with the \\'other names\\', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\".\\n\\nStep 2: Applying other conditions\\nOnce the match is identified, the next step is to identify other conditions from the user question and apply them to the identified matches. Refer to the following statements to understand different types of conditions to be applied:\\n\\n1. METRIC CONSTRAINT: METRIC can be MEASURE or DERIVED MEASURE. The user is asking for a comparison limit to be applied to the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied to a METRIC, and \"COMPARISON OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\\n\\n2. ADJECTIVE and TONE: Identify the adjectives (like least, highest performing, etc.) applied to the matched ENTITY. TONE is the intent of the adjective and can be positive or negative.\\n\\n3. EXCEPTION: Excluded FILTER of a DIMENSION asked in the question, if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\\n\\n4. RANK: Rank applied to a DIMENSION, if any, like top 5, bottom 3, etc. It has two parts: \"RANK ADJECTIVE,\" the adjective like top, bottom, etc., and \"RANK VALUE,\" a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in the question, make it 1. Based on the meaning of the RANK ADJECTIVE, make it either \"top\" or \"bottom.\"\\n\\n5. RATIO FILTERS: This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated.\\n\\n6. APPLIED MEASURES: This is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated.\\n\\nStep 3: Applying time tagger rules (ONLY IF time elements are present in the question)\\nIdentify the TIME ELEMENTS in the input question and convert them to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it. TIME ELEMENT can be either a temporal interval (across months, YoY, MoM, QoQ, WoW, quarterly, etc.) or a temporal expression (time points such as specific dates, relative expressions, etc.). Calculate date ranges for each time point based on specific conditions.\\n\\nStep 4: Creating the response JSON\\nStrictly return the response in the exact same JSON format as follows, filling in the information identified from the previous steps. The keys mentioned in upper case in the response are constant.\\n\\nExample 1 - User input: \"show me the 2 top segments basis sales\"\\n- Your response should be:\\n{\\n    \"DIMENSION\": {\\n        \"segments\": [\\n            {\\n                \"ENTITY\": \"Segment\",\\n                \"RANK\": [\\n                    {\\n                        \"RANK ADJECTIVE\": \"top\",\\n                        \"RANK VALUE\": \"2\"\\n                    }\\n                ]\\n            }\\n        ]\\n    },\\n    \"MEASURE\": {\\n        \"sales\": [\\n            {\\n                \"ENTITY\": \"Sales\"\\n            }\\n        ]\\n    }\\n}\\n\\nProvide reasoning for the response.\\n\\n            <</SYS>>\\n            \\n Now return a response for this question:\\nshow me the 2 top segments basis sales\\n\\n            [/INST]\\n            ', '\\n\\nThe user question is \"show me the 2 top segments basis sales.\" To answer this question, we need to identify the n-grams match between the question and the context, apply other conditions, and then create a response in JSON format.\\n\\nStep 1: Identify n-grams match\\nThe longest n-gram match between the question and the context is \"segments basis sales.\" We have identified the following n-grams match:\\n\\n* \"segments\" - matches with \"ENTITY\" in the context\\n* \"basis\" - matches with \"MEASURE\" in the context\\n* \"sales\" - matches with \"ENTITY\" in the context\\n\\nStep 2: Apply other conditions\\nBased on the identified n-grams match, we need to apply the following conditions:\\n\\n1. METRIC CONSTRAINT: The user is asking for a comparison limit to be applied to the METRIC. The comparison value is \"2,\" and the comparison operator is \"top.\"\\n2. ADJECTIVE and TONE: The adjective \"top\" has a positive tone.\\n3. EXCEPTION: There is no excluded filter in the question.\\n4. RANK: The rank is applied to the \"sales\" ENTITY, and the rank value is \"2.\"\\n5. RATIO FILTERS: There is no ratio filter in the question.\\n6. APPLIED MEASURES: The applied measure is \"sales\" for the derived measure.\\n\\nStep 3: Apply time tagger rules (ONLY IF time elements are present in the question)\\nThe question does not contain any time elements, so we do not need to apply any time tagger rules.\\n\\nStep 4: Creating the response JSON\\nBased on the identified n-grams match, application of other conditions, and absence of time elements, the response in JSON format is:\\n\\n{\\n    \"DIMENSION\": {\\n        \"segments\": [\\n            {\\n                \"ENTITY\": \"Segment\",\\n                \"RANK\": [\\n                    {\\n                        \"RANK ADJECTIVE\": \"top\",\\n                        \"RANK VALUE\": \"2\"\\n                    }\\n                ]\\n            }\\n        ]\\n    },\\n    \"MEASURE\": {\\n        \"sales\": [\\n            {\\n                \"ENTITY\": \"Sales\"\\n            }\\n        ]\\n    }\\n}\\n\\nReasoning for the response:\\nThe response is created based on the identified n-grams match between the question and the context. The conditions applied include the METRIC CONSTRAINT, ADJECTIVE and TONE, EXCEPTION, RANK, RATIO FILTERS, and APPLIED MEASURES. The response includes the identified ENTITY and RANK values, as well as the applied MEASURE. The absence of time elements in the question means that we do not need to apply any time tagger rules.']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mpost_process_open_ai_prompt_response\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     17\u001b[0m mql \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[END]\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReasoning:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m reason \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[END]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mReasoning:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMQL\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "question = \"show me the 2 top segments basis sales\"\n",
    "output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=newprompt2))\n",
    "try:\n",
    "    post_process_open_ai_prompt_response(output)\n",
    "except Exception as e:\n",
    "    print(output.split(\"[END]\"))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5978f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "questions = pd.read_csv(\"samplequestions.csv\")\n",
    "questions = list(questions[\"Question\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83aed4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "            You are an assistant that helps to map the user question to the context for a question answering system.\n",
      " You might also need to act as a time tagger expert to convert the date elements present in the question to a standard \n",
      " format and to find possible date ranges for the same.\n",
      "Step 1: Identify the n-grams match between question and context\n",
      "Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
      "Always consider the longest n-gram match, not the sub-string.\n",
      "If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
      "If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
      "Step 2: Applying other conditions\n",
      "Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
      "Refer to the following statements to understand about different types of conditions to be applied:\n",
      "    1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
      "    2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
      "    3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
      "    4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
      "    5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
      "    6. APPLIED MEASURES: This is applicable only for DERVIED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
      "    \n",
      "    Step 3: Applying time tagger rules only if time elements are present in question\n",
      "    \n",
      "    Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
      "    TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
      "    Calculate date range for each time points based on the following conditions:\n",
      "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \n",
      "{'start_date': '01/01/2020', 'end_date': '15/09/2023'}\n",
      "\n",
      "    2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
      "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
      "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
      "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
      "            Consider the reference month as the month in reference date\n",
      "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
      "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
      "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
      "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
      "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
      "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
      "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
      "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
      "    6. Provide the date range of each time point in start date - end date format always.\n",
      "    \n",
      "    Step 4: Creating the response JSON\n",
      "    Strictly return the response in the exact same JSON format as follows. \n",
      "    Fill the information identified from above steps in the JSON. \n",
      "    The keys mentioned in upper case in the response are constant.\n",
      "    Return only if match is found from the context and non empty values are present\n",
      "    and remember \"n-gram matched to MEASURE\", \"n-gram matched to MEASURE\",\"n-gram matched to DIMENSION\",\n",
      "    \"n-gram matched to FILTER\" and \"n-gram matched to DERIVED MEASURE\"\n",
      "    in the following json structure should be the place holders, these keys you should be replacing with \n",
      "    if you have any the n-grams matched with the MEASURE, FILTER,  DERIVED MEASURE , DIMENSION entities in the step 2\n",
      "    {\n",
      "        \"MEASURE\": {\n",
      "            \"n-gram matched to MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched MEASURE\",\n",
      "                    \"MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DIMENSION\": {\n",
      "            \"n-gram matched to DIMENSION\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DIMENSION\",\n",
      "                    \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"FILTER\": {\n",
      "            \"n-gram matched to FILTER\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched FILTER\",\n",
      "                    \"PARENT\": \"parent of the Matched FILTER\",\n",
      "                    \"EXCLUDE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DERIVED MEASURE\": {\n",
      "            \"n-gram matched to DERIVED MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "                    \"RATIO FILTER\": [{}],\n",
      "                    \"APPLIED MEASURE\": [{\"n-gram matched to MEASURE\": Matched MEASURE}],\n",
      "                    \"DERIVED MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DATE VARIABLE\": {\n",
      "            \"asked time element\": [{\"ENTITY\": \"Matched DATE VARIABLE\"\n",
      "                \"DATE RANGE\": \"date range\",\n",
      "                \"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "                }]\n",
      "        }\n",
      "    }\n",
      "    and provide reasoning.\n",
      "    \n",
      "     \n",
      "    Example 1 - user input :  \"show me the 2 top segments basis sales\"\n",
      "               - your response should be : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "with provided reasoning by you.\n",
      "\n",
      "  Example 2 - user input : \"top 2 and bottom 3 segments by sales\"\n",
      "  your response should be in this case : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"bottom\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"3\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "and respective reasoning   \n",
      "    \n",
      "            <</SYS>>\n",
      "            \n",
      " Now return a response for this question:\n",
      "show me the 2 top segments basis sales\n",
      "\n",
      "            [/INST]\n",
      "            [END]\n",
      "\n",
      "The assistant understands the user's question and identifies the n-grams that match with the context. Based on the identified n-grams, the assistant applies the conditions mentioned in the question to find the relevant matches.\n",
      "\n",
      "For the question \"show me the 2 top segments basis sales\", the assistant identifies the following n-grams that match with the context:\n",
      "\n",
      "* \"top segments\" matches with the DIMENSION \"segments\"\n",
      "* \"basis sales\" matches with the MEASURE \"sales\"\n",
      "\n",
      "Based on the identified n-grams, the assistant applies the conditions mentioned in the question:\n",
      "\n",
      "* For the DIMENSION \"segments\", the assistant finds the top 2 segments based on the RANK ADJECTIVE \"top\" and RANK VALUE \"2\".\n",
      "* For the MEASURE \"sales\", the assistant finds the sales data for the top 2 segments.\n",
      "\n",
      "The assistant creates a response in the expected format:\n",
      "\n",
      "{\n",
      "\"DIMENSION\": {\n",
      "\"segments\": [\n",
      "{\n",
      "\"ENTITY\": \"Segment\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"2\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Segment\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"2\"\n",
      "}\n",
      "]\n",
      "]\n",
      "},\n",
      "\"MEASURE\": {\n",
      "\"sales\": [\n",
      "{\n",
      "\"ENTITY\": \"Sales\",\n",
      "\"value\": 2000\n",
      "}\n",
      "{\n",
      "\"ENTITY\": \"Sales\",\n",
      "\"value\": 1500\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "Reasoning:\n",
      "The assistant uses the identified n-grams to find the relevant matches with the context. The assistant applies the conditions mentioned in the question to find the top 2 segments based on the RANK ADJECTIVE \"top\" and RANK VALUE \"2\". The assistant also finds the sales data for the top 2 segments.\n",
      "\n",
      "Note: The response is in the expected format, but the actual data may vary based on the actual data available in the context.\n",
      "**********0 question is done.********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "The user question is \"top 2 and bottom 3 segments by sales.\" We need to identify the n-grams that match the question and apply the conditions to find the relevant entities.\n",
      "\n",
      "Step 1: Identify n-gram matches\n",
      "\n",
      "The question contains the following n-grams:\n",
      "\n",
      "* top\n",
      "* bottom\n",
      "* sales\n",
      "\n",
      "Step 2: Apply conditions\n",
      "\n",
      "For the n-gram \"top\", we need to find the ENTITY that matches the measure \"sales\" with a high similarity. We identify the following entity:\n",
      "\n",
      "* Segment\n",
      "\n",
      "The measure constraint for \"top\" is:\n",
      "\n",
      "* COMPARISON VALUE: 2\n",
      "* COMPARSION OPERATOR: >\n",
      "\n",
      "For the n-gram \"bottom\", we need to find the ENTITY that matches the measure \"sales\" with a high similarity. We identify the following entity:\n",
      "\n",
      "* Segment\n",
      "\n",
      "The measure constraint for \"bottom\" is:\n",
      "\n",
      "* COMPARISON VALUE: 3\n",
      "* COMPARSION OPERATOR: <\n",
      "\n",
      "Step 3: Apply time tagger rules (if applicable)\n",
      "\n",
      "The question contains the following time elements:\n",
      "\n",
      "* last 3 months\n",
      "* last 2 years\n",
      "\n",
      "We convert the time elements to a standard format:\n",
      "\n",
      "* last 3 months: 01/07/2022 - 14/09/2022\n",
      "* last 2 years: 01/07/2020 - 14/09/2022\n",
      "\n",
      "Step 4: Create the response JSON\n",
      "\n",
      "Based on the conditions identified in step 2, we create the following response JSON:\n",
      "\n",
      "{\n",
      "\"DIMENSION\": {\n",
      "\"segments\": [\n",
      "    {\n",
      "        \"ENTITY\": \"Segment\",\n",
      "        \"RANK\": [\n",
      "            {\n",
      "                \"RANK ADJECTIVE\": \"top\",\n",
      "                \"RANK VALUE\": \"2\"\n",
      "            },\n",
      "            {\n",
      "                \"RANK ADJECTIVE\": \"bottom\",\n",
      "                \"RANK VALUE\": \"3\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"MEASURE\": {\n",
      "        \"sales\": [\n",
      "            {\n",
      "                \"ENTITY\": \"Sales\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "},\n",
      "\"DATE VARIABLE\": {\n",
      "    \"asked time element\": [\n",
      "        {\n",
      "            \"ENTITY\": \"Matched DATE VARIABLE\",\n",
      "            \"DATE RANGE\": \"last 3 months\",\n",
      "            \"CONVERTED TIME ELEMENT\": \"01/07/2022 - 14/09/2022\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "}\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "* For the n-gram \"top\", we identify the entity \"Segment\" that matches the measure \"sales\" with a high similarity.\n",
      "* For the n-gram \"bottom\", we identify the entity \"Segment\" that matches the measure \"sales\" with a high similarity.\n",
      "* The measure constraint for \"top\" is \"2\", and the measure constraint for \"bottom\" is \"3\".\n",
      "* We convert the time elements \"last 3 months\" and \"last 2 years\" to a standard format.\n",
      "\n",
      "Note: The response JSON is in a simplified format, and the actual response may vary based on the specific requirements of the question.\n",
      "**********1 question is done.********************\n",
      "[INST]<<SYS>>\n",
      "            You are an assistant that helps to map the user question to the context for a question answering system.\n",
      " You might also need to act as a time tagger expert to convert the date elements present in the question to a standard \n",
      " format and to find possible date ranges for the same.\n",
      "Step 1: Identify the n-grams match between question and context\n",
      "Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
      "Always consider the longest n-gram match, not the sub-string.\n",
      "If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
      "If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
      "Step 2: Applying other conditions\n",
      "Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
      "Refer to the following statements to understand about different types of conditions to be applied:\n",
      "    1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
      "    2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
      "    3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
      "    4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
      "    5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
      "    6. APPLIED MEASURES: This is applicable only for DERVIED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
      "    \n",
      "    Step 3: Applying time tagger rules only if time elements are present in question\n",
      "    \n",
      "    Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
      "    TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
      "    Calculate date range for each time points based on the following conditions:\n",
      "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \n",
      "{'start_date': '01/01/2020', 'end_date': '15/09/2023'}\n",
      "\n",
      "    2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
      "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
      "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
      "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
      "            Consider the reference month as the month in reference date\n",
      "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
      "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
      "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
      "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
      "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
      "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
      "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
      "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
      "    6. Provide the date range of each time point in start date - end date format always.\n",
      "    \n",
      "    Step 4: Creating the response JSON\n",
      "    Strictly return the response in the exact same JSON format as follows. \n",
      "    Fill the information identified from above steps in the JSON. \n",
      "    The keys mentioned in upper case in the response are constant.\n",
      "    Return only if match is found from the context and non empty values are present\n",
      "    and remember \"n-gram matched to MEASURE\", \"n-gram matched to MEASURE\",\"n-gram matched to DIMENSION\",\n",
      "    \"n-gram matched to FILTER\" and \"n-gram matched to DERIVED MEASURE\"\n",
      "    in the following json structure should be the place holders, these keys you should be replacing with \n",
      "    if you have any the n-grams matched with the MEASURE, FILTER,  DERIVED MEASURE , DIMENSION entities in the step 2\n",
      "    {\n",
      "        \"MEASURE\": {\n",
      "            \"n-gram matched to MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched MEASURE\",\n",
      "                    \"MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DIMENSION\": {\n",
      "            \"n-gram matched to DIMENSION\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DIMENSION\",\n",
      "                    \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"FILTER\": {\n",
      "            \"n-gram matched to FILTER\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched FILTER\",\n",
      "                    \"PARENT\": \"parent of the Matched FILTER\",\n",
      "                    \"EXCLUDE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DERIVED MEASURE\": {\n",
      "            \"n-gram matched to DERIVED MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "                    \"RATIO FILTER\": [{}],\n",
      "                    \"APPLIED MEASURE\": [{\"n-gram matched to MEASURE\": Matched MEASURE}],\n",
      "                    \"DERIVED MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DATE VARIABLE\": {\n",
      "            \"asked time element\": [{\"ENTITY\": \"Matched DATE VARIABLE\"\n",
      "                \"DATE RANGE\": \"date range\",\n",
      "                \"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "                }]\n",
      "        }\n",
      "    }\n",
      "    and provide reasoning.\n",
      "    \n",
      "     \n",
      "    Example 1 - user input :  \"show me the 2 top segments basis sales\"\n",
      "               - your response should be : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "with provided reasoning by you.\n",
      "\n",
      "  Example 2 - user input : \"top 2 and bottom 3 segments by sales\"\n",
      "  your response should be in this case : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"bottom\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"3\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "and respective reasoning   \n",
      "    \n",
      "            <</SYS>>\n",
      "            \n",
      " Now return a response for this question:\n",
      "top 2 segments and bottom 3 sub-category basis quantity\n",
      "\n",
      "            [/INST]\n",
      "            [END]\n",
      "\n",
      "The assistant understands the question and identifies the n-grams matches in the context. Based on the identified matches, the assistant applies the conditions specified in the question to find the relevant information.\n",
      "\n",
      "For the question \"top 2 segments and bottom 3 sub-category basis quantity,\" the assistant identifies the following n-gram matches in the context:\n",
      "\n",
      "* \"top\" matches with the DIMENSION \"RANK\" ADJECTIVE \"top\" and RANK VALUE \"2\"\n",
      "* \"bottom\" matches with the DIMENSION \"RANK\" ADJECTIVE \"bottom\" and RANK VALUE \"3\"\n",
      "\n",
      "Based on the identified matches, the assistant applies the conditions specified in the question:\n",
      "\n",
      "* For the top 2 segments, the assistant finds the ENTITY \"Segment\" with a RANK of 2.\n",
      "* For the bottom 3 sub-categories, the assistant finds the ENTITY \"Sub-category\" with a RANK of 3.\n",
      "\n",
      "The assistant then provides the response in the expected format:\n",
      "\n",
      "{\n",
      "\"DIMENSION\": {\n",
      "\"segments\": [\n",
      "{\n",
      "\"ENTITY\": \"Segment\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"top\",\n",
      "\"RANK VALUE\": \"2\"\n",
      "}\n",
      "]\n",
      "},\n",
      "{\n",
      "\"ENTITY\": \"Sub-category\",\n",
      "\"RANK\": [\n",
      "{\n",
      "\"RANK ADJECTIVE\": \"bottom\",\n",
      "\"RANK VALUE\": \"3\"\n",
      "}\n",
      "]\n",
      "}\n",
      "],\n",
      "\"MEASURE\": {\n",
      "\"quantity\": [\n",
      "{\n",
      "\"ENTITY\": \"Quantity\",\n",
      "}\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "Reasoning:\n",
      "The assistant uses the identified n-gram matches to find the relevant information in the context. The assistant applies the conditions specified in the question to find the top 2 segments and bottom 3 sub-categories based on the quantity. The assistant provides the response in the expected format with the identified entities and their ranks.\n",
      "**********2 question is done.********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "            You are an assistant that helps to map the user question to the context for a question answering system.\n",
      " You might also need to act as a time tagger expert to convert the date elements present in the question to a standard \n",
      " format and to find possible date ranges for the same.\n",
      "Step 1: Identify the n-grams match between question and context\n",
      "Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
      "Always consider the longest n-gram match, not the sub-string.\n",
      "If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
      "If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
      "Step 2: Applying other conditions\n",
      "Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
      "Refer to the following statements to understand about different types of conditions to be applied:\n",
      "    1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
      "    2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
      "    3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
      "    4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
      "    5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
      "    6. APPLIED MEASURES: This is applicable only for DERVIED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
      "    \n",
      "    Step 3: Applying time tagger rules only if time elements are present in question\n",
      "    \n",
      "    Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
      "    TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
      "    Calculate date range for each time points based on the following conditions:\n",
      "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \n",
      "{'start_date': '01/01/2020', 'end_date': '15/09/2023'}\n",
      "\n",
      "    2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
      "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
      "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
      "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
      "            Consider the reference month as the month in reference date\n",
      "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
      "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
      "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
      "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
      "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
      "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
      "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
      "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
      "    6. Provide the date range of each time point in start date - end date format always.\n",
      "    \n",
      "    Step 4: Creating the response JSON\n",
      "    Strictly return the response in the exact same JSON format as follows. \n",
      "    Fill the information identified from above steps in the JSON. \n",
      "    The keys mentioned in upper case in the response are constant.\n",
      "    Return only if match is found from the context and non empty values are present\n",
      "    and remember \"n-gram matched to MEASURE\", \"n-gram matched to MEASURE\",\"n-gram matched to DIMENSION\",\n",
      "    \"n-gram matched to FILTER\" and \"n-gram matched to DERIVED MEASURE\"\n",
      "    in the following json structure should be the place holders, these keys you should be replacing with \n",
      "    if you have any the n-grams matched with the MEASURE, FILTER,  DERIVED MEASURE , DIMENSION entities in the step 2\n",
      "    {\n",
      "        \"MEASURE\": {\n",
      "            \"n-gram matched to MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched MEASURE\",\n",
      "                    \"MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DIMENSION\": {\n",
      "            \"n-gram matched to DIMENSION\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DIMENSION\",\n",
      "                    \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"FILTER\": {\n",
      "            \"n-gram matched to FILTER\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched FILTER\",\n",
      "                    \"PARENT\": \"parent of the Matched FILTER\",\n",
      "                    \"EXCLUDE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DERIVED MEASURE\": {\n",
      "            \"n-gram matched to DERIVED MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "                    \"RATIO FILTER\": [{}],\n",
      "                    \"APPLIED MEASURE\": [{\"n-gram matched to MEASURE\": Matched MEASURE}],\n",
      "                    \"DERIVED MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DATE VARIABLE\": {\n",
      "            \"asked time element\": [{\"ENTITY\": \"Matched DATE VARIABLE\"\n",
      "                \"DATE RANGE\": \"date range\",\n",
      "                \"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "                }]\n",
      "        }\n",
      "    }\n",
      "    and provide reasoning.\n",
      "    \n",
      "     \n",
      "    Example 1 - user input :  \"show me the 2 top segments basis sales\"\n",
      "               - your response should be : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "with provided reasoning by you.\n",
      "\n",
      "  Example 2 - user input : \"top 2 and bottom 3 segments by sales\"\n",
      "  your response should be in this case : \"{\n",
      "    \"\"DIMENSION\"\": {\n",
      "        \"\"segments\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Segment\"\",\n",
      "                \"\"RANK\"\": [\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"top\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"2\"\"\n",
      "                    },\n",
      "                    {\n",
      "                        \"\"RANK ADJECTIVE\"\": \"\"bottom\"\",\n",
      "                        \"\"RANK VALUE\"\": \"\"3\"\"\n",
      "                    }\n",
      "                ]\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"\"MEASURE\"\": {\n",
      "        \"\"sales\"\": [\n",
      "            {\n",
      "                \"\"ENTITY\"\": \"\"Sales\"\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\"\n",
      "and respective reasoning   \n",
      "    \n",
      "            <</SYS>>\n",
      "            \n",
      " Now return a response for this question:\n",
      "quantity across segments except consumer and corporate in dubai\n",
      "\n",
      "            [/INST]\n",
      "            [END]\n",
      "\n",
      "The provided question is: \"quantity across segments except consumer and corporate in dubai\"\n",
      "\n",
      "To answer this question, we need to identify the n-grams that match with the context and apply the conditions mentioned in the question.\n",
      "\n",
      "Context:\n",
      "\"Show me the 2 top segments basis sales\"\n",
      "\n",
      "N-grams match:\n",
      "\n",
      "* \"top\" - matches with the RANK ADJECTIVE in the context\n",
      "* \"sales\" - matches with the ENTITY in the context\n",
      "\n",
      "Conditions:\n",
      "\n",
      "* METRIC CONSTRAINT: No comparison value is provided in the question, so we cannot apply any metric constraint.\n",
      "* ADJECTIVE: No adjectives are provided in the question, so we cannot apply any adjective conditions.\n",
      "* TONE: The tone of the question is neutral, so we cannot apply any tone conditions.\n",
      "* EXCEPTION: No exception is provided in the question, so we cannot apply any exclusion conditions.\n",
      "* RANK: The rank value is not provided in the question, so we cannot apply any rank condition.\n",
      "* RATIO FILTERS: No ratio filters are provided in the question, so we cannot apply any ratio filter conditions.\n",
      "* APPLIED MEASURES: No applied measures are provided in the question, so we cannot apply any applied measure conditions.\n",
      "* DATE VARIABLE: No date variable is provided in the question, so we cannot apply any date variable condition.\n",
      "\n",
      "Reasoning:\n",
      "Based on the n-grams match and the conditions provided in the question, we can identify the following entities and their corresponding measures:\n",
      "\n",
      "* ENTITY: \"Segments\"\n",
      "* MEASURE: \"sales\"\n",
      "\n",
      "The reasoning for this response is as follows:\n",
      "\n",
      "* The question asks for the top 2 segments in terms of sales.\n",
      "* The context provides the measure of sales.\n",
      "* The n-grams match indicates that the question is asking for the top segments in terms of sales.\n",
      "* Therefore, we can identify the ENTITY as \"Segments\" and the MEASURE as \"sales\".\n",
      "\n",
      "The response for the question is:\n",
      "\n",
      "{\n",
      "\"DIMENSION\": {\n",
      "\"segments\": [\n",
      "    {\n",
      "        \"ENTITY\": \"Segments\",\n",
      "        \"RANK\": [\n",
      "            {\n",
      "                \"RANK ADJECTIVE\": \"top\",\n",
      "                \"RANK VALUE\": \"2\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "],\n",
      "\"MEASURE\": {\n",
      "\"sales\": [\n",
      "    {\n",
      "        \"ENTITY\": \"Sales\",\n",
      "        \"value\": \"X\"\n",
      "    }\n",
      "]\n",
      "}\n",
      "}\n",
      "\n",
      "Where \"X\" is the actual sales value for the top 2 segments.\n",
      "**********3 question is done.********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************MQL**************************************************\n",
      "\n",
      "\n",
      "The assistant has identified the following matches based on the user's question and context:\n",
      "\n",
      "Context:\n",
      "\n",
      "* Question: in corporate share of phone and binder basis discount\n",
      "* User: [ ]\n",
      "\n",
      "Matches:\n",
      "\n",
      "* MEASURE:\n",
      "\t+ Sales\n",
      "\t+ Discount\n",
      "* DIMENSION:\n",
      "\t+ Phone\n",
      "\t+ Binder\n",
      "* FILTER:\n",
      "\t+ Parent of the FILTER is \"corporate\"\n",
      "* RATIO FILTERS: []\n",
      "* APPLIED MEASURES: []\n",
      "* DATE VARIABLE: []\n",
      "\n",
      "**************************************************Reason**************************************************\n",
      "* The user's question mentions \"phone\" and \"binder\", which are entities in the DIMENSION context.\n",
      "* The user's question also mentions \"discount\", which is a MEASURE in the context.\n",
      "* The FILTER \"parent of the FILTER\" is \"corporate\", which is a DIMENSION in the context.\n",
      "* There are no RATIO FILTERS or APPLIED MEASURES that match the user's question.\n",
      "* There is no DATE VARIABLE that matches the user's question.\n",
      "\n",
      "Response:\n",
      "\n",
      "{\n",
      "\"MEASURE\": {\n",
      "\"sales\": [\n",
      "{\n",
      "\"ENTITY\": \"Sales\"\n",
      "}\n",
      "],\n",
      "\"discount\": [\n",
      "{\n",
      "\"ENTITY\": \"Discount\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"DIMENSION\": {\n",
      "\"phone\": [\n",
      "{\n",
      "\"ENTITY\": \"Phone\"\n",
      "}\n",
      "],\n",
      "\"binder\": [\n",
      "{\n",
      "\"ENTITY\": \"Binder\"\n",
      "}\n",
      "]\n",
      "},\n",
      "\"FILTER\": {\n",
      "\"parent of the FILTER\": \"corporate\"\n",
      "},\n",
      "\"RATIO FILTERS\": [],\n",
      "\"APPLIED MEASURES\": [],\n",
      "\"DATE VARIABLE\": []\n",
      "}\n",
      "}\n",
      "\n",
      "Explanation:\n",
      "\n",
      "* The user's question mentions \"phone\" and \"binder\", which are entities in the DIMENSION context.\n",
      "* The user's question also mentions \"discount\", which is a MEASURE in the context.\n",
      "* The FILTER \"parent of the FILTER\" is \"corporate\", which is a DIMENSION in the context.\n",
      "* There are no RATIO FILTERS or APPLIED MEASURES that match the user's question.\n",
      "* There is no DATE VARIABLE that matches the user's question.\n",
      "\n",
      "Note: The response is structured in the format expected by the assistant, with the MEASURE, DIMENSION, FILTER, RATIO FILTERS, APPLIED MEASURES, and DATE VARIABLE keys filled in with the appropriate values based on the user's question and context.\n",
      "**********4 question is done.********************\n"
     ]
    }
   ],
   "source": [
    "for index,question in enumerate(questions[:5]):\n",
    "    output = gereneate_output_llama2(compose_prompt_open_ai_prompt(question,base_prompt=newprompt))\n",
    "    try:\n",
    "        post_process_open_ai_prompt_response(output)\n",
    "    except Exception as e:\n",
    "        print(output)\n",
    "    print(\"*\"*10+f\"{str(index)} question is done.\"+\"*\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c522961c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9239fb772eb2484ba86503fc4f2b06aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-13b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhf_AnMNnliBQHgpXoYkHvLNascxKlSSnwAqpc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m tokenizer2 \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name,\n\u001b[1;32m     11\u001b[0m                                            use_auth_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_AnMNnliBQHgpXoYkHvLNascxKlSSnwAqpc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    492\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2903\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2894\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2896\u001b[0m     (\n\u001b[1;32m   2897\u001b[0m         model,\n\u001b[1;32m   2898\u001b[0m         missing_keys,\n\u001b[1;32m   2899\u001b[0m         unexpected_keys,\n\u001b[1;32m   2900\u001b[0m         mismatched_keys,\n\u001b[1;32m   2901\u001b[0m         offload_index,\n\u001b[1;32m   2902\u001b[0m         error_msgs,\n\u001b[0;32m-> 2903\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2914\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2915\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2921\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   2922\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:3260\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3250\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3251\u001b[0m     state_dict,\n\u001b[1;32m   3252\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3256\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3257\u001b[0m )\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[0;32m-> 3260\u001b[0m     new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3267\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3268\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3276\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:725\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    722\u001b[0m             fp16_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m param_name:\n\u001b[0;32m--> 725\u001b[0m             \u001b[43mset_module_quantized_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, offload_index, state_dict_index\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/utils/bitsandbytes.py:99\u001b[0m, in \u001b[0;36mset_module_quantized_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, fp16_statistics)\u001b[0m\n\u001b[1;32m     97\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mInt8Params(new_value, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_4bit:\n\u001b[0;32m---> 99\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m new_value\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fp16_statistics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:179\u001b[0m, in \u001b[0;36mParams4bit.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:156\u001b[0m, in \u001b[0;36mParams4bit.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[0;32m--> 156\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     w_4bit, quant_state \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mquantize_4bit(w, blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize, compress_statistics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress_statistics, quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_type)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m w_4bit\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "model2 = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                              quantization_config=bnb_config,\n",
    "                                              device_map=device_map,\n",
    "                                              use_auth_token=\"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\")\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(model_name,\n",
    "                                           use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03de994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gereneate_output_llama2_13b(prompt):\n",
    "    #prompt = json.dumps(prompt)\n",
    "    model_input = tokenizer2(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #model.eval()\n",
    "    response = tokenizer2.decode(model2.generate(**model_input, max_length=4096)[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "707d1358",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2697: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    }
   ],
   "source": [
    "question = \"top 2 segments and bottom 3 sub-category basis quantity\"\n",
    "output = gereneate_output_llama2_13b(compose_prompt_open_ai_prompt(question,base_prompt=system_msg))\n",
    "#post_process_open_ai_prompt_response(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5898db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "            You are an assistant that helps to map the user question to the context for a question answering system.\n",
      " You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
      "Rule 1: Identify the n-grams match between given question and \"CONTEXT\" (\"CONTEXT\" is like a lookup data which user will be providing in the JSON format contains data about \"MEASURE\",\"DIMENSION\",\"FILTER\", \"DERIVED MEASURE\" etc).\n",
      "        Map the n-gram or their lemma or their inflections from the question with the 'other names' field in the passed \"CONTEXT\".\n",
      "        Always consider the longest n-gram match, not the sub-string.\n",
      "        If there are multiple matches for an n-gram with CONTEXT, return all such ENTITY in response.\n",
      "        If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
      "    Rule 2: Applying other conditions\n",
      "            Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
      "            Refer to the following statements to understand about different types of conditions to be applied:\n",
      "                1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
      "                2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
      "                3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
      "                4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
      "                5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
      "                6. APPLIED MEASURES: This is applicable only for DERVIED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
      "    \n",
      "   Rule 3: Applying time tagger rules only if time elements are present in question\n",
      "        \n",
      "                Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time  tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
      "        TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
      "    Calculate date range for each time points based on the following conditions:\n",
      "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \n",
      "{'start_date': '01/01/2020', 'end_date': '15/09/2023'}\n",
      "\n",
      "    2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
      "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
      "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
      "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
      "            Consider the reference month as the month in reference date\n",
      "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
      "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
      "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
      "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
      "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
      "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
      "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
      "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
      "    6. Provide the date range of each time point in start date - end date format always.\n",
      "    \n",
      "    Rule 4: Creating the response JSON\n",
      "    Strictly return the response in the exact same JSON format as follows. \n",
      "    Fill the information identified from above steps in the JSON. \n",
      "    The keys mentioned in upper case in the response are constant.\n",
      "    Return only if match is found from the context and non empty values are present\n",
      "    {\n",
      "        \"MEASURE\": {\n",
      "            \"n-gram matched to MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched MEASURE\",\n",
      "                    \"MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DIMENSION\": {\n",
      "            \"n-gram matched to DIMENSION\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DIMENSION\",\n",
      "                    \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"FILTER\": {\n",
      "            \"n-gram matched to FILTER\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched FILTER\",\n",
      "                    \"PARENT\": \"parent of the Matched FILTER\",\n",
      "                    \"EXCLUDE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DERIVED MEASURE\": {\n",
      "            \"n-gram matched to DERIVED MEASURE\": [\n",
      "                {\n",
      "                    \"ENTITY\": \"Matched DERIVED MEASURE\",\n",
      "                    \"RATIO FILTER\": [{}],\n",
      "                    \"APPLIED MEASURE\": [{\"n-gram matched to MEASURE\": Matched MEASURE}],\n",
      "                    \"DERIVED MEASURE CONSTRAINT\": [\n",
      "                        {\n",
      "                            \"COMPARISON VALUE\": \"\",\n",
      "                            \"COMPARSION OPERATOR\": \"\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"ADJECTIVE\": [],\n",
      "                    \"TONE\": \"\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"DATE VARIABLE\": {\n",
      "            \"asked time element\": [{\"ENTITY\": \"Matched DATE VARIABLE\"\n",
      "                \"DATE RANGE\": \"date range\",\n",
      "                \"CONVERTED TIME ELEMENT\": \"converted time element\"\n",
      "                }]\n",
      "        }\n",
      "    }    \n",
      "    Provide reasoning\n",
      "    \n",
      "            <</SYS>>\n",
      "            Based on the following \"CONTEXT\" data:\n",
      "{'MEASURE': [{'ENTITY': 'Discount', 'other names': ['discount', 'discount rate', 'discount value', 'deduction']}, {'ENTITY': 'Purchase Vol', 'other names': ['purchase', 'purchase value', 'purchase model']}, {'ENTITY': 'Quantity', 'other names': ['quantity', 'volume']}, {'ENTITY': 'Sales', 'other names': ['sales', 'sale']}], 'DIMENSION': [{'ENTITY': 'Sub-Category', 'other names': ['sub-category', 'sub category', 'categories', 'section']}, {'ENTITY': 'Segment', 'other names': ['segment', 'segments', 'units', 'divisions']}, {'ENTITY': 'Parts', 'other names': ['parts', 'part', 'section', 'divisions']}, {'ENTITY': 'Country', 'other names': ['country', 'countries']}], 'FILTER': [{'ENTITY': 'Consumer', 'other names': ['consumers', 'consumer'], 'parent': 'Segment'}, {'ENTITY': 'Phone', 'other names': ['phone', 'phones', 'mobile phones'], 'parent': 'Sub-Category'}, {'ENTITY': 'Binder', 'other names': ['binders', 'binder'], 'parent': 'Sub-Category'}, {'ENTITY': 'Corporate', 'other names': ['corporates', 'corporate'], 'parent': 'Segment'}, {'ENTITY': 'India', 'other names': ['india'], 'parent': 'Country'}, {'ENTITY': 'Dubai', 'other names': ['dubai'], 'parent': 'Country'}], 'DERIVED MEASURE': [{'ENTITY': 'Ratio', 'other names': ['ratio', 'share', 'contribution', 'percentage', 'proportion', 'contributing']}, {'ENTITY': 'Why', 'other names': ['why', 'cause of', 'reason for', 'diagnose']}, {'ENTITY': 'contribution_to_growth', 'other names': ['contribution to growth', 'growth', 'grown']}, {'ENTITY': 'kda_transactional', 'other names': ['kda', 'key drivers', 'key driver', 'drivers', 'driver']}, {'ENTITY': 'Growth Rate', 'other names': ['growth rate', 'growth', 'grown']}, {'ENTITY': 'correlation', 'other names': ['associate', 'associated', 'association', 'associations', 'correlate', 'correlated', 'correlation', 'correlations', 'relate', 'related', 'relation', 'relations', 'relationship', 'relationships']}], 'DATE VARIABLE': [{'ENTITY': 'Order Date', 'other names': ['order date', 'date', 'trend', 'time', 'when', 'mom', 'yoy']}]}\n",
      " return a response for the question:\n",
      "top 2 segments and bottom 3 sub-category basis quantity\n",
      "\n",
      "            [/INST]\n",
      "            [END]\n",
      "\n",
      "Based on the given \"CONTEXT\" data, I can provide the following response for the question \"top 2 segments and bottom 3 sub-category basis quantity\":\n",
      "\n",
      "MEASURE:\n",
      "\n",
      "* n-gram matched to MEASURE: ['quantity']\n",
      "* ENTITY: Quantity\n",
      "* MEASURE CONSTRAINT: [{\"COMPARISON VALUE\": \"\", \"COMPARSION OPERATOR\": \"\"}]\n",
      "* ADJECTIVE: []\n",
      "* TONE: \"\"\n",
      "\n",
      "DIMENSION:\n",
      "\n",
      "* n-gram matched to DIMENSION: ['sub-category', 'segment']\n",
      "* ENTITY: Sub-Category, Segment\n",
      "* RANK: [{\"RANK ADJECTIVE\": \"top\", \"RANK VALUE\": \"2\"}]\n",
      "* ADJECTIVE: []\n",
      "* TONE: \"\"\n",
      "\n",
      "FILTER:\n",
      "\n",
      "* n-gram matched to FILTER: ['consumer', 'phone', 'binder', 'corporate', 'india', 'dubai']\n",
      "* ENTITY: Consumer, Phone, Binder, Corporate, India, Dubai\n",
      "* EXCLUDE: []\n",
      "\n",
      "DERIVED MEASURE:\n",
      "\n",
      "* n-gram matched to DERIVED MEASURE: ['ratio']\n",
      "* ENTITY: Ratio\n",
      "* RATIO FILTERS: [{\"ENTITY\": \"Binder\", \"ratio\": \"100\"}]\n",
      "* APPLIED MEASURE: [{\"ENTITY\": \"Quantity\", \"MEASURE CONSTRAINT\": [{\"COMPARISON VALUE\": \"\", \"COMPARSION OPERATOR\": \"\"}]}]\n",
      "* ADJECTIVE: []\n",
      "* TONE: \"\"\n",
      "\n",
      "DATE VARIABLE:\n",
      "\n",
      "* asked time element: ['Order Date']\n",
      "* CONVERTED TIME ELEMENT: ['order date']\n",
      "\n",
      "Based on the question, the top 2 segments and bottom 3 sub-category basis quantity are:\n",
      "\n",
      "Top 2 segments:\n",
      "\n",
      "1. Segment A\n",
      "2. Segment B\n",
      "\n",
      "Bottom 3 sub-category:\n",
      "\n",
      "1. Sub-Category C\n",
      "2. Sub-Category D\n",
      "3. Sub-Category E\n",
      "\n",
      "Note: The response is based on the given \"CONTEXT\" data and the question asked. The answer is in the format of a JSON object.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
