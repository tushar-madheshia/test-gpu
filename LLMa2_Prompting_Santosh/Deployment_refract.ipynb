{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a551a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install --upgrade transformers\n",
    "# !sudo pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d05e4a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.35.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig\n",
    "import json\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from fuzzywuzzy import process\n",
    "print(transformers.__version__)\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a080b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a30cf0adca4a6fbc3f2ce54ff4cf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name =\"openchat/openchat_3.5\"\n",
    "# model_mistral = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,\n",
    "#     device_map=device_map)\n",
    "model_open_chat = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.bfloat16,offload_folder=\"offload\")\n",
    "tokenizer_open_chat = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1ce2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTBigCodeForCausalLM were not initialized from the model checkpoint at /packages/huggingface/cache/models--HuggingFaceH4--starchat-beta/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f/ and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "#pipe = pipeline(\"text-generation\", model=\"HuggingFaceH4/starchat-beta\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "pipe = pipeline(\"text-generation\", model=\"/packages/huggingface/cache/models--HuggingFaceH4--starchat-beta/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f/\", torch_dtype=torch.bfloat16, device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a74b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:49155 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2023-11-09 11:58:02.727955\n",
      "1699531082.7280452\n",
      "before model start\n",
      "aavesh\n",
      "Today's date: 2023-11-09 11:59:41.961743\n",
      "ended the pipe\n",
      "[{'generated_text': \"<|system|>\\n<|end|>\\n<|user|>\\nHow do I sort a list in Python?<|end|>\\n<|assistant|>\\nThere are multiple ways to sort a list in Python. One of the most common ways is to use the sort() method.\\n\\nHere's an example:\\n\\n```\\nnumbers = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\\nnumbers.sort()\\nprint(numbers)\\n```\\n\\nThis will sort the list in place and print the sorted list.\\n\\nAnother way to sort a list is to use the sorted() function, which returns a new sorted list without modifying the original list.\\n\\nHere's an example:\\n\\n```\\nnumbers = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5]\\nsorted_numbers = sorted(numbers)\\nprint(sorted_numbers)\\n```\\n\\nBoth methods support various sorting algorithms and can sort a list in either ascending or descending order.\"}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "print(\"Today's date:\", datetime.now())\n",
    "t1 = time.time()\n",
    "print(t1)\n",
    "prompt_template = \"<|system|>\\n<|end|>\\n<|user|>\\n{query}<|end|>\\n<|assistant|>\"\n",
    "prompt = prompt_template.format(query=\"How do I sort a list in Python?\")\n",
    "print(\"before model start\")\n",
    "# We use a special <|end|> token with ID 49155 to denote ends of a turn\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.2, top_k=50, top_p=0.95, eos_token_id=49155)\n",
    "print(\"aavesh\")\n",
    "t2 = time.time()\n",
    "t2-t1\n",
    "print(\"Today's date:\", datetime.now())\n",
    "print(\"ended the pipe\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a variant of ChatML to format each message\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "prompt_template = \"<|system|>\\n<|end|>\\n<|user|>\\n{query}<|end|>\\n<|assistant|>\"\n",
    "prompt = prompt_template.format(query=\"How do I sort a list in Python?\")\n",
    "print(\"before model start\")\n",
    "# We use a special <|end|> token with ID 49155 to denote ends of a turn\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.2, top_k=50, top_p=0.95, eos_token_id=49155)\n",
    "print(\"aavesh\")\n",
    "t2 = time.time()\n",
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81f5cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outputs[0][\"generated_text\"].split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a957e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.34.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5453fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "\n",
    "# # new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6753e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "                         \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "                        {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "                        {\"ENTITY\": \"contribution_to_growth\",\n",
    "                         \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"kda_transactional\",\n",
    "                         \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "                        {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"correlation\",\n",
    "                         \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\",\n",
    "                                         \"correlated\",\n",
    "                                         \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                                         \"relationship\",\n",
    "                                         \"relationships\"]}\n",
    "                        ],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}\n",
    "\n",
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}\n",
    "\n",
    "system_msg = \"\"\"You are an assistant that helps to map the user question to the context for a question answering system.\n",
    " You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
    "Step 1: Identify the n-grams match between question and context\n",
    "Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
    "Always consider the longest n-gram match, not the sub-string.\n",
    "If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
    "If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
    "Step 2: Applying other conditions\n",
    "Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
    "Refer to the following statements to understand about different types of conditions to be applied:\n",
    "    1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
    "    2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
    "    3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
    "    4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
    "    5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
    "    6. APPLIED MEASURES: This is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
    "    \n",
    "    Step 3: Applying time tagger rules only if time elements are present in question\n",
    "    \n",
    "    Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
    "    TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
    "    Calculate date range for each time points based on the following conditions:\n",
    "    1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \"\"\" '\\n' + str(\n",
    "    date_input) + '\\n' \"\"\"\n",
    "    2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
    "            For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
    "            For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
    "    3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
    "            Consider the reference month as the month in reference date\n",
    "            For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
    "            For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
    "    4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
    "            For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
    "            For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
    "    5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
    "            For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
    "            For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
    "    6. Provide the date range of each time point in start date - end date format always.\n",
    "    \n",
    "    Step 4: Creating the response JSON\n",
    "    Strictly return the response in the exact same JSON format as follows. \n",
    "    Fill the information identified from above steps in the JSON. \n",
    "    The keys mentioned in upper case in the response are constant.\n",
    "    Return only if match is found from the context and non empty values are present.\n",
    "    Replace the placeholders \"<>\" with your findings.\n",
    "    {\n",
    "        \"MEASURE\": {\n",
    "            \"<n-gram matched to MEASURE>\": [\n",
    "                {\n",
    "                    \"ENTITY\": \"<Matched MEASURE>\",\n",
    "                    \"MEASURE CONSTRAINT\": [\n",
    "                        {\n",
    "                            \"COMPARISON VALUE\": \"\",\n",
    "                            \"COMPARSION OPERATOR\": \"\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"ADJECTIVE\": [],\n",
    "                    \"TONE\": \"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"DIMENSION\": {\n",
    "            \"<n-gram matched to DIMENSION>\": [\n",
    "                {\n",
    "                    \"ENTITY\": \"<Matched DIMENSION>\",\n",
    "                    \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
    "                    \"ADJECTIVE\": [],\n",
    "                    \"TONE\": \"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"FILTER\": {\n",
    "            \"<n-gram matched to FILTER>\": [\n",
    "                {\n",
    "                    \"ENTITY\": \"<Matched FILTER>\",\n",
    "                    \"PARENT\": \"<parent of the Matched FILTER>\",\n",
    "                    \"EXCLUDE\": \"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"DERIVED MEASURE\": {\n",
    "            \"<n-gram matched to DERIVED MEASURE>\": [\n",
    "                {\n",
    "                    \"ENTITY\": \"<Matched DERIVED MEASURE>\",\n",
    "                    \"RATIO FILTER\": [{}],\n",
    "                    \"APPLIED MEASURE\": [{\"<n-gram matched to MEASURE>\": \"<Matched MEASURE>\"}],\n",
    "                    \"DERIVED MEASURE CONSTRAINT\": [\n",
    "                        {\n",
    "                            \"COMPARISON VALUE\": \"\",\n",
    "                            \"COMPARSION OPERATOR\": \"\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"ADJECTIVE\": [],\n",
    "                    \"TONE\": \"\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"DATE VARIABLE\": {\n",
    "            \"asked time element\": [{\"ENTITY\": \"<Matched DATE VARIABLE>\"\n",
    "                \"DATE RANGE\": \"date range\",\n",
    "                \"CONVERTED TIME ELEMENT\": \"<converted time element>\"\n",
    "                }]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Provide reasoning\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51831cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self,model_name,base_prompt,model_loaded=None,tokenizer_loaded=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_loaded = model_loaded\n",
    "        self.tokenizer_loaded = tokenizer_loaded\n",
    "        self.model_name = model_name\n",
    "        self.base_prompt =base_prompt\n",
    "        import torch\n",
    "        from transformers import pipeline\n",
    "\n",
    "        if self.model_loaded is None:\n",
    "            print(\"LLM model loading from data section\")\n",
    "            \n",
    "            self.model_loaded = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.bfloat16,offload_folder=\"offload\")\n",
    "            #pipeline(\"text-generation\", model=\"/packages/huggingface/cache/models--HuggingFaceH4--starchat-beta/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f/\", torch_dtype=torch.bfloat16, device_map=\"cpu\")\n",
    "            self.tokenizer_loaded = AutoTokenizer.from_pretrained(model_name)\n",
    "            \n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[{\"question\": \"\",\"context\":\"\"},{\"question\": \"\",\"context\":\"\"},...]\n",
    "\n",
    "        :return: (n_inputs, payload's)\n",
    "\n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (len(raw_payload), raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        return payload\n",
    "\n",
    "   \n",
    "    \n",
    "    def compose_prompt_open_chat(input_json):\n",
    "        #question = input_json[\"question\"] \n",
    "        #context = input_json[\"context\"] \n",
    "        print(input_json[\"question\"])\n",
    "        return f\"\"\"<s>[IDENTITY]\n",
    "                {system_msg}\n",
    "                [/IDENTITY]</s>\n",
    "                [INST]\n",
    "                {get_user_question_for_open_chat(question,context)}\n",
    "                [/INST]\n",
    "                \"\"\"\n",
    "    def gereneate_output_openchat(prompt):\n",
    "        #prompt = json.dumps(prompt)\n",
    "        model_input = self.tokenizer_loaded(prompt, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "        #model.eval()\n",
    "        response = self.tokenizer_loaded.decode(self.model_loaded.generate(**model_input, max_length=1024*6)[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    \n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      input_query\n",
    "                       ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "        question = input_query[\"question\"]\n",
    "        context = input_query[\"context\"]\n",
    "        query = \"\"\"Now Based on this following context: \\n \"\"\"+ str(context) + \"\\n return a response for this question:\\n\" + question + \"\\n\"\n",
    "        prompt = f\"\"\"<s>[IDENTITY]\n",
    "                    {system_msg}\n",
    "                    [/IDENTITY]</s>\n",
    "                    [INST]\n",
    "                    {query}\n",
    "                    [/INST]\n",
    "                    \"\"\"\n",
    "        print(\"promting has started\")\n",
    "        model_input = self.tokenizer_loaded(prompt, return_tensors=\"pt\")#.to(\"cuda\")\n",
    "        #model.eval()\n",
    "        response = self.tokenizer_loaded.decode(self.model_loaded.generate(**model_input, max_length=1024*3)[0], skip_special_tokens=True)\n",
    "        preds = response.split(\"[SOL]\")[-1].split(\"[/SOL]\")[0]\n",
    "        print(\"prediction is \\n: \",preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc341beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "promting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"segments\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"segments\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [\n",
      "                                        \"top\"\n",
      "                                    ],\n",
      "                                    \"TONE\": \"positive\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"sub-category\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"sub-category\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [\n",
      "                                        \"bottom\"\n",
      "                                    ],\n",
      "                                    \"TONE\": \"negative\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {},\n",
      "                        \"FILTER\": {},\n",
      "                        \"DERIVED MEASURE\": {},\n",
      "                        \"DATE VARIABLE\": {}\n",
      "                    }\n",
      "                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample(model_name=\"openchat/openchat_3.5\",\n",
    "                              tokenizer_loaded=score_.tokenizer_loaded,\n",
    "                              model_loaded=score_.model_loaded,\n",
    "                              base_prompt=system_msg)\n",
    "\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1480642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model loading from data section\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6be9d53425440dcb426f6cd4005407d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTBigCodeForCausalLM were not initialized from the model checkpoint at /packages/huggingface/cache/models--HuggingFaceH4--starchat-beta/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f/ and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()\n",
    "import requests\n",
    "req = requests.Request()\n",
    "\n",
    "req.json = {\"payload\":\"How do I build neural network in Python?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6ed4178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:49155 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "promting has started\n",
      "prediction is \n",
      ":  \n",
      "Building a neural network in Python can be done using the popular library TensorFlow. Here's a basic example of how to create a neural network in Python using TensorFlow:\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "# Define the layers of the neural network\n",
      "input_layer = tf.keras.layers.Input(shape=(2,))\n",
      "hidden_layer = tf.keras.layers.Dense(3, activation='relu')(input_layer)\n",
      "output_layer = tf.keras.layers.Dense(1)(hidden_layer)\n",
      "\n",
      "# Define the model\n",
      "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
      "\n",
      "# Compile the model\n",
      "model.compile(optimizer='adam', loss='mean_squared_error')\n",
      "\n",
      "# Generate some sample data\n",
      "x_train = [[0, 0], [1, 1], [2, 2], [3, 3]]\n",
      "y_train = [0, 1, 4, 9]\n",
      "\n",
      "# Train the model\n",
      "model.fit(x_train, y_train, epochs=500, verbose=0)\n",
      "\n",
      "# Evaluate the model\n",
      "model.evaluate(x_train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159.01578283309937"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = time.time()\n",
    "model_predictions = score_.score(None, req, dry_run=True)\n",
    "t4 = time.time()\n",
    "t4-t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "364fcb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<<ScoreResponse>>]\n"
     ]
    }
   ],
   "source": [
    "print(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e3b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"/data/huggingface/cache/models--HuggingFaceH4--starchat-beta/snapshots/b1bcda690655777373f57ea6614eb095ec2c886f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4590e224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PASS:: Mandatory Validation :: dict_keys(['name', 'description', 'flavour', 'scoring_func'])\n",
      "INFO:root:PASS:: AlphaNumeric Validation :: dict_keys(['name'])\n",
      "INFO:root:PASS:: Validation/IfPresentTypeCheck :: dict_keys(['schema', 'metadata_info', 'tags'])\n",
      "INFO:root:PASS:: Validation/IfPresentSubfieldMustExist :: dict_keys(['kyd'])\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"POST /registry/api/v1/ml-model/register HTTP/1.1\" 200 10735\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/746254b5-39f1-4c3e-9520-04ed064c6a28 HTTP/1.1\" 200 10728\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/746254b5-39f1-4c3e-9520-04ed064c6a28 HTTP/1.1\" 200 10728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57448a5e9f4453ab5cf2bbba7bd8754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(model,\n",
    "               ScoreTemplateExample,\n",
    "               \"Starchat_Beta_5worker_test\",\n",
    "               \"Starchat_Beta_for_code_Generation\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"pip install SentencePiece \\\\n pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
