{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06917d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prometheus-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f35740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/pip_packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-05-07 07:50:29,439\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from prometheus_eval import PrometheusEval\n",
    "from prometheus_eval.prompts import ABSOLUTE_PROMPT, SCORE_RUBRIC_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export TRANSFORMERS_CACHE=\"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $TRANSFORMERS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71578c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $HF_HUB_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b6f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/data'\n",
    "print(os.environ['TRANSFORMERS_CACHE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc51209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-07 08:12:07 config.py:1086] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 05-07 08:12:07 llm_engine.py:100] Initializing an LLM engine (v0.4.2) with config: model='/data/models--prometheus-eval--prometheus-7b-v2.0/snapshots/43ab11571461e145783a07ebdfbedbe9f11fc7d0', speculative_config=None, tokenizer='/data/models--prometheus-eval--prometheus-7b-v2.0/snapshots/43ab11571461e145783a07ebdfbedbe9f11fc7d0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0, served_model_name=/data/models--prometheus-eval--prometheus-7b-v2.0/snapshots/43ab11571461e145783a07ebdfbedbe9f11fc7d0)\n",
      "INFO 05-07 08:12:07 utils.py:660] Found nccl from library /home/mosaic-ai/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-07 08:12:09 selector.py:81] Cannot use FlashAttention-2 backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 05-07 08:12:09 selector.py:32] Using XFormers backend.\n",
      "INFO 05-07 08:12:42 model_runner.py:175] Loading model weights took 13.4966 GB\n",
      "INFO 05-07 08:12:43 gpu_executor.py:114] # GPU blocks: 26807, # CPU blocks: 2048\n",
      "INFO 05-07 08:12:44 model_runner.py:937] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-07 08:12:44 model_runner.py:941] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-07 08:12:49 model_runner.py:1017] Graph capturing finished in 5 secs.\n"
     ]
    }
   ],
   "source": [
    "judge = PrometheusEval(model_id=\"/data/models--prometheus-eval--prometheus-7b-v2.0/snapshots/43ab11571461e145783a07ebdfbedbe9f11fc7d0\", absolute_grade_template=ABSOLUTE_PROMPT,dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9c8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Struggling with a recent break-up, a person opens up about the intense feelings of loneliness and sadness. They ask for advice on how to cope with the heartbreak and move forward in life.\",\n",
    "response = \"I'm genuinely sorry to hear about your break-up. This can be an immensely challenging time filled with intense emotions of loneliness and sorrow. It's important to remember that it's normal to experience these feelings; they are a testament to the deep connection you once had. Firstly, don't hesitate to embrace your emotions, let them flow freely. Ignoring them often complicates the healing process. It's natural to be upset, to shed tears, or to feel angry. This is all part of the journey towards healing. Self-care can be a healing balm in these tough times. This could mean indulging in your favourite book, journaling your thoughts, or even just a quiet cup of tea. Small acts of kindness to oneself can significantly improve your emotional well-being. Also, don't isolate yourself. Surround yourself with supportive individuals who can offer comfort and understanding. This might include friends, family, or even a mental health professional. They can provide much-needed emotional support and strategies to help you cope. Lastly, remember there's no set timeline for healing. It's different for everyone and it's okay to take as long as you need. Keep your focus on the future and the potential it holds. Though it may not seem possible now, you will emerge stronger from this experience. It's okay to ask for help, it's okay to grieve, and it's okay to take it one day at a time. You're not alone in this journey, and there are people ready and willing to help. It's okay to heal at your own pace.\",\n",
    "reference_answer = \"I can only imagine how difficult this time must be for you. Heartbreak can feel like an overwhelming wave that washes over you, making you feel lost and alone. It's important to remember that it's okay to feel this way; your feelings are valid and it's natural to grieve the loss of a relationship. Firstly, it's crucial to allow yourself to feel the emotions fully. Suppressing or denying them often only prolongs the healing process. It's okay to cry, to feel sad, or to be angry. These are all part of the healing journey. Engaging in self-care activities can also provide a much-needed boost. This could be anything from taking a warm bath, writing in a journal, or simply drinking a cup of your favorite tea. Small acts of self-love can make a big difference in how you feel. Next, try to surround yourself with supportive people who understand your situation and provide comfort. Friends and family can be a great source of strength in times of heartbreak. If you feel comfortable, you might want to consider seeking professional help. Therapists and counselors are trained to provide assistance and tools to navigate through difficult times like these. Lastly, it's important to remember that it's okay to take your time to heal. Everyone has their own pace and there's no rush. Try to focus on the future and the possibilities it holds. While it may not seem like it now, you will come out stronger and more resilient from this experience. Remember, it's okay to ask for help and it's okay to feel the way you feel. You are not alone in this journey and there are people who care about you and want to help. It's okay to take one day at a time. Healing is a process, and it's okay to move through it at your own pace.\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d97b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_data = {\n",
    "  \"criteria\":\"Is the model proficient in applying empathy and emotional intelligence to its responses when the user conveys emotions or faces challenging circumstances?\",\n",
    "  \"score1_description\":\"The model neglects to identify or react to the emotional tone of user inputs, giving responses that are unfitting or emotionally insensitive.\",\n",
    "  \"score2_description\":\"The model intermittently acknowledges emotional context but often responds without sufficient empathy or emotional understanding.\",\n",
    "  \"score3_description\":\"The model typically identifies emotional context and attempts to answer with empathy, yet the responses might sometimes miss the point or lack emotional profundity.\",\n",
    "  \"score4_description\":\"The model consistently identifies and reacts suitably to emotional context, providing empathetic responses. Nonetheless, there may still be sporadic oversights or deficiencies in emotional depth.\",\n",
    "  \"score5_description\":\"The model excels in identifying emotional context and persistently offers empathetic, emotionally aware responses that demonstrate a profound comprehension of the user's emotions or situation.\"\n",
    "}\n",
    "\n",
    "score_rubric = SCORE_RUBRIC_TEMPLATE.format(**rubric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcce4bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/1 instances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finalizing: 100%|██████████| 1/1 [00:00<00:00, 20560.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback: The response excels in applying empathy and emotional intelligence, thus aligning with a score of 5. It begins by validating the person's feelings, showing a deep understanding of the emotional context of the situation. It then provides practical advice for coping with the break-up, suggesting self-care activities, reaching out for social support, and giving the individual permission to grieve at their own pace. Furthermore, it reinforces the concept that healing is a personal journey and encourages focusing on the future. The response is emotionally sensitive and demonstrates a profound comprehension of the user's emotions and situation. Thus, it meets the criteria set out in the score rubric effectively, displaying consistent empathy and emotional understanding throughout.\n",
      "Score: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feedback, score = judge.single_absolute_grade(\n",
    "    instruction=instruction,\n",
    "    response=response,\n",
    "    rubric=score_rubric,\n",
    "    reference_answer=reference_answer\n",
    ")\n",
    "\n",
    "print(\"Feedback:\", feedback)\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70349c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
