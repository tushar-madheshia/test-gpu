{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8961cdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a6e886ff99417a8f90924ca695ce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4e40a7679b4eeb8f26979d2f54af4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)codet5p_embedding.py:   0%|          | 0.00/2.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/codet5p-110m-embedding:\n",
      "- configuration_codet5p_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6078f56a4a84901ac00792813ce14ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)codet5p_embedding.py:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/codet5p-110m-embedding:\n",
      "- modeling_codet5p_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faa15054a3a40d698c1cd89eac3cbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the embedding: 256, with norm=1.0\n",
      "tensor([ 0.0185,  0.0229, -0.0315, -0.0307, -0.1421, -0.0575, -0.0275,  0.0501,\n",
      "         0.0203,  0.0337, -0.0067, -0.0075, -0.0222, -0.0107, -0.0250, -0.0657,\n",
      "         0.1571, -0.0994, -0.0370,  0.0164, -0.0948,  0.0490, -0.0352,  0.0907,\n",
      "        -0.0198,  0.0130, -0.0921,  0.0209,  0.0651,  0.0319,  0.0299, -0.0173,\n",
      "        -0.0693, -0.0798, -0.0066, -0.0417,  0.1076,  0.0597, -0.0316,  0.0940,\n",
      "        -0.0313,  0.0993,  0.0931, -0.0427,  0.0256,  0.0297, -0.0561, -0.0155,\n",
      "        -0.0496, -0.0697, -0.1011,  0.1178,  0.0283, -0.0571, -0.0635, -0.0222,\n",
      "         0.0710, -0.0617,  0.0423, -0.0057,  0.0620, -0.0262,  0.0441,  0.0425,\n",
      "        -0.0413, -0.0245,  0.0043,  0.0185,  0.0060, -0.1727, -0.1152,  0.0655,\n",
      "        -0.0235, -0.1465, -0.1359,  0.0022,  0.0177, -0.0176, -0.0361, -0.0750,\n",
      "        -0.0464, -0.0846, -0.0088,  0.0136, -0.0221,  0.0591,  0.0876, -0.0903,\n",
      "         0.0271, -0.1165, -0.0169, -0.0566,  0.1173, -0.0801,  0.0430,  0.0236,\n",
      "         0.0060, -0.0778, -0.0570,  0.0102, -0.0172, -0.0051, -0.0891, -0.0620,\n",
      "        -0.0536,  0.0190, -0.0039, -0.0189, -0.0267, -0.0389, -0.0208,  0.0076,\n",
      "        -0.0676,  0.0630, -0.0962,  0.0418, -0.0172, -0.0229, -0.0452,  0.0401,\n",
      "         0.0270,  0.0677, -0.0111, -0.0089,  0.0175,  0.0703,  0.0714, -0.0068,\n",
      "         0.1214, -0.0004,  0.0020,  0.0255,  0.0424, -0.0030,  0.0318,  0.1227,\n",
      "         0.0676, -0.0723,  0.0970,  0.0637, -0.0140, -0.0283, -0.0120,  0.0343,\n",
      "        -0.0890,  0.0680,  0.0514,  0.0513,  0.0627, -0.0284, -0.0479,  0.0068,\n",
      "        -0.0794,  0.0202,  0.0208, -0.0113, -0.0747,  0.0045, -0.0854, -0.0609,\n",
      "        -0.0078,  0.1168,  0.0618, -0.0223, -0.0755,  0.0182, -0.0128,  0.1116,\n",
      "         0.0240,  0.0342,  0.0119, -0.0235, -0.0150, -0.0228, -0.0568, -0.1528,\n",
      "         0.0164, -0.0268,  0.0727, -0.0569,  0.1306,  0.0643, -0.0158, -0.1070,\n",
      "        -0.0107, -0.0139, -0.0363,  0.0366, -0.0986, -0.0628, -0.0277,  0.0316,\n",
      "         0.0363,  0.0038, -0.1092, -0.0679, -0.1398, -0.0648,  0.1711, -0.0666,\n",
      "         0.0563,  0.0581,  0.0226,  0.0347, -0.0672, -0.0229, -0.0565,  0.0623,\n",
      "         0.1089, -0.0687, -0.0901, -0.0073,  0.0426,  0.0870, -0.0390, -0.0144,\n",
      "        -0.0166,  0.0262, -0.0310,  0.0467, -0.0164, -0.0700, -0.0602, -0.0720,\n",
      "        -0.0386,  0.0067, -0.0337, -0.0053,  0.0829,  0.1004,  0.0427,  0.0026,\n",
      "        -0.0537,  0.0951,  0.0584, -0.0583, -0.0208,  0.0124,  0.0067,  0.0403,\n",
      "         0.0091, -0.0044, -0.0036,  0.0524,  0.1103, -0.1511, -0.0479,  0.1709,\n",
      "         0.0772,  0.0721, -0.0332,  0.0866,  0.0799, -0.0581,  0.0713,  0.0218],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "checkpoint = \"Salesforce/codet5p-110m-embedding\"\n",
    "device = \"cpu\"  # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True,cache_dir=\"/notebooks/\")\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True,cache_dir=\"/notebooks/\").to(device)\n",
    "\n",
    "inputs = tokenizer.encode(\"def print_hello_world():\\tprint('Hello World!')\", return_tensors=\"pt\").to(device)\n",
    "embedding = model(inputs)[0]\n",
    "print(f'Dimension of the embedding: {embedding.size()[0]}, with norm={embedding.norm().item()}')\n",
    "# Dimension of the embedding: 256, with norm=1.0\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28787675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1214,  0.0426, -0.1520,  0.0044, -0.1233,  0.0252,  0.0243,  0.0170,\n",
       "         0.0716,  0.0224,  0.0143,  0.0095, -0.0731, -0.0102, -0.0158, -0.0078,\n",
       "         0.0892, -0.1409, -0.0094, -0.0018,  0.0189, -0.0322,  0.0323,  0.1402,\n",
       "        -0.0496,  0.0070, -0.0775,  0.0310, -0.0435,  0.0604,  0.0409, -0.0310,\n",
       "        -0.1309,  0.0529, -0.0998, -0.0534,  0.0469, -0.0016, -0.0833,  0.0781,\n",
       "        -0.0856, -0.0287,  0.0715, -0.0346,  0.0047, -0.0086, -0.0940, -0.0866,\n",
       "        -0.0478, -0.0643, -0.1062,  0.0678, -0.0599, -0.0412, -0.1128,  0.0597,\n",
       "        -0.0262, -0.1115, -0.0639,  0.0995, -0.0118, -0.0560, -0.0240, -0.0074,\n",
       "         0.0069,  0.0619,  0.0092, -0.0694,  0.0821, -0.0933, -0.0225,  0.0777,\n",
       "        -0.0236, -0.0532, -0.1346,  0.0644, -0.0580, -0.1037,  0.0451, -0.0083,\n",
       "         0.0175,  0.0466,  0.0384, -0.0293,  0.0537, -0.0697, -0.0073,  0.0003,\n",
       "        -0.0871, -0.0698,  0.0102, -0.0301,  0.1254, -0.0640, -0.0743,  0.0673,\n",
       "        -0.0525, -0.0624,  0.0359,  0.0684, -0.0534, -0.0685,  0.0304, -0.0006,\n",
       "         0.0484,  0.1216, -0.0868, -0.0179,  0.0077,  0.1046, -0.1202,  0.0116,\n",
       "        -0.0807,  0.0893,  0.0172,  0.0104, -0.0864, -0.0547, -0.0122,  0.0597,\n",
       "        -0.0233,  0.0647,  0.0250, -0.0075, -0.0625,  0.1396,  0.0750, -0.0081,\n",
       "         0.0096,  0.0172,  0.0433, -0.0340, -0.0224, -0.0156,  0.0282,  0.0614,\n",
       "         0.0335,  0.0532,  0.0449,  0.0178,  0.0729,  0.0372, -0.0067,  0.0621,\n",
       "         0.0201,  0.0148,  0.0032,  0.0479, -0.0961,  0.0093, -0.0737, -0.0865,\n",
       "        -0.0516, -0.0564, -0.0175, -0.0879, -0.0589,  0.0299, -0.0119,  0.0103,\n",
       "         0.1322,  0.0821,  0.0052,  0.0447, -0.0402,  0.0122, -0.1254, -0.1036,\n",
       "         0.0287, -0.0160,  0.0139,  0.0815,  0.0697, -0.0395,  0.0007, -0.1118,\n",
       "        -0.1318, -0.0130, -0.0176, -0.0553, -0.0304,  0.0135, -0.0125, -0.0789,\n",
       "         0.0813,  0.0099, -0.0727, -0.0480, -0.0793, -0.0022, -0.0252,  0.0234,\n",
       "        -0.0345,  0.0141,  0.0048, -0.0196, -0.1205,  0.0216,  0.0426, -0.0214,\n",
       "         0.0579, -0.0730,  0.0286,  0.0041,  0.0501, -0.1118,  0.0715, -0.0462,\n",
       "         0.0190,  0.0322, -0.0099,  0.0005,  0.0412, -0.0109, -0.0113,  0.0027,\n",
       "         0.0447,  0.0238,  0.0202,  0.0108, -0.1402, -0.0972,  0.0164, -0.0217,\n",
       "         0.0019, -0.1215,  0.0336, -0.0508,  0.1566,  0.1063, -0.0130,  0.0455,\n",
       "        -0.1045, -0.0151, -0.0112, -0.1560, -0.0922,  0.0121,  0.1032,  0.0521,\n",
       "        -0.0292, -0.0190,  0.0373, -0.1018, -0.0631, -0.0274, -0.0361,  0.1061,\n",
       "        -0.0174, -0.0098, -0.0815,  0.0398,  0.0595,  0.0324, -0.0277, -0.0177],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code = \"proc sql; \\n title 'Population of Large Countries Grouped by Continent';\\n select Continent, sum(Population) as TotPop format=comma15. \\n from sql.countries \\n where Population gt 1000000 \\n group by Continent \\n order by TotPop; \\n quit;\"\n",
    "\n",
    "code = \"\"\"\n",
    "proc sql;\n",
    "   title 'Population of Large Countries Grouped by Continent';\n",
    "   select Continent, sum(Population) as TotPop format=comma15.\n",
    "      from sql.countries\n",
    "      where Population gt 1000000\n",
    "      group by Continent\n",
    "      order by TotPop;\n",
    "quit;\n",
    "\"\"\" \n",
    "inputs1 = tokenizer.encode(code, return_tensors=\"pt\").to(device)\n",
    "embedding1 = model(inputs1)[0]\n",
    "embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d316fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1215,  0.0847, -0.1707,  0.0181, -0.1230,  0.0195,  0.0471,  0.0426,\n",
       "         0.0947, -0.0185, -0.0009,  0.0615, -0.0555,  0.0441,  0.0814, -0.0189,\n",
       "         0.0639, -0.1309, -0.0400, -0.0319, -0.0355,  0.0226, -0.0285,  0.0963,\n",
       "        -0.0858,  0.0070, -0.0834,  0.0342, -0.0089,  0.1064,  0.0361, -0.0523,\n",
       "        -0.0827,  0.0236, -0.1247, -0.0340,  0.0100, -0.0378, -0.1260,  0.1373,\n",
       "        -0.0421, -0.0025,  0.0840,  0.0073,  0.0050, -0.0269, -0.1314, -0.0906,\n",
       "        -0.0374, -0.0909, -0.1117,  0.0749, -0.0824, -0.0191, -0.0840, -0.0040,\n",
       "        -0.0623, -0.0833, -0.0875,  0.0753, -0.0048,  0.0120, -0.0312,  0.0077,\n",
       "         0.0514,  0.0558,  0.0097, -0.0539,  0.0897, -0.1490, -0.0168,  0.0357,\n",
       "         0.0017, -0.0550, -0.1272,  0.0519, -0.0640, -0.1506,  0.0152, -0.0425,\n",
       "        -0.0130,  0.0734,  0.0812, -0.0466,  0.0641, -0.0461, -0.0080, -0.0285,\n",
       "        -0.0235, -0.0820, -0.0291, -0.0439,  0.1463, -0.0723, -0.0745,  0.0427,\n",
       "        -0.0113, -0.0859,  0.0081,  0.0056, -0.0099, -0.0791,  0.0454,  0.0268,\n",
       "         0.0368,  0.1309, -0.0443, -0.0136,  0.0276,  0.0675, -0.0702, -0.0418,\n",
       "        -0.0363,  0.0781, -0.0074, -0.0178, -0.1069, -0.0083,  0.0262,  0.0187,\n",
       "        -0.0276,  0.0684,  0.0114, -0.0481,  0.0158,  0.0593,  0.0896, -0.0352,\n",
       "         0.0369,  0.0004,  0.0107, -0.0782,  0.0228, -0.0426,  0.0043,  0.0241,\n",
       "         0.0573, -0.0145, -0.0289,  0.0096,  0.0612, -0.0121, -0.0290,  0.0575,\n",
       "         0.0320,  0.0127, -0.0105,  0.0107, -0.0368,  0.0256, -0.0175, -0.0817,\n",
       "        -0.1344, -0.0588,  0.0084, -0.1032, -0.1054,  0.0815, -0.0177,  0.0027,\n",
       "         0.1364,  0.0899,  0.0108,  0.0320, -0.0286, -0.0226, -0.1148, -0.0457,\n",
       "         0.0603,  0.0286, -0.0196,  0.1151,  0.0130, -0.0199, -0.0277, -0.0874,\n",
       "        -0.0902, -0.0205, -0.0082, -0.0267,  0.0043,  0.0314, -0.0077, -0.0752,\n",
       "         0.0982,  0.0358, -0.0449, -0.0213, -0.1134, -0.0236,  0.0254,  0.0318,\n",
       "        -0.0622, -0.0574, -0.0673, -0.0235, -0.0634,  0.0141,  0.0700, -0.0118,\n",
       "         0.0130, -0.0410,  0.0342,  0.0201,  0.0736, -0.0489,  0.0355,  0.0170,\n",
       "         0.0172,  0.0489, -0.0380,  0.0525,  0.0410, -0.0354,  0.0165, -0.0134,\n",
       "        -0.0514,  0.0499,  0.0207, -0.0498, -0.1691, -0.1041,  0.0420, -0.0030,\n",
       "        -0.0090, -0.0787,  0.0354, -0.0071,  0.0899,  0.0878, -0.0386,  0.0309,\n",
       "        -0.0633, -0.0031, -0.0008, -0.2143, -0.0956,  0.0106,  0.0732,  0.0615,\n",
       "        -0.0412, -0.0631,  0.0667, -0.0785, -0.0051,  0.0074, -0.0299,  0.0642,\n",
       "        -0.0081,  0.0021, -0.0835,  0.0327,  0.0881,  0.0017,  0.0378,  0.0274],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code = \"proc sql; \\n title '\\n select Continent, sum(Population) as TotPop format=comma15. \\n from sql.countries \\n where Population lt 1000000 \\n group by Continent \\n order by Nikhil; \\n quit;\"\n",
    "code2 = \"\"\"\n",
    "proc summary data=sql.countries;\n",
    "   where Population > 1000000;\n",
    "   class Continent;\n",
    "   var Population;\n",
    "   output out=sumPop sum=TotPop;\n",
    "run;\n",
    "\"\"\"\n",
    "inputs2 = tokenizer.encode(code2, return_tensors=\"pt\").to(device)\n",
    "embedding2 = model(inputs2)[0]\n",
    "embedding2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9db592",
   "metadata": {},
   "source": [
    "# similarity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4980f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score is 0.9994461\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "t1 = embedding1.detach().numpy() \n",
    "t2 = embedding2.detach().numpy() \n",
    "cos_sim = dot(t1, t2)/(norm(t1)*norm(t2))\n",
    "print(\"Similarity Score is\",cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129a0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
