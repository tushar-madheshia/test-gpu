{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3d8c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835dba50c4ce41968fdf4fc577d413fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1216af0089a4fb195a9ab7ac7d258dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e171a9813e14306bf6b775833214001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f341061e1744a49706f5e9d04f474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9190ec093049c88c04f673b82dd06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/50.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352672ba142a49ec812b3311c64a0eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513531fb108d464b81b6bec42c6470d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cf911ef7624b17ac1f96c41454c24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cb276c6fa646b39b1c332e82afdaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d948cff28ab84d7ab16e5d5d305e3ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047c8364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "<pad> Response : <unk>\"formatted sentence\":\"why sales changed in last 4 years\n",
      "943 ms ± 9.99 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "input_text = \"\"\"\n",
    "You are a time tagger expert. Your expertise lies in replacing time related constraints\n",
    "in a sentence with the specified domain related tags. Below given the formatting condition in a structure that,\n",
    "Domain unrelated time tag -> Domain related time tag.\n",
    "\n",
    "2021/01/20 -> Jan 2021\n",
    "2019-05-15 -> May 2019\n",
    "07.2023 -> July 2023\n",
    "first quarter -> quarter 1\n",
    "now -> today\n",
    "two and half year->30 months\n",
    "\n",
    "Your input will be a single sentence\n",
    "here after known as input sentence. You must follow the given rules for this task.\n",
    "\n",
    "Rule 1: Return the sentence itself without any formatting in the below cases\n",
    "    case 1 : If no time related constrained found in the input sentence\n",
    "    case 2 : Only domain related time tags are found in the sentence\n",
    "Rule 2: If any domain unrelated time tags are found in the sentence then replace those with corresponding domain related time tag by analysing the above formating conditions.\n",
    "Rule 3: Very important: Only return the response in the json format without any other info. \n",
    "\n",
    "Examples:\n",
    "input sentence : Why sales changed in 01.23\n",
    "Response : {\"formatted sentence\":\"Why sales changed in jan 2023\"}\n",
    "###\n",
    "input sentence : Total sales in india in 2014-03-19\n",
    "Response : {\"formatted sentence\":\"Total sales in india in March 2014\"}\n",
    "###\n",
    "input sentence : Trend of sales in UK now\n",
    "Response : {\"formatted sentence\":\"Trend of sales in UK today\"}\n",
    "###\n",
    "input sentence : Trend of profits in dec 2017\n",
    "Response : {\"formatted sentence\":\"Trend of profits in dec 2017\"}\n",
    "###\n",
    "input sentence : why sales changed in last three years\n",
    "Response : {\"formatted sentence\":\"why sales changed in last 36 months\"}\n",
    "###\n",
    "input sentence : Total profits in india in fifth quarter\n",
    "Response : {\"formatted sentence\":\"Total profits in india in quarter 5\"}\n",
    "input sentence: why sales changed in last 4 years\n",
    "\"\"\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b1f86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98287a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
