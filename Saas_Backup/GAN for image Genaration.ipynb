{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f98f7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/20/b15abac0be474f12cf51a104c9dd935b053081b502c103e9e947e8be7b84/tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6MB)\n",
      "\u001b[K     |████████████████████▏           | 302.3MB 157.3MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/df/55525e489c43f9dbb6c8ea27d8a567b3dcd18a22f3c45483055f5ca6611d/libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9MB)\n",
      "\u001b[K     |████████████████████████████████| 22.9MB 101.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/7f/25913aacbe0c2c68e7354222bdefe4e840489725eb835e311c581396f91f/wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 96.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<=1.24.3,>=1.22\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/d9/814a619ab84d8eb0d95e08d4c723e665f1e694b5a6068ca505a61bdc3745/numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 95.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/67/e1/434566ffce04448192369c1a282931cf4ae593e91907558eaecd2e9f2801/termcolor-2.3.0-py3-none-any.whl\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl\n",
      "Collecting absl-py>=1.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl (130kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 103.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/a1/c5ca3fb951edb7bab892e61e24c72fc7359ae48916cf7352cde9d712867d/grpcio-1.59.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3MB 94.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/2c/03046cac73f46bfe98fc846ef629cf4f84c2f59258216aa2cc0d22bfca8f/protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 110.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.14,>=2.13\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/f2/e8be5599634ff063fa2c59b7b51636815909d5140a26df9f02ce5d99b81a/tensorboard-2.13.0-py3-none-any.whl (5.6MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6MB 98.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 90.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 91.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.14,>=2.13.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7MB 77.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/f6/0f259f41abaa489f185e16d397d5f5a5973970d4677c7d39456cea6f4453/tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4MB 86.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading https://files.pythonhosted.org/packages/31/25/5abcd82372d3d4a3932e1fa8c3dbf9efac10cc7c0d16e78467460571b404/typing_extensions-4.5.0-py3-none-any.whl\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Collecting h5py>=2.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/31/b5965f76e0bb2b02f273d87ec9cb59c77b9864ac27a0078c4229baa45dfc/h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8MB 90.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 87.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.12.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/26/7945080113158354380a12ce26873dd6c1ebd88d47f5bc24e2c5bb38c16a/setuptools-68.2.2-py3-none-any.whl (807kB)\n",
      "\u001b[K     |████████████████████████████████| 808kB 100.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 90.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 95.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/c1/50caaec6cadc1c6adc8fe351e03bd646d6e4dd17f55fca0f4c8d7ea8d3e9/Markdown-3.5-py3-none-any.whl (101kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 104.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/07/8d9a8186e6768b55dfffeb57c719bc03770cf8a970a074616ae6f9e26a57/google_auth_oauthlib-1.0.0-py2.py3-none-any.whl\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl (182kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 104.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/52/fb9e51fba47951aabd7a6b25e41d73eae94208ccf62d886168096941a781/tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6MB 88.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/a5/54b01f663d60d5334f6c9c87c26274e94617a4fd463d812463626423b10d/werkzeug-3.0.0-py3-none-any.whl (226kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 110.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wheel>=0.26\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/8b/31273bf66016be6ad22bb7345c37ff350276cfd46e389a0c2ac5da9d9073/wheel-0.41.2-py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 104.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl (158kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 112.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 339kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/07/ffb69702716514cca44d58c7cd4f10fcc81e8a44a0e95bd8fd188a709a80/charset_normalizer-3.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 111.0MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/b2/b157855192a68541a91ba7b2bbcb91f1b4faa51f8bae38d8005c034be524/urllib3-2.0.7-py3-none-any.whl (124kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 109.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/37/db7ba97e676af155f5fcb1a35466f446eadc9104e25b83366e8088c9c926/importlib_metadata-6.8.0-py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/bb/5deac77a9af870143c684ab46a7934038a53eb4aa975bc0687ed6ca2c610/requests_oauthlib-1.3.1-py2.py3-none-any.whl\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/8e/bea464350e1b8c6ed0da3a312659cb648804a08af6cacc6435867f74f8bd/pyasn1_modules-0.3.0-py2.py3-none-any.whl (181kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 106.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/de/e2/32c14301bb023986dff527a49325b6259cab4ebb4633f69de54af312fc45/MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting zipp>=0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/80/cab10959dc1faead58dc8384a781dfbf93cb4d33d50988f7a69f1b7c9bbe/oauthlib-3.2.2-py3-none-any.whl (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 107.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/b56a725cbde139aa960c26a1a3ca4d4af437282e20b5314ee6a3501e7dfc/pyasn1-0.5.0-py2.py3-none-any.whl (83kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 110.3MB/s eta 0:00:01\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement PyYAML==6.0, but you'll have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement urllib3==1.26.15, but you'll have urllib3 2.0.7 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, wrapt, numpy, termcolor, flatbuffers, absl-py, grpcio, protobuf, setuptools, certifi, idna, charset-normalizer, urllib3, requests, zipp, importlib-metadata, markdown, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, MarkupSafe, werkzeug, wheel, tensorboard, tensorflow-estimator, opt-einsum, keras, tensorflow-io-gcs-filesystem, typing-extensions, gast, h5py, six, google-pasta, packaging, astunparse, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.3 absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 certifi-2023.7.22 charset-normalizer-3.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.10.0 idna-3.4 importlib-metadata-6.8.0 keras-2.13.1 libclang-16.0.6 markdown-3.5 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.2 protobuf-4.24.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 setuptools-68.2.2 six-1.16.0 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 typing-extensions-4.5.0 urllib3-2.0.7 werkzeug-3.0.0 wheel-0.41.2 wrapt-1.15.0 zipp-3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45ec7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/73/a4af3493a81d6e5e1fdb4c72f4d3573a7e94b60f7c2c69ab0275fdc7cd8e/matplotlib-3.7.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2MB)\n",
      "\u001b[K     |████████████████████████████████| 9.2MB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b8/965acdc0510d0ceca51bb9b9286a600eb8221d1e79d29da16f5bf035deab/fonttools-4.43.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6MB 107.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/21/6cd5249e15834982492f92e5bec7c3beb8135fba0a2e3184b8e80741c46d/Pillow-10.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5MB 111.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2,>=1.20\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 107.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl (247kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 108.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/65/6e/09d8816b5cb7a4006ef8ad1717a2703ad9f331dae9717d9f22488a2d6469/importlib_resources-6.1.0-py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/55/7021ffcc8cb26a520bb051aa0a3d08daf200cde945e5863d5768161e2d3d/kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 103.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging>=20.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 102.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/71/7f20855592cc929bc206810432b991ec4c702dc26b0567b132e52c85536f/contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 106.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl (103kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 103.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl\n",
      "Collecting six>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting zipp>=3.1.0; python_version < \"3.10\"\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/66/48866fc6b158c81cc2bfecc04c480f105c6040e8b077bc54c634b4a67926/zipp-3.17.0-py3-none-any.whl\n",
      "\u001b[31mERROR: tensorflow 2.13.1 has requirement numpy<=1.24.3,>=1.22, but you'll have numpy 1.24.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: fonttools, pillow, numpy, six, python-dateutil, zipp, importlib-resources, kiwisolver, packaging, contourpy, pyparsing, cycler, matplotlib\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.43.1 importlib-resources-6.1.0 kiwisolver-1.4.5 matplotlib-3.7.3 numpy-1.24.4 packaging-23.2 pillow-10.1.0 pyparsing-3.1.1 python-dateutil-2.8.2 six-1.16.0 zipp-3.17.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging-23.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/zipp-3.17.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34127912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bdd1426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9bda71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8b425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(28,)\n",
      "(28, 28)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(input[0][0][0][0][0].shape)\n",
    "print(input[0][0][0][0].shape)\n",
    "print(input[0][0][0].shape)\n",
    "print(input[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a18c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(input[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810667c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-1_1wbkzs because the default path (/home/mosaic-ai/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "086f6320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa48cb2ba30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(input[0][0][10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2cbb53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47040000\n"
     ]
    }
   ],
   "source": [
    "print(input[0][0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af7ae56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(input[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a0754c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dimn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimn\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dimn'"
     ]
    }
   ],
   "source": [
    "print(input[0][0].dimn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e867ce57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  29 150 195 254 255 254 176 193 150\n",
      "   96   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  48 166 224 253 253 234 196 253 253 253 253\n",
      "  233   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  93 244 249 253 187  46  10   8   4  10 194 253 253\n",
      "  233   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 107 253 253 230  48   0   0   0   0   0 192 253 253\n",
      "  156   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   3  20  20  15   0   0   0   0   0  43 224 253 245\n",
      "   74   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 245 126\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  14 101 223 253 248 124   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  11 166 239 253 253 253 187  30   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  16 248 250 253 253 253 253 232 213\n",
      "  111   2   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  43  98  98 208 253 253 253\n",
      "  253 187  22   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   9  51 119 253\n",
      "  253 253  76   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 183\n",
      "  253 253 139   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 182\n",
      "  253 253 104   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  85 249\n",
      "  253 253  36   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  60 214 253\n",
      "  253 173  11   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  98 247 253 253\n",
      "  226   9   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  42 150 252 253 253 233\n",
      "   53   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  42 115  42  60 115 159 240 253 253 250 175  25\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 187 253 253 253 253 253 253 253 197  86   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 103 253 253 253 253 253 232  67   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(input[0][0][10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43484e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da73f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba37b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9927d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddcd10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = models.Sequential([generator, discriminator])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e2980ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "345df02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac286925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580f74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "339b587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc03a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75448f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "332300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "916319bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"<ipython-input-18-fafdd8657c08>\", line 8, in train_step  *\n        real_output = discriminator(images, training=True)\n    File \"/tmp/pip_packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/pip_packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_1\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'images:0' shape=(60000, 28, 28) dtype=uint8>, <tf.Tensor 'images_1:0' shape=(60000,) dtype=uint8>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/pip_packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filech1zr2ea.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gen_tape, ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m disc_tape:\n\u001b[1;32m     10\u001b[0m     generated_images \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(generator), (ag__\u001b[38;5;241m.\u001b[39mld(noise),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 11\u001b[0m     real_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(discriminator), (ag__\u001b[38;5;241m.\u001b[39mld(images),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[1;32m     12\u001b[0m     fake_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(discriminator), (ag__\u001b[38;5;241m.\u001b[39mld(generated_images),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[1;32m     13\u001b[0m     gen_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(generator_loss), (ag__\u001b[38;5;241m.\u001b[39mld(fake_output),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/pip_packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/pip_packages/keras/src/engine/input_spec.py:219\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-18-fafdd8657c08>\", line 8, in train_step  *\n        real_output = discriminator(images, training=True)\n    File \"/tmp/pip_packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/pip_packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_1\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'images:0' shape=(60000, 28, 28) dtype=uint8>, <tf.Tensor 'images_1:0' shape=(60000,) dtype=uint8>]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for image_batch in input:\n",
    "        train_step(image_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acd029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    predictions = (predictions + 1) / 2.0  # Rescale from [-1, 1] to [0, 1]\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b87e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    generate_and_save_images(generator, epoch, seed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
