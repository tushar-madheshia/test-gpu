{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899dd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://lumin-azure-openai-rnd.openai.azure.com/\"\n",
    "openai.api_version = \"2024-02-01\"\n",
    "openai.api_key = \"38002279fa574fbcba0fbc424ae056d5\"\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint =  \"https://lumin-azure-openai-rnd.openai.azure.com/\",\n",
    "  api_key=\"38002279fa574fbcba0fbc424ae056d5\",  \n",
    "  api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d90b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrative_generation_rules = \"\"\"Act as a narrative generator who always strictly follow the specified rules. Generate a concise, professional narrative describing the data in the given JSON input by keeping all important points for this business report for an analyst.\n",
    "        Rule 1: Keep the narrative brief consisting of 1 to 4 sentences, using simple and professional language without repetition, and not exceeding 50 words, except for \"why\" questions. \n",
    "        Rule 2: If a date-type dimension is present, treat it as a trend line; otherwise, consider it as a distributional chart or bar chart.\n",
    "        Rule 3: For trend line charts, the narrative must include the total measure value, the latest measure value, percentage change in the last date interval, and the highest single period climb in percentage.\n",
    "        Rule 4: For distributional or bar charts, the narrative must provide the total measure value, dimension with the highest measure percentage, and the average measure value if present.\n",
    "        Rule 5: If a filter is present in the input JSON, focus on it in the initial sentence of the narrative.\n",
    "        Rule 6: When specifying filters, prioritize in this order in the narrative: location filter, date filter, and default filter.\n",
    "        Rule 7: For charts with non-additive measures, concentrate on the top, second, and bottom players in the narrative.\n",
    "        Rule 8: For ratio questions, the narrative must emphasize the ratio values.\n",
    "        Rule 9: In share-type questions with bar charts, mention the top and bottom players in the narrative.\n",
    "        Rule 10: For share-type questions with trend line charts, the narrative must include percentage share, interval, change in share, and share trend in the latest date interval, excluding other information.\n",
    "        Rule 11: For growth-rate questions, focus on the latest measure value, final percentage change, and growth-rate trends in the narrative.\n",
    "        Rule 12: For \"why\" questions, the narrative must detail on target change, changes in focus areas, and their contribution percentages. These narratives should be more elaborate.\n",
    "        Rule 13: For kda question types, the narrative must include only the top and bottom key drivers and the corresponding values.\n",
    "        Rule 14: For list questions, the narrative must include only the length and dimension data information including the total measure.\n",
    "        Rule 15: For top-bottom question types, with three or more dimension limit, mention only the top/bottom two values for each dimension in the narrative. Include only the number of many tops and its value if many tops are present for dimension1. Very Important to note that Level2 values in json represents the dimension2 top/bottom values in level1 top1(dimension1).\n",
    "        Rule 16: Strictly exclude attaching symbols such as \"EUR\", \"USD\", \"$\", \"%\" etc to any values. The narrative strictly must contain only the information in the Input_question's json. The narrative strictly must not contain any calculated values if any values mentioned in rule to include in narrative is not known.\n",
    "        Generate the narrative for the given input, ensuring it adheres to these guidelines.\"\"\"\n",
    "\n",
    "question = \"trend of sales across market in 2021\"\n",
    "intermediate_result = \"{'Date_Interval': 'month', 'Latest_period': '2021-12-01', 'Total_Latest_Value': 200609.99, 'Latest_Period_Constant_Measures': False, 'Latest_Top1': ['APAC'], 'Latest_Top1_Values': [53514.51], 'Latest_Top2': ['US'], 'Latest_Top2_Values': [47591.55], 'Latest_Bottom1': ['Canada'], 'Latest_Bottom1_Values': [270.6], 'Negative_present': False, 'Measure': [{'label': 'Sales', 'variable': 'Sales', 'type': 'measure', 'alternate_usage': ['Sales'], 'isRegional': False, 'number_type': 'add_values'}], 'Dimension': [{'label': 'Order Date', 'variable': 'Order Date', 'type': 'dimension', 'alternate_usage': ['Order Date'], 'isRegional': False, 'singular': 'Order Date', 'plural': 'Order Dates'}, {'label': 'Market', 'variable': 'Market', 'type': 'dimension', 'alternate_usage': ['Market'], 'isRegional': False, 'singular': 'Market', 'plural': 'Markets'}], 'Dimension_1_len': 12, 'Dimension_2_len': 7, 'Filter': {'Order Date': [{'ref_interval': 'month', 'start_date': '2021/01/01', 'end_date': '2021/12/31'}]}, 'Many_Top_1': False, 'Share_of_Top1_Latest_Period': '26.68', 'ShareType_of_Top1_Latest_Period': '%', 'Share_of_Top2_Latest_Period': '23.72', 'ShareType_of_Top2_Latest_Period': '%', 'Label_Dates': ['2021-01-01', '2021-02-01', '2021-03-01', '2021-04-01', '2021-05-01', '2021-06-01', '2021-07-01', '2021-08-01', '2021-09-01', '2021-10-01', '2021-11-01', '2021-12-01'], 'Number_of_Tops_Latest_period': 1, 'Additive_Last_Two_Periods_Performance': {'focus_call_out_absolute': False, 'competitor_call_out_absolute': False, 'competitor_available': True, 'focus_competitor_similar_value_change': False, 'competitor_brand': 'US', 'focus_brand': 'APAC', 'focus_same_value_in_final_periods': False, 'competitor_same_value_in_final_periods': False, 'focus_directionv1': 'up', 'focus_change': '37.06', 'focus_change_type': '%', 'competitor_directionv1': 'up', 'com_change': '62.62', 'competitor_change_type': '%'}, 'Top_Players': ['APAC']}\"\n",
    "input_to_model = \"Input_question: \"+question +\"\\n\"+ str(intermediate_result)\n",
    "prompt = \"Analyse the given input JSON and infer the values as per the need expressed in the Question in input.\\n\" + str(input_to_model) + \"\\nNarrative:\"\n",
    "    \n",
    "message_text = [\n",
    "    {\"role\":\"system\",\"content\":narrative_generation_rules},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d07638c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"lumin-rnd-gpt-4-32k\", # model = \"deployment_name\".\n",
    "    messages=message_text,\n",
    "    max_tokens=500,\n",
    "    temperature=0,\n",
    "    stop=None,\n",
    "    seed=123,\n",
    "    tools=None,\n",
    "    logprobs=True,  # whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message..\n",
    "    top_logprobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2b0115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-946Kxi3fRN67DjadWZSO1OBZWclCD', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='In', bytes=[73, 110], logprob=-0.0023883758, top_logprobs=[TopLogprob(token='In', bytes=[73, 110], logprob=-0.0023883758), TopLogprob(token='Sales', bytes=[83, 97, 108, 101, 115], logprob=-7.0336385)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00024631983, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-0.00024631983), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-8.312746)]), ChatCompletionTokenLogprob(token='202', bytes=[50, 48, 50], logprob=-5.5122365e-07, top_logprobs=[TopLogprob(token='202', bytes=[50, 48, 50], logprob=-5.5122365e-07), TopLogprob(token=' ', bytes=[32], logprob=-16.367188)]), ChatCompletionTokenLogprob(token='1', bytes=[49], logprob=-2.8160932e-06, top_logprobs=[TopLogprob(token='1', bytes=[49], logprob=-2.8160932e-06), TopLogprob(token='12', bytes=[49, 50], logprob=-14.250003)]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-7.107425e-06, top_logprobs=[TopLogprob(token=',', bytes=[44], logprob=-7.107425e-06), TopLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-12.187507)]), ChatCompletionTokenLogprob(token=' total', bytes=[32, 116, 111, 116, 97, 108], logprob=-0.2437134, top_logprobs=[TopLogprob(token=' total', bytes=[32, 116, 111, 116, 97, 108], logprob=-0.2437134), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.8062134)]), ChatCompletionTokenLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-1.6524515e-05, top_logprobs=[TopLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-1.6524515e-05), TopLogprob(token=' monthly', bytes=[32, 109, 111, 110, 116, 104, 108, 121], logprob=-11.609391)]), ChatCompletionTokenLogprob(token=' reached', bytes=[32, 114, 101, 97, 99, 104, 101, 100], logprob=-0.260711, top_logprobs=[TopLogprob(token=' reached', bytes=[32, 114, 101, 97, 99, 104, 101, 100], logprob=-0.260711), TopLogprob(token=' across', bytes=[32, 97, 99, 114, 111, 115, 115], logprob=-1.979461)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-6.635165e-05, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-6.635165e-05), TopLogprob(token=' $', bytes=[32, 36], logprob=-9.796942)]), ChatCompletionTokenLogprob(token='200', bytes=[50, 48, 48], logprob=-7.89631e-07, top_logprobs=[TopLogprob(token='200', bytes=[50, 48, 48], logprob=-7.89631e-07), TopLogprob(token='2', bytes=[50], logprob=-14.921876)]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0045524733, top_logprobs=[TopLogprob(token=',', bytes=[44], logprob=-0.0045524733), TopLogprob(token='609', bytes=[54, 48, 57], logprob=-5.3951774)]), ChatCompletionTokenLogprob(token='609', bytes=[54, 48, 57], logprob=-1.3902034e-05, top_logprobs=[TopLogprob(token='609', bytes=[54, 48, 57], logprob=-1.3902034e-05), TopLogprob(token='610', bytes=[54, 49, 48], logprob=-11.187514)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-9.0883464e-07, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-9.0883464e-07), TopLogprob(token=',', bytes=[44], logprob=-14.828126)]), ChatCompletionTokenLogprob(token='99', bytes=[57, 57], logprob=-9.0883464e-07, top_logprobs=[TopLogprob(token='99', bytes=[57, 57], logprob=-9.0883464e-07), TopLogprob(token='9', bytes=[57], logprob=-14.812501)]), ChatCompletionTokenLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-0.3214176, top_logprobs=[TopLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-0.3214176), TopLogprob(token=',', bytes=[44], logprob=-1.6495426)]), ChatCompletionTokenLogprob(token=' AP', bytes=[32, 65, 80], logprob=-0.6826683, top_logprobs=[TopLogprob(token=' AP', bytes=[32, 65, 80], logprob=-0.6826683), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.8232933)]), ChatCompletionTokenLogprob(token='AC', bytes=[65, 67], logprob=0.0, top_logprobs=[TopLogprob(token='AC', bytes=[65, 67], logprob=0.0), TopLogprob(token='ac', bytes=[97, 99], logprob=-18.1875)]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-1.3145672, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-1.3145672), TopLogprob(token=' leading', bytes=[32, 108, 101, 97, 100, 105, 110, 103], logprob=-1.4864422)]), ChatCompletionTokenLogprob(token=' US', bytes=[32, 85, 83], logprob=-0.17976204, top_logprobs=[TopLogprob(token=' US', bytes=[32, 85, 83], logprob=-0.17976204), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.804762)]), ChatCompletionTokenLogprob(token=' markets', bytes=[32, 109, 97, 114, 107, 101, 116, 115], logprob=-0.49757007, top_logprobs=[TopLogprob(token=' markets', bytes=[32, 109, 97, 114, 107, 101, 116, 115], logprob=-0.49757007), TopLogprob(token=' holding', bytes=[32, 104, 111, 108, 100, 105, 110, 103], logprob=-1.81007)]), ChatCompletionTokenLogprob(token=' leading', bytes=[32, 108, 101, 97, 100, 105, 110, 103], logprob=-1.2585311, top_logprobs=[TopLogprob(token=' leading', bytes=[32, 108, 101, 97, 100, 105, 110, 103], logprob=-1.2585311), TopLogprob(token=' holding', bytes=[32, 104, 111, 108, 100, 105, 110, 103], logprob=-1.4147811)]), ChatCompletionTokenLogprob(token=' at', bytes=[32, 97, 116], logprob=-0.44162092, top_logprobs=[TopLogprob(token=' at', bytes=[32, 97, 116], logprob=-0.44162092), TopLogprob(token=',', bytes=[44], logprob=-1.441621)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0067559825, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-0.0067559825), TopLogprob(token=' shares', bytes=[32, 115, 104, 97, 114, 101, 115], logprob=-5.459881)]), ChatCompletionTokenLogprob(token='26', bytes=[50, 54], logprob=-0.02220496, top_logprobs=[TopLogprob(token='26', bytes=[50, 54], logprob=-0.02220496), TopLogprob(token='53', bytes=[53, 51], logprob=-3.8347049)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-3.1281633e-07, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-3.1281633e-07), TopLogprob(token='%', bytes=[37], logprob=-16.484375)]), ChatCompletionTokenLogprob(token='68', bytes=[54, 56], logprob=-1.7432603e-06, top_logprobs=[TopLogprob(token='68', bytes=[54, 56], logprob=-1.7432603e-06), TopLogprob(token='6', bytes=[54], logprob=-14.468752)]), ChatCompletionTokenLogprob(token='%', bytes=[37], logprob=-1.0206721e-05, top_logprobs=[TopLogprob(token='%', bytes=[37], logprob=-1.0206721e-05), TopLogprob(token='%,', bytes=[37, 44], logprob=-11.7500105)]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.0013659506, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.0013659506), TopLogprob(token=' (', bytes=[32, 40], logprob=-6.641991)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-1.0280384e-06, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-1.0280384e-06), TopLogprob(token='23', bytes=[50, 51], logprob=-14.453126)]), ChatCompletionTokenLogprob(token='23', bytes=[50, 51], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='23', bytes=[50, 51], logprob=-1.9361265e-07), TopLogprob(token=' ', bytes=[32], logprob=-15.875)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.9361265e-07, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-1.9361265e-07), TopLogprob(token='-', bytes=[45], logprob=-16.445312)]), ChatCompletionTokenLogprob(token='72', bytes=[55, 50], logprob=-3.0545007e-06, top_logprobs=[TopLogprob(token='72', bytes=[55, 50], logprob=-3.0545007e-06), TopLogprob(token='7', bytes=[55], logprob=-12.968753)]), ChatCompletionTokenLogprob(token='%', bytes=[37], logprob=-0.008956906, top_logprobs=[TopLogprob(token='%', bytes=[37], logprob=-0.008956906), TopLogprob(token='%,', bytes=[37, 44], logprob=-4.727707)]), ChatCompletionTokenLogprob(token=' shares', bytes=[32, 115, 104, 97, 114, 101, 115], logprob=-0.33537763, top_logprobs=[TopLogprob(token=' shares', bytes=[32, 115, 104, 97, 114, 101, 115], logprob=-0.33537763), TopLogprob(token=' share', bytes=[32, 115, 104, 97, 114, 101], logprob=-1.3353777)]), ChatCompletionTokenLogprob(token=' respectively', bytes=[32, 114, 101, 115, 112, 101, 99, 116, 105, 118, 101, 108, 121], logprob=-0.63533604, top_logprobs=[TopLogprob(token=' respectively', bytes=[32, 114, 101, 115, 112, 101, 99, 116, 105, 118, 101, 108, 121], logprob=-0.63533604), TopLogprob(token=',', bytes=[44], logprob=-0.76033604)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.06739325, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.06739325), TopLogprob(token=',', bytes=[44], logprob=-2.8798933)]), ChatCompletionTokenLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.37018445, top_logprobs=[TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.37018445), TopLogprob(token=' Sales', bytes=[32, 83, 97, 108, 101, 115], logprob=-1.4326844)]), ChatCompletionTokenLogprob(token=' latest', bytes=[32, 108, 97, 116, 101, 115, 116], logprob=-0.18411301, top_logprobs=[TopLogprob(token=' latest', bytes=[32, 108, 97, 116, 101, 115, 116], logprob=-0.18411301), TopLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-2.434113)]), ChatCompletionTokenLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-0.715778, top_logprobs=[TopLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-0.715778), TopLogprob(token=' month', bytes=[32, 109, 111, 110, 116, 104], logprob=-1.059528)]), ChatCompletionTokenLogprob(token=' value', bytes=[32, 118, 97, 108, 117, 101], logprob=-0.9297435, top_logprobs=[TopLogprob(token=' value', bytes=[32, 118, 97, 108, 117, 101], logprob=-0.9297435), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-1.5859935)]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.9566589, top_logprobs=[TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.9566589), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-1.0504088)]), ChatCompletionTokenLogprob(token=' December', bytes=[32, 68, 101, 99, 101, 109, 98, 101, 114], logprob=-0.00047821683, top_logprobs=[TopLogprob(token=' December', bytes=[32, 68, 101, 99, 101, 109, 98, 101, 114], logprob=-0.00047821683), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-8.484853)]), ChatCompletionTokenLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-0.50842637, top_logprobs=[TopLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-0.50842637), TopLogprob(token=' ', bytes=[32], logprob=-1.3365514)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0027330746, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-0.0027330746), TopLogprob(token=' highest', bytes=[32, 104, 105, 103, 104, 101, 115, 116], logprob=-7.565233)]), ChatCompletionTokenLogprob(token='535', bytes=[53, 51, 53], logprob=-0.86016273, top_logprobs=[TopLogprob(token='535', bytes=[53, 51, 53], logprob=-0.86016273), TopLogprob(token='53', bytes=[53, 51], logprob=-0.98516273)]), ChatCompletionTokenLogprob(token='14', bytes=[49, 52], logprob=-4.3464544e-05, top_logprobs=[TopLogprob(token='14', bytes=[49, 52], logprob=-4.3464544e-05), TopLogprob(token='.', bytes=[46], logprob=-10.343794)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-8.299462e-06, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-8.299462e-06), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-12.359384)]), ChatCompletionTokenLogprob(token='51', bytes=[53, 49], logprob=-2.2961513e-05, top_logprobs=[TopLogprob(token='51', bytes=[53, 49], logprob=-2.2961513e-05), TopLogprob(token='5', bytes=[53], logprob=-11.140648)]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.06380869, top_logprobs=[TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.06380869), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-2.8138087)]), ChatCompletionTokenLogprob(token=' AP', bytes=[32, 65, 80], logprob=-0.006321101, top_logprobs=[TopLogprob(token=' AP', bytes=[32, 65, 80], logprob=-0.006321101), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-5.068821)]), ChatCompletionTokenLogprob(token='AC', bytes=[65, 67], logprob=-5.5122365e-07, top_logprobs=[TopLogprob(token='AC', bytes=[65, 67], logprob=-5.5122365e-07), TopLogprob(token=' AC', bytes=[32, 65, 67], logprob=-15.062501)]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.09246871, top_logprobs=[TopLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.09246871), TopLogprob(token=',', bytes=[44], logprob=-2.5299687)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00016432605, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-0.00016432605), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-10.312664)]), ChatCompletionTokenLogprob(token='475', bytes=[52, 55, 53], logprob=-0.0091154445, top_logprobs=[TopLogprob(token='475', bytes=[52, 55, 53], logprob=-0.0091154445), TopLogprob(token='270', bytes=[50, 55, 48], logprob=-4.915365)]), ChatCompletionTokenLogprob(token='91', bytes=[57, 49], logprob=-2.8160932e-06, top_logprobs=[TopLogprob(token='91', bytes=[57, 49], logprob=-2.8160932e-06), TopLogprob(token='9', bytes=[57], logprob=-13.343753)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.504853e-06, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-1.504853e-06), TopLogprob(token='-', bytes=[45], logprob=-14.703127)]), ChatCompletionTokenLogprob(token='55', bytes=[53, 53], logprob=-9.4914985e-06, top_logprobs=[TopLogprob(token='55', bytes=[53, 53], logprob=-9.4914985e-06), TopLogprob(token='56', bytes=[53, 54], logprob=-12.828135)]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-6.6113236e-05, top_logprobs=[TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-6.6113236e-05), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-9.703191)]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.5167935, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.5167935), TopLogprob(token=' US', bytes=[32, 85, 83], logprob=-0.9074185)]), ChatCompletionTokenLogprob(token=' US', bytes=[32, 85, 83], logprob=-1.9146995e-05, top_logprobs=[TopLogprob(token=' US', bytes=[32, 85, 83], logprob=-1.9146995e-05), TopLogprob(token=' U', bytes=[32, 85], logprob=-11.265644)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.2701164, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.2701164), TopLogprob(token=' market', bytes=[32, 109, 97, 114, 107, 101, 116], logprob=-1.9732413)]), ChatCompletionTokenLogprob(token=' Canada', bytes=[32, 67, 97, 110, 97, 100, 97], logprob=-0.69222176, top_logprobs=[TopLogprob(token=' Canada', bytes=[32, 67, 97, 110, 97, 100, 97], logprob=-0.69222176), TopLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-1.2078468)]), ChatCompletionTokenLogprob(token=' had', bytes=[32, 104, 97, 100], logprob=-0.2988271, top_logprobs=[TopLogprob(token=' had', bytes=[32, 104, 97, 100], logprob=-0.2988271), TopLogprob(token=' recorded', bytes=[32, 114, 101, 99, 111, 114, 100, 101, 100], logprob=-2.3769522)]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-4.604148e-06, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-4.604148e-06), TopLogprob(token=' a', bytes=[32, 97], logprob=-13.218755)]), ChatCompletionTokenLogprob(token=' lowest', bytes=[32, 108, 111, 119, 101, 115, 116], logprob=-0.0021961716, top_logprobs=[TopLogprob(token=' lowest', bytes=[32, 108, 111, 119, 101, 115, 116], logprob=-0.0021961716), TopLogprob(token=' least', bytes=[32, 108, 101, 97, 115, 116], logprob=-6.2521963)]), ChatCompletionTokenLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-0.005839334, top_logprobs=[TopLogprob(token=' sales', bytes=[32, 115, 97, 108, 101, 115], logprob=-0.005839334), TopLogprob(token=' share', bytes=[32, 115, 104, 97, 114, 101], logprob=-6.0058393)]), ChatCompletionTokenLogprob(token=' at', bytes=[32, 97, 116], logprob=-0.8830034, top_logprobs=[TopLogprob(token=' at', bytes=[32, 97, 116], logprob=-0.8830034), TopLogprob(token=' with', bytes=[32, 119, 105, 116, 104], logprob=-1.4455035)]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0014665347, top_logprobs=[TopLogprob(token=' ', bytes=[32], logprob=-0.0014665347), TopLogprob(token=' just', bytes=[32, 106, 117, 115, 116], logprob=-6.7514668)]), ChatCompletionTokenLogprob(token='270', bytes=[50, 55, 48], logprob=-2.1008714e-06, top_logprobs=[TopLogprob(token='270', bytes=[50, 55, 48], logprob=-2.1008714e-06), TopLogprob(token='27', bytes=[50, 55], logprob=-14.617189)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.3856493e-06, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-1.3856493e-06), TopLogprob(token='6', bytes=[54], logprob=-15.140626)]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-0.0021194504, top_logprobs=[TopLogprob(token='6', bytes=[54], logprob=-0.0021194504), TopLogprob(token='60', bytes=[54, 48], logprob=-6.1583695)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.031612348, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.031612348), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-3.8128624)])]), message=ChatCompletionMessage(content='In 2021, total sales reached 200,609.99 with APAC and US markets leading at 26.68% and 23.72% shares respectively. The latest sales value in December was 53514.51 for APAC and 47591.55 for the US. Canada had the lowest sales at 270.6.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1710764699, model='gpt-4-32k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=72, prompt_tokens=1309, total_tokens=1381), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e27005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2021, total sales reached 200,609.99 with APAC and US markets leading at 26.68% and 23.72% shares respectively. The latest sales value in December was 53514.51 for APAC and 47591.55 for the US. Canada had the lowest sales at 270.6.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a151722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token or the word: In and the probability: -0.0023883758 linear probability: 99.76%\n",
      "Token or the word:   and the probability: -0.00024631983 linear probability: 99.98%\n",
      "Token or the word: 202 and the probability: -5.5122365e-07 linear probability: 100.0%\n",
      "Token or the word: 1 and the probability: -2.8160932e-06 linear probability: 100.0%\n",
      "Token or the word: , and the probability: -7.107425e-06 linear probability: 100.0%\n",
      "Token or the word:  total and the probability: -0.2437134 linear probability: 78.37%\n",
      "Token or the word:  sales and the probability: -1.6524515e-05 linear probability: 100.0%\n",
      "Token or the word:  reached and the probability: -0.260711 linear probability: 77.05%\n",
      "Token or the word:   and the probability: -6.635165e-05 linear probability: 99.99%\n",
      "Token or the word: 200 and the probability: -7.89631e-07 linear probability: 100.0%\n",
      "Token or the word: , and the probability: -0.0045524733 linear probability: 99.55%\n",
      "Token or the word: 609 and the probability: -1.3902034e-05 linear probability: 100.0%\n",
      "Token or the word: . and the probability: -9.0883464e-07 linear probability: 100.0%\n",
      "Token or the word: 99 and the probability: -9.0883464e-07 linear probability: 100.0%\n",
      "Token or the word:  with and the probability: -0.3214176 linear probability: 72.51%\n",
      "Token or the word:  AP and the probability: -0.6826683 linear probability: 50.53%\n",
      "Token or the word: AC and the probability: 0.0 linear probability: 100.0%\n",
      "Token or the word:  and and the probability: -1.3145672 linear probability: 26.86%\n",
      "Token or the word:  US and the probability: -0.17976204 linear probability: 83.55%\n",
      "Token or the word:  markets and the probability: -0.49757007 linear probability: 60.8%\n",
      "Token or the word:  leading and the probability: -1.2585311 linear probability: 28.41%\n",
      "Token or the word:  at and the probability: -0.44162092 linear probability: 64.3%\n",
      "Token or the word:   and the probability: -0.0067559825 linear probability: 99.33%\n",
      "Token or the word: 26 and the probability: -0.02220496 linear probability: 97.8%\n",
      "Token or the word: . and the probability: -3.1281633e-07 linear probability: 100.0%\n",
      "Token or the word: 68 and the probability: -1.7432603e-06 linear probability: 100.0%\n",
      "Token or the word: % and the probability: -1.0206721e-05 linear probability: 100.0%\n",
      "Token or the word:  and and the probability: -0.0013659506 linear probability: 99.86%\n",
      "Token or the word:   and the probability: -1.0280384e-06 linear probability: 100.0%\n",
      "Token or the word: 23 and the probability: -1.9361265e-07 linear probability: 100.0%\n",
      "Token or the word: . and the probability: -1.9361265e-07 linear probability: 100.0%\n",
      "Token or the word: 72 and the probability: -3.0545007e-06 linear probability: 100.0%\n",
      "Token or the word: % and the probability: -0.008956906 linear probability: 99.11%\n",
      "Token or the word:  shares and the probability: -0.33537763 linear probability: 71.51%\n",
      "Token or the word:  respectively and the probability: -0.63533604 linear probability: 52.98%\n",
      "Token or the word: . and the probability: -0.06739325 linear probability: 93.48%\n",
      "Token or the word:  The and the probability: -0.37018445 linear probability: 69.06%\n",
      "Token or the word:  latest and the probability: -0.18411301 linear probability: 83.18%\n",
      "Token or the word:  sales and the probability: -0.715778 linear probability: 48.88%\n",
      "Token or the word:  value and the probability: -0.9297435 linear probability: 39.47%\n",
      "Token or the word:  in and the probability: -0.9566589 linear probability: 38.42%\n",
      "Token or the word:  December and the probability: -0.00047821683 linear probability: 99.95%\n",
      "Token or the word:  was and the probability: -0.50842637 linear probability: 60.14%\n",
      "Token or the word:   and the probability: -0.0027330746 linear probability: 99.73%\n",
      "Token or the word: 535 and the probability: -0.86016273 linear probability: 42.31%\n",
      "Token or the word: 14 and the probability: -4.3464544e-05 linear probability: 100.0%\n",
      "Token or the word: . and the probability: -8.299462e-06 linear probability: 100.0%\n",
      "Token or the word: 51 and the probability: -2.2961513e-05 linear probability: 100.0%\n",
      "Token or the word:  for and the probability: -0.06380869 linear probability: 93.82%\n",
      "Token or the word:  AP and the probability: -0.006321101 linear probability: 99.37%\n",
      "Token or the word: AC and the probability: -5.5122365e-07 linear probability: 100.0%\n",
      "Token or the word:  and and the probability: -0.09246871 linear probability: 91.17%\n",
      "Token or the word:   and the probability: -0.00016432605 linear probability: 99.98%\n",
      "Token or the word: 475 and the probability: -0.0091154445 linear probability: 99.09%\n",
      "Token or the word: 91 and the probability: -2.8160932e-06 linear probability: 100.0%\n",
      "Token or the word: . and the probability: -1.504853e-06 linear probability: 100.0%\n",
      "Token or the word: 55 and the probability: -9.4914985e-06 linear probability: 100.0%\n",
      "Token or the word:  for and the probability: -6.6113236e-05 linear probability: 99.99%\n",
      "Token or the word:  the and the probability: -0.5167935 linear probability: 59.64%\n",
      "Token or the word:  US and the probability: -1.9146995e-05 linear probability: 100.0%\n",
      "Token or the word: . and the probability: -0.2701164 linear probability: 76.33%\n",
      "Token or the word:  Canada and the probability: -0.69222176 linear probability: 50.05%\n",
      "Token or the word:  had and the probability: -0.2988271 linear probability: 74.17%\n",
      "Token or the word:  the and the probability: -4.604148e-06 linear probability: 100.0%\n",
      "Token or the word:  lowest and the probability: -0.0021961716 linear probability: 99.78%\n",
      "Token or the word:  sales and the probability: -0.005839334 linear probability: 99.42%\n",
      "Token or the word:  at and the probability: -0.8830034 linear probability: 41.35%\n",
      "Token or the word:   and the probability: -0.0014665347 linear probability: 99.85%\n",
      "Token or the word: 270 and the probability: -2.1008714e-06 linear probability: 100.0%\n",
      "Token or the word: . and the probability: -1.3856493e-06 linear probability: 100.0%\n",
      "Token or the word: 6 and the probability: -0.0021194504 linear probability: 99.79%\n",
      "Token or the word: . and the probability: -0.031612348 linear probability: 96.89%\n",
      "\n",
      "Confidance probability for the entire response is  86.355 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "final_prob = 0.0\n",
    "token_count = 0\n",
    "for logprob in response.choices[0].logprobs.content:\n",
    "    token_count+=1\n",
    "    final_prob+=np.round(np.exp(logprob.logprob)*100,2)\n",
    "    print(f\"Token or the word: {logprob.token} and the probability: {logprob.logprob} linear probability: {np.round(np.exp(logprob.logprob)*100,2)}%\")\n",
    "print(\"\\nConfidance probability for the entire response is \",final_prob/token_count,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc5baab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken==0.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/62/5d/0adc459426364216cb25eeace411b18f820f11feb945a76a59eed2c67abd/tiktoken-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting openai==1.14.1\n",
      "  Using cached https://files.pythonhosted.org/packages/b3/05/4e1b778f3e261076354148e7716d14b95a279381e0a246e1fa7a5f574732/openai-1.14.1-py3-none-any.whl\n",
      "Collecting requests>=2.26.0\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/10/4ccc8eed80f11c082a2883d49d4090aa80c7f65704216a529f490cb089b1/regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Using cached https://files.pythonhosted.org/packages/14/fd/2f20c40b45e4fb4324834aea24bd4afdf1143390242c0b33774da0e2e34f/anyio-4.3.0-py3-none-any.whl\n",
      "Collecting tqdm>4\n",
      "  Using cached https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Using cached https://files.pythonhosted.org/packages/e5/f3/8296f550276194a58c5500d55b19a27ae0a5a3a51ffef66710c58544b32d/pydantic-2.6.4-py3-none-any.whl\n",
      "Collecting sniffio\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl\n",
      "Collecting typing-extensions<5,>=4.7\n",
      "  Using cached https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/09/d82fe4a34c5f0585f9ea1df090e2a71eb9bb1e469723053e1ee9f57c16f3/charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting exceptiongroup>=1.0.2; python_version < \"3.11\"\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/9a/5028fd52db10e600f1c4674441b968cf2ea4959085bfb5b99fb1250e5f68/exceptiongroup-1.2.0-py3-none-any.whl\n",
      "Collecting httpcore==1.*\n",
      "  Using cached https://files.pythonhosted.org/packages/2c/93/13f25f2f78646bab97aee7680821e30bd85b2ff0fc45d5fdf5393b79716d/httpcore-1.0.4-py3-none-any.whl\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/20/c44de400d4906f75c11e8e447d1dba24ee7273fec02073686af8866f6e38/pydantic_core-2.16.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement urllib3==1.26.15, but you'll have urllib3 2.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-server 2.0.0a1 has requirement anyio<4,>=3.1.0, but you'll have anyio 4.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-auth 2.22.0 has requirement urllib3<2.0, but you'll have urllib3 2.2.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: urllib3, idna, certifi, charset-normalizer, requests, regex, tiktoken, sniffio, typing-extensions, exceptiongroup, anyio, tqdm, h11, httpcore, httpx, distro, annotated-types, pydantic-core, pydantic, openai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.3.0 certifi-2024.2.2 charset-normalizer-3.3.2 distro-1.9.0 exceptiongroup-1.2.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 idna-3.6 openai-1.14.1 pydantic-2.6.4 pydantic-core-2.16.3 regex-2023.12.25 requests-2.31.0 sniffio-1.3.1 tiktoken-0.6.0 tqdm-4.66.2 typing-extensions-4.10.0 urllib3-2.2.1\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sniffio-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tiktoken_ext already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/regex-2023.12.25.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/distro already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/httpx already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/openai-1.14.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/annotated_types already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/h11 already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/typing_extensions-4.10.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tiktoken already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/annotated_types-0.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/distro-1.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tiktoken-0.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/anyio-4.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/sniffio already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi-2024.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/h11-0.14.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pydantic_core-2.16.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/urllib3-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/httpcore already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/httpx-0.27.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm-4.66.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna-3.6.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/regex already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/exceptiongroup already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pydantic-2.6.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pydantic_core already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/openai already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/exceptiongroup-1.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/httpcore-1.0.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/pydantic already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/anyio already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken==0.6.0 openai==1.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee8080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
