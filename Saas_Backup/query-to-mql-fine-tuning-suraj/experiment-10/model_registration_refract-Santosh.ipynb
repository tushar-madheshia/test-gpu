{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfc391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install --upgrade -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb264e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5453fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "# # new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bbd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47d45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# print(json.dumps(payload,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64598c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9eaa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context ={\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "                         \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "                        {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "                        {\"ENTITY\": \"contribution_to_growth\",\n",
    "                         \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"kda_transactional\",\n",
    "                         \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "                        {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "                        {\"ENTITY\": \"correlation\",\n",
    "                         \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\",\n",
    "                                         \"correlated\",\n",
    "                                         \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                                         \"relationship\",\n",
    "                                         \"relationships\"]}\n",
    "                        ],\n",
    "    \"DATE VARIABLE\": [\n",
    "        {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51831cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_loaded = None\n",
    "        self.model_name =\"/data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf\"\n",
    "        self.date_input = {\n",
    "            \"start_date\": \"01/01/2020\",\n",
    "            \"end_date\": \"15/09/2023\"}\n",
    "\n",
    "        self.base_prompt = \"\"\"You are an assistant that helps to map the user question to the context for a question answering system.\n",
    "         You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
    "        Step 1: Identify the n-grams match between question and context\n",
    "        Map the n-gram or their lemma or their inflections from the question with the 'other names' in the passed context.\n",
    "        Always consider the longest n-gram match, not the sub-string.\n",
    "        If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
    "        If you are returning any match which is not exactly present with the 'other names', make sure that it is a noun phrase and there is a high similarity between the match and the matched \"ENTITY\". \n",
    "        Step 2: Applying other conditions\n",
    "        Once the match is identified, next step is to identify other conditions from user question and apply it to the identified matches.\n",
    "        Refer to the following statements to understand about different types of conditions to be applied:\n",
    "            1. METRIC CONSTRAINT : METRIC can be MEASURE or DERIVED MEASURE. User is asking for a comparison limit to be applied on the METRIC. It has two parts: \"COMPARISON VALUE\" is the value applied on a METRIC and \"COMPARSION OPERATOR\" is the operator (in symbols) applied between METRIC and COMPARISON VALUE.\n",
    "            2. ADJECTIVE and TONE : Identify the adjectives (like least, highest performing etc.) applied on the matched ENTITY. TONE is the intent of adjective and it can be postive or negative.\n",
    "            3. EXCEPTION : Excluded FILTER of a DIMENSION asked in question if any. DIMENSION should be the parent of the FILTER. Add a key \"EXCLUDE\" for such excluded FILTERS and set the value as \"True\" in the response.\n",
    "            4. RANK : Rank applied on a DIMENSION if any like top 5, bottom 3 etc. It has two parts: \"RANK ADJECTIVE\", the adjective like top, bottom etc. and \"RANK VALUE\", a number that comes along with the RANK ADJECTIVE, immediately before or after. If there is no explicit RANK VALUE in question, make it as 1. Based on the meaning of the RANK ADJECTIVE, make it as either top or bottom.\n",
    "            5. RATIO FILTERS : This is applicable only for ENTITY \"Ratio\" in DERIVED MEASURE. Identify the FILTER on which Ratio needs to be calculated. Example 1: Question: bike share of sales in area, (where ENTITY of 'bike' is 'Bikes'), RATIO FILTERS = [{'bike': 'Bikes'}]. Example 2: Question: in area, share of bike and cycle basis sales, (where ENTITY of 'Bike' is 'Bikes' and 'cycle' is 'Cycle') RATIO FILTERS = [{'bike': 'Bikes', 'cycle': 'Cycles'}]. If there are no matched FILTERS, then keep RATIO FILTERS = []\"\n",
    "            6. APPLIED MEASURES: This is applicable only for DERIVED MEASURE. Identify the MEASURE on which the DERIVED MEASURE needs to be calculated. \n",
    "\n",
    "            Step 3: Applying time tagger rules only if time elements are present in question\n",
    "\n",
    "            Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
    "            TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
    "            Calculate date range for each time points based on the following conditions:\n",
    "            1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: \"\"\" '\\n' + str(\n",
    "            self.date_input) + '\\n' \"\"\"\n",
    "            2. To calculate the date range for \"last X years\", strictly follow the below conditions:\n",
    "                    For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
    "                    For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
    "            3. To calculate the date range for \"last X months\", strictly follow the below conditions:\n",
    "                    Consider the reference month as the month in reference date\n",
    "                    For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month .\n",
    "                    For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
    "            4. To calculate the date range for \"last X quarters\", strictly follow the below conditions:\n",
    "                    For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
    "                    For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
    "            5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
    "                    For \"last 1 week\", consider exactly one week before the reference week and set start date as Monday and end date as Sunday of that week .\n",
    "                    For \"last X weeks\", where X is greater than 1, consider starting week = (reference week - X+1) and set start date as Monday of starting week and end date as the reference date.\n",
    "            6. Provide the date range of each time point in start date - end date format always.\n",
    "\n",
    "            Step 4: Creating the response JSON\n",
    "            Strictly return the response in the exact same JSON format as follows. \n",
    "            Fill the information identified from above steps in the JSON. \n",
    "            The keys mentioned in upper case in the response are constant.\n",
    "            Return only if match is found from the context and non empty values are present.\n",
    "            Replace the placeholders \"<>\" with your findings.\n",
    "            {\n",
    "                \"MEASURE\": {\n",
    "                    \"<n-gram matched to MEASURE>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched MEASURE>\",\n",
    "                            \"MEASURE CONSTRAINT\": [\n",
    "                                {\n",
    "                                    \"COMPARISON VALUE\": \"\",\n",
    "                                    \"COMPARSION OPERATOR\": \"\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DIMENSION\": {\n",
    "                    \"<n-gram matched to DIMENSION>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched DIMENSION>\",\n",
    "                            \"RANK\": [{\"RANK ADJECTIVE\":\"\", \"RANK VALUE\": \"\"}],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"FILTER\": {\n",
    "                    \"<n-gram matched to FILTER>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched FILTER>\",\n",
    "                            \"PARENT\": \"<parent of the Matched FILTER>\",\n",
    "                            \"EXCLUDE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DERIVED MEASURE\": {\n",
    "                    \"<n-gram matched to DERIVED MEASURE>\": [\n",
    "                        {\n",
    "                            \"ENTITY\": \"<Matched DERIVED MEASURE>\",\n",
    "                            \"RATIO FILTER\": [{}],\n",
    "                            \"APPLIED MEASURE\": [{\"<n-gram matched to MEASURE>\": \"<Matched MEASURE>\"}],\n",
    "                            \"DERIVED MEASURE CONSTRAINT\": [\n",
    "                                {\n",
    "                                    \"COMPARISON VALUE\": \"\",\n",
    "                                    \"COMPARSION OPERATOR\": \"\"\n",
    "                                }\n",
    "                            ],\n",
    "                            \"ADJECTIVE\": [],\n",
    "                            \"TONE\": \"\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"DATE VARIABLE\": {\n",
    "                    \"asked time element\": [{\"ENTITY\": \"<Matched DATE VARIABLE>\"\n",
    "                        \"DATE RANGE\": \"date range\",\n",
    "                        \"CONVERTED TIME ELEMENT\": \"<converted time element>\"\n",
    "                        }]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            Provide reasoning\n",
    "            \"\"\"\n",
    "        from transformers import pipeline\n",
    "        import time\n",
    "        import torch\n",
    "        from huggingface_hub.utils import disable_progress_bars\n",
    "        disable_progress_bars()\n",
    "        if self.model_loaded is None:\n",
    "            print(\"LLM model loading Open_Chat_3_5\")\n",
    "            self.model_loaded = pipeline(\"text-generation\", model= self.model_name, torch_dtype=torch.bfloat16, device_map=\"auto\",model_kwargs={\"offload_folder\":\"offload\"})\n",
    "            \n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[{\"question\": \"\",\"context\":\"\"},{\"question\": \"\",\"context\":\"\"},...]\n",
    "\n",
    "        :return: (n_inputs, payload's)\n",
    "\n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (len(raw_payload), raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        return payload\n",
    "\n",
    "    \n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      input_query\n",
    "                       ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "        question = input_query[\"question\"]\n",
    "        context = input_query[\"context\"]\n",
    "        query = \"\"\"Now Based on this following context: \\n \"\"\"+ str(context) + \"\\n return a response for this question:\\n\" + question + \"\\n\"\n",
    "        prompt = f\"\"\"<s>[IDENTITY]\n",
    "                    {self.base_prompt}\n",
    "                    [/IDENTITY]</s>\n",
    "                    [INST]\n",
    "                    {query}\n",
    "                    [/INST]\n",
    "                    \"\"\"\n",
    "        print(\"Prompting has started\")\n",
    "        start = time.time()\n",
    "        response = self.model_loaded(prompt, max_new_tokens=1024*4)#.to(\"cuda\")\n",
    "        print(f\"Total time taken = {time.time()-start}\")\n",
    "        response = response[0][\"generated_text\"]\n",
    "        preds = response.split(\"[SOL]\")[-1].split(\"[/SOL]\")[0]\n",
    "        print(\"prediction is \\n: \",preds)\n",
    "        return [preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f40d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM model loading Open_Chat_3_5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163f8b9ba33640cb816c32d37a3025a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc341beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "Prompting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"Quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Quantity\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"Segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Segment\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"Sub-Category\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Sub-Category\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"bottom\",\n",
      "                                            \"RANK VALUE\": \"3\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": [],\n",
      "                        \"DERIVED MEASURE\": [],\n",
      "                        \"DATE VARIABLE\": {\n",
      "                            \"Order Date\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"Order Date\",\n",
      "                                    \"DATE RANGE\": \"date range\",\n",
      "                                    \"CONVERTED TIME ELEMENT\": \"date range\"\n",
      "                                }\n",
      "                            ]\n",
      "                        }\n",
      "                    }\n",
      "                    \n",
      "CPU times: user 40min 41s, sys: 1min, total: 41min 42s\n",
      "Wall time: 5min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc61fc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "promting has started\n",
      "prediction is \n",
      ":  \n",
      "                    {\n",
      "                        \"MEASURE\": {\n",
      "                            \"segment\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"segments\",\n",
      "                                    \"MEASURE CONSTRAINT\": [\n",
      "                                        {\n",
      "                                            \"COMPARISON VALUE\": \"\",\n",
      "                                            \"COMPARSION OPERATOR\": \"\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"DIMENSION\": {\n",
      "                            \"quantity\": [\n",
      "                                {\n",
      "                                    \"ENTITY\": \"quantity\",\n",
      "                                    \"RANK\": [\n",
      "                                        {\n",
      "                                            \"RANK ADJECTIVE\": \"top\",\n",
      "                                            \"RANK VALUE\": \"2\"\n",
      "                                        }\n",
      "                                    ],\n",
      "                                    \"ADJECTIVE\": [],\n",
      "                                    \"TONE\": \"\"\n",
      "                                }\n",
      "                            ]\n",
      "                        },\n",
      "                        \"FILTER\": {},\n",
      "                        \"DERIVED MEASURE\": {},\n",
      "                        \"DATE VARIABLE\": {}\n",
      "                    }\n",
      "                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "req = requests.Request()\n",
    "req.json = {\"payload\":[{\"question\":\"top 2 segments basis quantity\",\"context\":context}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e3b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"/data/huggingface/cache/models--openchat--openchat_3.5/snapshots/2d39b2e68fc16446e1760700e0de14721434cbbf\"\n",
    "#model=score_.model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4590e224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PASS:: Mandatory Validation :: dict_keys(['name', 'description', 'flavour', 'scoring_func'])\n",
      "INFO:root:PASS:: AlphaNumeric Validation :: dict_keys(['name'])\n",
      "INFO:root:PASS:: Validation/IfPresentTypeCheck :: dict_keys(['schema', 'metadata_info', 'tags'])\n",
      "INFO:root:PASS:: Validation/IfPresentSubfieldMustExist :: dict_keys(['kyd'])\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"POST /registry/api/v1/ml-model/register HTTP/1.1\" 200 2119\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/c7570892-a4e2-40a6-8ca0-94eed8dea3c6 HTTP/1.1\" 200 2112\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/c7570892-a4e2-40a6-8ca0-94eed8dea3c6 HTTP/1.1\" 200 2112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada7acee67eb4cd4b616074d2399ff19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(model,\n",
    "               ScoreTemplateExample2,\n",
    "               \"Open_Chat_iMQL_Generator_for_GPU\",\n",
    "               \"IMQL_Generator_using_open_chat_3_5_for_GPU\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"\"\"sudo chmod -R 777 /home/mosaic-ai/.cache\\\\npip install torch \\\\npip install --upgrade transformers\\\\npip install accelerate\"\"\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
