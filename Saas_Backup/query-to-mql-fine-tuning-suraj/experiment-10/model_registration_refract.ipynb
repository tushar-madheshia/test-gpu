{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bfc391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install --upgrade -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5453fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "# # new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bbd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\"context\":{\n",
    "#     \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "#                 {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "#                 {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "#                 {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "#     \"DATE VARIABLE\": [\n",
    "#         {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "# }}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47d45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# print(json.dumps(payload,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64598c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context ={\n",
    "#     \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "#                 {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "#                 {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "#                 {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "#     \"DATE VARIABLE\": [\n",
    "#         {\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9eaa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a6d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51831cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreTemplateExample(ScoreBase):\n",
    "    \"\"\"\n",
    "    This Class Demonstrate How To Implements ScoreBase Interface Class And It Basic Usage.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_loaded = None\n",
    "        self.model_name =\"/data/mistral/query-to-mql/exp-10/nov-20/merged-model\"\n",
    "        self.date_input = {\n",
    "            \"start_date\": \"01/01/2020\",\n",
    "            \"end_date\": \"15/09/2023\"}\n",
    "\n",
    "        from transformers import pipeline\n",
    "        import time\n",
    "        import torch\n",
    "        from huggingface_hub.utils import disable_progress_bars\n",
    "        disable_progress_bars()\n",
    "        if self.model_loaded is None:\n",
    "            print(\"Loading mistral fine tuned model\")\n",
    "            self.model_loaded = pipeline(\"text-generation\", model= self.model_name, torch_dtype=torch.bfloat16, device_map=\"auto\",model_kwargs={\"offload_folder\":\"offload\"})\n",
    "            \n",
    "    def request_processing_fn(self, request) :\n",
    "        \"\"\"\n",
    "        Processes Request Object -> List[{\"question\": \"\",\"context\":\"\"},{\"question\": \"\",\"context\":\"\"},...]\n",
    "\n",
    "        :return: (n_inputs, payload's)\n",
    "\n",
    "        Warnings:\n",
    "        1. Do not reshape your final output for single sample here, do it in prediction.\n",
    "           Else payloads will be invalidated for extraction at raw and extraction level.\n",
    "        \"\"\"\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (len(raw_payload), raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        return payload\n",
    "\n",
    "    \n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      input_query\n",
    "                       ):\n",
    "        \"\"\"\n",
    "                Does the main prediction on pre_processed_input(Single Sample) using supplied model .\n",
    "\n",
    "                :param model: Supported Model\n",
    "                :param pre_processed_input: Single Preprocessed Payload\n",
    "                :return: Prediction Value From the model\n",
    "                \n",
    "                Important Notes:\n",
    "                - Reshape your data array.reshape(1, -1) before predictions as it contains a single sample.\n",
    "                    \n",
    "        \"\"\"\n",
    "        user_query = input_query[\"question\"]\n",
    "        context = input_query[\"context\"]\n",
    "        date_input = input_query[\"date_input\"]\n",
    "        prompt = f\"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\"\"\"\n",
    "        print(\"prompting has started\")\n",
    "        start = time.time()\n",
    "        response = self.model_loaded(prompt, max_new_tokens=1000)#.to(\"cuda\")\n",
    "        print(f\"Total time taken = {time.time()-start}\")\n",
    "        response = response[0][\"generated_text\"]\n",
    "        output = response.split('[MQL]\\n')[1]\n",
    "        preds =  output.split('\\n[/MQL]')[0]\n",
    "        print(\"prediction is \\n: \",preds)\n",
    "        return [preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7f40d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmph1388wq7\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmph1388wq7/_remote_module_non_scriptable.py\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/notebooks/notebooks/query-to-mql-fine-tuning-suraj/experiment-10, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/notebooks/notebooks/query-to-mql-fine-tuning-suraj/experiment-10, universal_newlines=False, shell=None, istream=None)\n",
      "DEBUG:wandb.docker.auth:Trying paths: ['/home/mosaic-ai/.docker/config.json', '/home/mosaic-ai/.dockercfg']\n",
      "DEBUG:wandb.docker.auth:No config file found\n",
      "DEBUG:sentry_sdk.errors:[Tracing] Create new propagation context: {'trace_id': '16b959ac9edf4e9492d314d1d3ee99ca', 'span_id': 'b041fdfeaf8ac742', 'parent_span_id': None, 'dynamic_sampling_context': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mistral fine tuned model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbafd976819a44dc96cd2a8cf3393692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_ = ScoreTemplateExample()\n",
    "req = requests.Request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd9c8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554addb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "prompting has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2574: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken = 66.65761876106262\n",
      "prediction is \n",
      ":  {'DIMENSION': {'segments': [{'ENTITY': 'Segment', 'RANK': [{'RANK ADJECTIVE': 'top', 'RANK VALUE': '2'}]}],'sub-category': [{'ENTITY': 'Sub-Category', 'RANK': [{'RANK ADJECTIVE': 'bottom', 'RANK VALUE': '3'}]}], 'MEASURE': {'quantity': [{'ENTITY': 'Quantity'}]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<<ScoreResponse>>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.json = {\"payload\":[{\"question\":\"top 2 segments and bottom 3 sub-category basis quantity\",\n",
    "                        \"context\":context,\n",
    "                       \"date_input\":date_input}]}\n",
    "score_.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61fc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"/data/mistral/query-to-mql/exp-10/nov-20/merged-model\"\n",
    "#model=score_.model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4590e224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PASS:: Mandatory Validation :: dict_keys(['name', 'description', 'flavour', 'scoring_func'])\n",
      "INFO:root:PASS:: AlphaNumeric Validation :: dict_keys(['name'])\n",
      "INFO:root:PASS:: Validation/IfPresentTypeCheck :: dict_keys(['schema', 'metadata_info', 'tags'])\n",
      "INFO:root:PASS:: Validation/IfPresentSubfieldMustExist :: dict_keys(['kyd'])\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"POST /registry/api/v1/ml-model/register HTTP/1.1\" 200 2109\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/dac5ac34-1c6f-4251-8f4a-0de379fcc957 HTTP/1.1\" 200 2102\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): mosaic-ai-backend:5000\n",
      "DEBUG:urllib3.connectionpool:http://mosaic-ai-backend:5000 \"GET /registry/api/v1/ml-model/dac5ac34-1c6f-4251-8f4a-0de379fcc957 HTTP/1.1\" 200 2102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f34d7d9a0944c2199d0faef031e7795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "register_model(model,\n",
    "               ScoreTemplateExample,\n",
    "               \"Mistral_fine_tuned_for_query_to_iMQL\",\n",
    "               \"Mistral_fine_tuned_for_query_to_iMQL\",\n",
    "               MLModelFlavours.pytorch,\n",
    "               init_script=\"\"\"sudo chmod -R 777 /home/mosaic-ai/.cache\\\\npip install torch \\\\npip install --upgrade transformers\\\\npip install accelerate\"\"\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
