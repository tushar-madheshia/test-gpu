{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc95442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo -H pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c4a3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autoawq==0.1.7+cu118\n",
      "\u001b[?25l  Downloading https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp38-cp38-linux_x86_64.whl (20.0MB)\n",
      "\u001b[K     |████████████████████████████████| 20.0MB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl\n",
      "Collecting lm-eval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/c5/bff92e6b61fc2b0c1b7ac769633731910152e5176a404912ce7c07329ba0/lm_eval-0.3.0-py3-none-any.whl (178kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 18.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.35.0 in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (4.35.2)\n",
      "Requirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (2.0.1)\n",
      "Collecting toml\n",
      "  Downloading https://files.pythonhosted.org/packages/44/6f/7120676b6d73228c96e17f1f794d8ab046fc910d781c8d151120c3f1569e/toml-0.10.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.21.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.15.2)\n",
      "Collecting attributedict\n",
      "  Downloading https://files.pythonhosted.org/packages/de/db/337b36e8d85a07293f5a792644fa972b53a52b13587f484c627009206697/attributedict-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (4.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.15.0)\n",
      "Collecting texttable\n",
      "  Downloading https://files.pythonhosted.org/packages/24/99/4772b8e00a136f3e01236de33b0efda31ee7077203ba5967fcc76da94d65/texttable-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.1.99)\n",
      "Collecting jsonlines\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (0.19.0)\n",
      "Collecting numexpr\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/47/a2ede0e136a8ddc288b447c260aa035f3e75251f808aa61f6454b16dfd04/numexpr-2.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 119.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (2.14.4)\n",
      "Collecting pytablewriter\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/74/b39b823ee7dba155b117634e62733a0dfdfe5aa100a553b435062cee2062/pytablewriter-1.2.0-py3-none-any.whl (111kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 112.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rouge-score>=0.0.4\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/c5/9136736c37022a6ad27fea38f3111eb8f02fe75d067f9a985cc358653102/rouge_score-0.1.2.tar.gz\n",
      "Collecting openai>=0.6.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/d3/309769dad11d5f75b81c7252d9dc849ed440d0921215e759af169054f3b6/openai-1.3.7-py3-none-any.whl (221kB)\n",
      "\u001b[K     |████████████████████████████████| 225kB 108.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict\n",
      "  Downloading https://files.pythonhosted.org/packages/12/9a/7620d1e9dcb02839ed6d4b14064e609cdd7a8ae1e47289aa0456796dd9ca/sqlitedict-2.1.0.tar.gz\n",
      "Collecting tqdm-multiprocess\n",
      "  Downloading https://files.pythonhosted.org/packages/25/7e/0d889fc6c84e3df6b69aaafe893fc77f69b3d968ac9ce574d1c62c688050/tqdm_multiprocess-0.0.11-py3-none-any.whl\n",
      "Collecting sacrebleu==1.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/7f/4fd83db8570288c3899d8e57666c2841403c15659f3d792a3cb8dc1c6689/sacrebleu-1.5.0-py3-none-any.whl (65kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 40.2MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (1.3.0)\n",
      "Collecting pycountry\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/24/033604d30f6cf82d661c0f9dfc2c71d52cafc2de516616f80d3b0600cb7c/pycountry-22.3.5.tar.gz (10.1MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1MB 112.6MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.6.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl (227kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 99.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (1.21.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (2.29.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (0.16.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (0.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (2023.8.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.101)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (10.2.10.91)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (3.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.4.91)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (4.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.99)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate->autoawq==0.1.7+cu118) (5.9.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->autoawq==0.1.7+cu118) (10.0.0)\n",
      "Collecting tox>=3.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/88/de28a027acdb3a1b070a8acdff62bd23fdc23ce32acc7ac4b92b088979a4/tox-4.11.4-py3-none-any.whl (153kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 120.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting codecov>=2.0.15\n",
      "  Downloading https://files.pythonhosted.org/packages/af/02/18785edcdf6266cdd6c6dc7635f1cbeefd9a5b4c3bb8aff8bd681e9dd095/codecov-2.1.13-py2.py3-none-any.whl\n",
      "Collecting deepdiff>=3.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/8f/a9d39ec15f40e8169cb134317824ee4618b864b2e4b91a9b310d3ef94729/deepdiff-6.7.1-py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 46.0MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting inspecta>=0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/03/aa/5ad8e223fa564d474b465771710b8b7b23896b59651cf115f510bcfda3ee/inspecta-0.1.3-py3-none-any.whl\n",
      "Collecting coverage>=4.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/1a/e4d0775502fae6ce2c2dd3692a66aff3b18e89757567e35680b9c63d89c5/coverage-7.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 109.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rootpath>=0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/f9/959835686c78b7a95d8d806a97fa0be020c2deccb96de2b60659744319b9/rootpath-0.1.1-py3-none-any.whl\n",
      "Collecting colour-runner>=0.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/82/ce3250026add1910739dcabc796571ad1d182cb47332716c8bb96ee5d624/colour_runner-0.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.8/site-packages (from jsonlines->lm-eval->autoawq==0.1.7+cu118) (23.1.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (3.8.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (0.70.15)\n",
      "Collecting mbstrdecoder<2,>=1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/0f/726229136022b154895138bb10ba35e8435c4143f614cb5ad4d4e3fc21ec/mbstrdecoder-1.1.3-py3-none-any.whl\n",
      "Collecting typepy[datetime]<2,>=1.3.2\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/10/0d6dc654bb4e0eca017bbaf43a315b464c888576a68a2883cd4a74bd1b6b/typepy-1.3.2-py3-none-any.whl\n",
      "Collecting DataProperty<2,>=1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/b1/3b/90ebd66ad57c588d6087e86e327436343e9cc60776a9445b79c6e80a022d/DataProperty-1.0.1-py3-none-any.whl\n",
      "Collecting tabledata<2,>=1.3.1\n",
      "  Downloading https://files.pythonhosted.org/packages/06/e2/96b10ebc00d20b55967200e3d95c2137d91f58af1af672627683431c9d5c/tabledata-1.3.3-py3-none-any.whl\n",
      "Collecting pathvalidate<4,>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/ab/673cce13ab635fd755d206b18c0a371ef6e28ddbe25fadba9ae6c59f22a5/pathvalidate-3.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.8/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7+cu118) (67.8.0)\n",
      "Collecting tcolorpy<1,>=0.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/34/d0/8a701df46bf546fd155da02934b0bb2ac6ad4186e29f4a3297e744ab259d/tcolorpy-0.1.4-py3-none-any.whl\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.8/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq==0.1.7+cu118) (1.4.0)\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 105.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.8/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq==0.1.7+cu118) (1.16.0)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/2b/64066de1c4cf3d4ed623beeb3bbf3f8d0cc26661f1e7d180ec5eb66b75a5/pydantic-2.5.2-py3-none-any.whl (381kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 113.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/2c/c90a3adaf0ddb70afe193f5ebfb539612af57cffe677c3126be533df3098/distro-1.8.0-py3-none-any.whl\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /opt/conda/lib/python3.8/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7+cu118) (3.7.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.8/site-packages (from openai>=0.6.4->lm-eval->autoawq==0.1.7+cu118) (1.3.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/65/6940eeb21dcb2953778a6895281c179efd9100463ff08cb6232bb6480da7/httpx-0.25.2-py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 40.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl\n",
      "Collecting portalocker\n",
      "  Downloading https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7+cu118) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7+cu118) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7+cu118) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7+cu118) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7+cu118) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7+cu118) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers>=4.35.0->autoawq==0.1.7+cu118) (2023.5.7)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=2.0.1->autoawq==0.1.7+cu118) (0.38.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=2.0.1->autoawq==0.1.7+cu118) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=2.0.1->autoawq==0.1.7+cu118) (2.1.3)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=2.0.1->autoawq==0.1.7+cu118) (16.0.6)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=2.0.1->autoawq==0.1.7+cu118) (3.27.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet>=5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl (199kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 114.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting platformdirs>=3.10\n",
      "  Downloading https://files.pythonhosted.org/packages/be/53/42fe5eab4a09d251a76d0043e018172db324a23fcdac70f77a551c11f618/platformdirs-4.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: cachetools>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7+cu118) (5.3.1)\n",
      "Collecting tomli>=2.0.1; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/97/75/10a9ebee3fd790d20926a90a2547f0bf78f371b2f13aa822c759680ca7b9/tomli-2.0.1-py3-none-any.whl\n",
      "Collecting pyproject-api>=1.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/b4/39eea50542e50e93876ebc09c4349a9c9eee9f6b9c9d30f88c7dc5433db8/pyproject_api-1.6.1-py3-none-any.whl\n",
      "Collecting pluggy>=1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/05/b8/42ed91898d4784546c5f06c60506400548db3f7a4b3fb441cba4e5c17952/pluggy-1.3.0-py3-none-any.whl\n",
      "Collecting virtualenv>=20.24.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/22/54b1180756d2d6194bcafb7425d437c3034c4bff92129c3e1e633079e2c4/virtualenv-20.25.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 100.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading https://files.pythonhosted.org/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: pygments>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from inspecta>=0.1.0->attributedict->autoawq==0.1.7+cu118) (2.15.1)\n",
      "Collecting coloredlogs>=10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 30.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blessings\n",
      "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (1.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2023.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk->rouge-score>=0.0.4->lm-eval->autoawq==0.1.7+cu118) (8.1.7)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl\n",
      "Collecting pydantic-core==2.14.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/95/d1104b88d5e3ad42db30935a4c258da2385139dd216ec8dfbc347a32dbff/pydantic_core-2.14.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 103.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup; python_version < \"3.11\" in /opt/conda/lib/python3.8/site-packages (from anyio<4,>=3.5.0->openai>=0.6.4->lm-eval->autoawq==0.1.7+cu118) (1.1.1)\n",
      "Collecting httpcore==1.*\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 44.5MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting distlib<1,>=0.3.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/a0/9ba967fdbd55293bacfc1507f58e316f740a3b231fc00e3d86dc39bc185a/distlib-0.3.7-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 100.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 45.1MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 36.4MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pycountry\n",
      "  Building wheel for pycountry (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycountry: filename=pycountry-22.3.5-cp38-none-any.whl size=10681832 sha256=decbe8667433023abab9c13e0a945a0d4913b9aaeffd161359d0619d6d9c629f\n",
      "  Stored in directory: /root/.cache/pip/wheels/7a/c3/f8/3e164430062ee08d5b8bc8fcd1b891ce54c7ad99871aa3adc1\n",
      "Successfully built pycountry\n",
      "Building wheels for collected packages: rouge-score, sqlitedict\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-cp38-none-any.whl size=24937 sha256=1353faf1b3ca986c571b79d2bb30aa6a3876f08fa47f179aa01d02cf226c2641\n",
      "  Stored in directory: /root/.cache/pip/wheels/df/aa/59/74f33db3bbedf322bcaadca4a43750ea5eb523bbe742d78b25\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-cp38-none-any.whl size=16865 sha256=5eb49e0649e193a50e9550f4f0cf2f705553fd566e6ba07bbe06f3efb66322f2\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/10/02/9725042cf8a987b45e38bcfb106f4b0cdcc9d8968e248b93e1\n",
      "Successfully built rouge-score sqlitedict\n",
      "\u001b[31mERROR: pydantic-core 2.14.5 has requirement typing-extensions!=4.7.0,>=4.6.0, but you'll have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pydantic 2.5.2 has requirement typing-extensions>=4.6.1, but you'll have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: openai 1.3.7 has requirement typing-extensions<5,>=4.5, but you'll have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pyproject-api 1.6.1 has requirement packaging>=23.1, but you'll have packaging 23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tox 4.11.4 has requirement filelock>=3.12.3, but you'll have filelock 3.12.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tox 4.11.4 has requirement packaging>=23.1, but you'll have packaging 23.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tabulate, jsonlines, numexpr, chardet, mbstrdecoder, typepy, DataProperty, tabledata, pathvalidate, tcolorpy, pytablewriter, nltk, rouge-score, annotated-types, pydantic-core, pydantic, distro, h11, httpcore, httpx, openai, sqlitedict, colorama, tqdm-multiprocess, portalocker, sacrebleu, pycountry, pybind11, lm-eval, toml, platformdirs, tomli, pyproject-api, pluggy, distlib, virtualenv, tox, coverage, codecov, ordered-set, deepdiff, termcolor, humanfriendly, coloredlogs, blessings, colour-runner, rootpath, inspecta, attributedict, texttable, autoawq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found existing installation: platformdirs 3.6.0\n",
      "    Uninstalling platformdirs-3.6.0:\n",
      "      Successfully uninstalled platformdirs-3.6.0\n",
      "  Found existing installation: pluggy 1.0.0\n",
      "    Uninstalling pluggy-1.0.0:\n",
      "      Successfully uninstalled pluggy-1.0.0\n",
      "Successfully installed DataProperty-1.0.1 annotated-types-0.6.0 attributedict-0.3.0 autoawq-0.1.7+cu118 blessings-1.7 chardet-5.2.0 codecov-2.1.13 colorama-0.4.6 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.3.2 deepdiff-6.7.1 distlib-0.3.7 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 humanfriendly-10.0 inspecta-0.1.3 jsonlines-4.0.0 lm-eval-0.3.0 mbstrdecoder-1.1.3 nltk-3.8.1 numexpr-2.8.6 openai-1.3.7 ordered-set-4.1.0 pathvalidate-3.2.0 platformdirs-4.1.0 pluggy-1.3.0 portalocker-2.8.2 pybind11-2.11.1 pycountry-22.3.5 pydantic-2.5.2 pydantic-core-2.14.5 pyproject-api-1.6.1 pytablewriter-1.2.0 rootpath-0.1.1 rouge-score-0.1.2 sacrebleu-1.5.0 sqlitedict-2.1.0 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.4 termcolor-2.4.0 texttable-1.7.0 toml-0.10.2 tomli-2.0.1 tox-4.11.4 tqdm-multiprocess-0.0.11 typepy-1.3.2 virtualenv-20.25.0\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29fd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac0ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "603676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684c1b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvidia-cuda-cupti-cu11   11.7.101  \r\n",
      "nvidia-cuda-nvrtc-cu11   11.7.99   \r\n",
      "nvidia-cuda-runtime-cu11 11.7.99   \r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb53d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffccfab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aee117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/mistral/query-to-mql/exp-10/nov-20/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c42249",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_path = '/data/mistral/query-to-mql/exp-10/nov-20/quant-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89d01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = {\"zero_point\":True,\n",
    "               \"q_group_size\": 1024,\n",
    "               \"w_bit\": 4,\n",
    "               \"version\": \"GEMM\"\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f853010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a7ccddaaf9427fa23569bc00b89555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load model\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path, **{\"low_cpu_mem_usage\":True})\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path, safetensors=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50621ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48e2dc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e389fe9e060482783bede01a6d08585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcd14836ec94e309d0945cd5f656cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f850a771d84ac68f2f52771c449093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dc0535bbcf49ed84da787e6eac462d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b2f01dd43849bf85777955132db673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AWQ:   0%|          | 0/32 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 520.00 MiB (GPU 0; 15.60 GiB total capacity; 14.51 GiB already allocated; 370.94 MiB free; 14.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Quantize\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/awq/models/base.py:53\u001b[0m, in \u001b[0;36mBaseAWQForCausalLM.quantize\u001b[0;34m(self, tokenizer, quant_config, calib_data, split, text_column)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config: AwqConfig \u001b[38;5;241m=\u001b[39m AwqConfig\u001b[38;5;241m.\u001b[39mfrom_dict(quant_config)\n\u001b[1;32m     49\u001b[0m quantizer \u001b[38;5;241m=\u001b[39m AwqQuantizer(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, tokenizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mw_bit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mq_group_size,\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_config\u001b[38;5;241m.\u001b[39mversion, calib_data, split, text_column\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 53\u001b[0m \u001b[43mquantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/awq/quantize/quantizer.py:82\u001b[0m, in \u001b[0;36mAwqQuantizer.quantize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# [STEP 1]: Get layer, extract linear modules, extract input features\u001b[39;00m\n\u001b[1;32m     81\u001b[0m named_linears \u001b[38;5;241m=\u001b[39m get_named_linears(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules[i])\n\u001b[0;32m---> 82\u001b[0m input_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_input_feat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamed_linears\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m clear_memory()\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# [STEP 2]: Compute and apply scale list\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/awq/quantize/quantizer.py:362\u001b[0m, in \u001b[0;36mAwqQuantizer._get_input_feat\u001b[0;34m(self, layer, named_linears)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minps\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mnext\u001b[39m(layer\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# in case multi-gpu\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# get output as next layer's input\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minps \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m handles:\n\u001b[1;32m    364\u001b[0m     h\u001b[38;5;241m.\u001b[39mremove()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/mistral/modeling_mistral.py:623\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    621\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 623\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    626\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    627\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    628\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    633\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/mistral/modeling_mistral.py:84\u001b[0m, in \u001b[0;36mMistralRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     82\u001b[0m input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     83\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 84\u001b[0m variance \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 520.00 MiB (GPU 0; 15.60 GiB total capacity; 14.51 GiB already allocated; 370.94 MiB free; 14.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#Quantize\n",
    "\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9252d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb126257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
