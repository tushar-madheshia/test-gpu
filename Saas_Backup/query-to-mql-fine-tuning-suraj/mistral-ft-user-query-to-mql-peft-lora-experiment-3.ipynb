{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06dcc636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b437fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.34.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7ece4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install -q accelerate peft==0.4.0 bitsandbytes trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02bb11f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/mistral/query-to-mql/Live_Usage_queries_with_mql_formatted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219fed17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'mql', 'account_id', 'metadata', 'measure', 'dimension',\n",
       "       'derived_measure', 'date', 'measure_mql', 'dimension_mql', 'action_mql',\n",
       "       'date_mql', 'measure_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8070e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17334, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a2a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e065f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575c9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9666f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = torch.randint(0,df.shape[0],(train_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41714ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[['query','measure_new','measure_mql']].iloc[rows.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699e8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df[['query','measure_new','measure_mql']].drop(rows.tolist())\n",
    "val_df = val_df[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d56f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 3), (1000, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de7a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('val_df_query_to_mql.csv', index=True)\n",
    "train_df.to_csv('train_df_query_to_mql.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9060e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_df_query_to_mql.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6b4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37f45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "#dataset_name = \"\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "#new_model = \"mistral-ft-peft-on-template_and_user_query-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2ceeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f83e1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b95b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"/data/mistral/query-to-mql/0ct-25\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 15\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "# fp16 = False\n",
    "fp16 = True # not using quantisation\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine)\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = 1000\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 50\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd83a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36063e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template_measure = \"\"\"<s>[INST]<<SYS>>\n",
    "Given the CONTEXT:{context}, convert the 'user query' into JSON format which captures basic measures asked by user and maps it to CONTEXT.\n",
    "\n",
    "<</SYS>>\n",
    "User query : {user_query}\n",
    "\n",
    "Converted JSON is as shown below: \n",
    "[/INST]\n",
    "[MEASUREMQL]\n",
    "{measure_mql}\n",
    "[/MEASUREMQL]</s>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33b17057",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template_v1 = \"\"\"<s>[INST]<<SYS>>\n",
    "You are an assistant that helps to map the user question to the a particular JSON format which contains info asked by user and also maps it the below CONTEXT. You might also need to act as a time tagger expert to convert the date elements present in the question to a standard format and to find possible date ranges for the same.\n",
    "\n",
    "CONTEXT:{context}\n",
    "\n",
    "Step 1: Identify the n-grams match between question and context\n",
    "\n",
    "        Map the n-gram or their lemma or their inflections from the question with the values in the passed context.\n",
    "        Always consider the longest n-gram match, not the sub-string.\n",
    "        If there are multiple matches for an n-gram with context, return all such ENTITY in response.\n",
    "        If you are returning any match which is not exactly present with the context, make sure that it is a noun phrase and there is a high similarity between the match and the matched value in context. \n",
    "\n",
    "\n",
    "Step 2: Applying time tagger rules only if time elements are present in question\n",
    "\n",
    "        Identify the TIME ELEMENTS in the input question and convert it to a standard format (if not already) by applying the general time tagging rules. If the TIME ELEMENT is already in a standard format, then no need to convert it.\n",
    "        TIME ELEMENT can be either a temporal interval (across months, yoy, mom, qoq, wow, quarterly etc.) or a temporal expression (time points such as specific dates, relative expressions etc.).\n",
    "        Calculate date range for each time points based on the following conditions:\n",
    "        1. For relative time expressions, calculate the date range based on a reference date - By default the reference date is the end_date in date input: {date_input}\n",
    "        2. To calculate the date range for \"last X years\", strictly follow below conditions:\n",
    "                For \"last 1 year\", consider exactly one year before the reference year and set start date as January 1 and end date as Decemebr 31 of that year.\n",
    "                For \"last X years\", where X is greater than 1, consider starting year = (reference year - X+1) and set start date as January 1 of starting year and end date as the reference date.\n",
    "        3. To calculate the date range for \"last X months\", strictly follow below conditions:\n",
    "                Consider reference month as the month in reference date.\n",
    "                For \"last 1 month\", consider exactly one month before the reference month and set start date as first day and end date as last day of that month.\n",
    "                For \"last X months\", where X is greater than 1, consider starting month = (reference month - X+1) and set start date as first day of starting month and end date as the reference date. (Example: if reference date is 14/09/2022, then last 3 months = 01/07/2022 - 14/09/2022)\n",
    "        4. To calculate the date range for \"last X quarters\", strictly follow below conditions:\n",
    "                For \"last 1 quarter\", consider exactly one quarter before the reference quarter and set start date as first day and end date as last day of that quarter .\n",
    "                For \"last X quarter\", where X is greater than 1, consider starting quarter = (reference quarter - X+1) and set start date as first day of starting quarter and end date as the reference date.\n",
    "        5. To calculate the date range for \"last X weeks\", strictly follow the below conditions:\n",
    "                Consider reference week as the week in reference week.\n",
    "                For \"last 1 week\", set start date as Monday and end date as Sunday of the previous week of reference week. (Example: if reference date is 14/09/2022, then last week = 05/09/2022 - 11/09/2022)\n",
    "                For \"last X weeks\", set start date as Monday of reference week and set start date as the Monday of that week and end date as reference date. \n",
    "        6. Provide the date range of each time point in \"start date - end date\" format always.\n",
    "\n",
    "<</SYS>>\n",
    "User question is : {user_query}\n",
    "\n",
    "Converted JSON is as shown below: \n",
    "[/INST]\n",
    "[MQL]\n",
    "{mql}\n",
    "[/MQL]</s>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50d534e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'query', 'measure_new', 'measure_mql'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a95227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset(row):\n",
    "    mql = eval(row['mql'])[0]['mql']\n",
    "    user_query = row['query']\n",
    "    date_input = {\"start_date\": \"01/01/2020\", \"end_date\": \"15/09/2023\"}\n",
    "    context = row['metadata_none_removed']\n",
    "    formated = promt_template_v1.format(context=context,\n",
    "                                        date_input = date_input,\n",
    "                                        user_query=user_query,\n",
    "                                        mql=mql)\n",
    "    return formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bc719f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset_measure(row):\n",
    "    measure_mql = row['measure_mql']\n",
    "    user_query = row['query']\n",
    "    context = row['measure_new']\n",
    "    formated = promt_template_measure.format(context=context,\n",
    "                                             user_query=user_query,\n",
    "                                             measure_mql=measure_mql)\n",
    "    return formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a558ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fine_tuning_dataset']=train_df.apply(create_fine_tuning_dataset_measure, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6859de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['fine_tuning_dataset']=train_df.apply(create_fine_tuning_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4fcb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_df['fine_tuning_dataset']=val_df.apply(create_fine_tuning_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826aee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['fine_tuning_dataset']=val_df.apply(create_fine_tuning_dataset_measure, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0550eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8af15320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['fine_tuning_dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffaf5ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e5f8b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = val_df[['fine_tuning_dataset']]\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50718542",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.reset_index(inplace=True)\n",
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f4c4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0efa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'fine_tuning_dataset'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "555e910f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'fine_tuning_dataset'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68cc3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed25c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nf4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_4bit_quant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6664ecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e2c3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38e3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f49a0ae",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e994711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu': [{'fb_memory_usage': {'total': 16384.0,\n",
       "    'free': 15972.9375,\n",
       "    'unit': 'MiB'}}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynvml.smi import nvidia_smi\n",
    "nvsmi = nvidia_smi.getInstance()\n",
    "nvsmi.DeviceQuery('memory.free, memory.total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eec98fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!df -H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202bb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ca0d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba0a15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cae259bc89455d87c6911918e21bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef60f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6716c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(train_df['fine_tuning_dataset'][i])) for i in range(train_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5bf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75ffc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85583ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e30b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    eval_steps=50, # requires when eval_dataset is defined\n",
    "    per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "    evaluation_strategy=\"steps\", # requires when eval_dataset is defined\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=1000,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ee91f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint 4.551360512 GB\n",
      "Flops 21843.947814912 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "## Getting FLOPs of model\n",
    "\n",
    "model_flops = (\n",
    "  model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, 512)\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_arguments.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "#print(model)\n",
    "print(\"Memory footprint\", model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de52effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'fine_tuning_dataset'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9aa438a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8bf5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec87609084a4ad2b6a3e1378619ef6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1808578e50504efc8b8163b4b8a64d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"fine_tuning_dataset\",\n",
    "    max_seq_length=256,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942d91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5769042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 57:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>0.551327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.467490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.373558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.278459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.239976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.254446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.221894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.227620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.228516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.230014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.213361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.222692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.226286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.219442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.195800</td>\n",
       "      <td>0.215477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.212626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.217037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.218915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.217678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.218816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.268141952611506, metrics={'train_runtime': 3434.8712, 'train_samples_per_second': 1.165, 'train_steps_per_second': 0.291, 'total_flos': 2.7503331250569216e+16, 'train_loss': 0.268141952611506, 'epoch': 4.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned model name\n",
    "new_model_name = \"mistral-ft-peft-v1-lr-64-with-more-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5cbfc1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84916548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ad3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name = \"/data/mistral/query-to-mql/0ct-25/checkpoint-800\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e0e40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10ab609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c2b6a91e4e47849ec482edad528877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(new_model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a87991b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4ad5254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output_merged_dir = os.path.join(new_model_name, \"final_merged_checkpoint\")\n",
    "# model.save_pretrained(output_merged_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d80e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d7fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"<s>[INST]<<SYS>>\n",
    "Given the CONTEXT:{context}, convert the 'user query' into JSON format which captures basic measures asked by user and maps it to CONTEXT.\n",
    "\n",
    "<</SYS>>\n",
    "User query : {user_query}\n",
    "\n",
    "Converted JSON is as shown below: \n",
    "[/INST]\n",
    "[MEASUREMQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbc1fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_to_merge.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4530b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f512be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trend of profit',\n",
       " \"{'measure': 'PROFIT', 'measure_label': 'Profit in Dollars'}\",\n",
       " \"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['query'][0],df['measure'][0],df['measure_mql'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9a2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query, context):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=_inputs.to('cuda'), max_length= 256, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    output_new = output.split('[MEASUREMQL]\\n')[1]\n",
    "    return output_new.split('\\n[/MEASUREMQL]')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9397c",
   "metadata": {},
   "source": [
    "### Testing on data used for query to intermediate using openai prompt base approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46bdccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  show me the 2 top segments basis sales\n",
      "CPU times: user 6.41 s, sys: 218 ms, total: 6.63 s\n",
      "Wall time: 6.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'show me the 2 top segments basis sales'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Sales', 'PROFIT'], 'measure_label': ['Number Requests For Shift','PROFIT']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a35b829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  top 2 and bottom 3 segments by sales\n",
      "CPU times: user 6.46 s, sys: 174 ms, total: 6.64 s\n",
      "Wall time: 6.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'top 2 and bottom 3 segments by sales'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Sales', 'PROFIT'], 'measure_label': ['Number Requests For Shift','Sales']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e0070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  top 2 segments and bottom 3 sub-category basis quantity\n",
      "CPU times: user 8.19 s, sys: 191 ms, total: 8.38 s\n",
      "Wall time: 8.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'top 2 segments and bottom 3 sub-category basis quantity'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Quantity',], 'measure_label': ['Quantity in millions']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab141b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'top 2 segments and bottom 3 sub-category basis quantity'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Quantity',], 'measure_label': ['Quantity in millions']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c36cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  why did profit changed in may 2023\n",
      "CPU times: user 8.5 s, sys: 184 ms, total: 8.68 s\n",
      "Wall time: 8.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_query = 'why did profit changed in may 2023'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['PROFIT'], 'measure_label': ['Number Requests For Shift','PROFIT']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad45222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4c511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa006df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  trend of profit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2507: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.88 s, sys: 220 ms, total: 8.1 s\n",
      "Wall time: 8.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\",\n",
       " \"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = df['query'][i]\n",
    "print('user query: ', user_query)\n",
    "context = df['measure_new'][i]\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output, df['measure_mql'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24ba6a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  why profit change in july 2022\n",
      "CPU times: user 7.12 s, sys: 261 ms, total: 7.38 s\n",
      "Wall time: 7.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\",\n",
       " \"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=2\n",
    "user_query = df['query'][i]\n",
    "print('user query: ', user_query)\n",
    "context = df['measure_new'][i]\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output, df['measure_mql'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb9e971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'query', 'measure_new', 'measure_mql'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b7ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'Unnamed: 0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7f3e433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'query', 'measure_new', 'measure_mql'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dc4d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40198b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_index = set(range(df.shape[0]))-set(train_df['index'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65ecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4d65470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  what is growth of number of providers across arizona\n",
      "CPU times: user 5.44 s, sys: 204 ms, total: 5.64 s\n",
      "Wall time: 5.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"{'measure': None}\", \"{'measure': None}\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=2000\n",
    "user_query = df['query'][i]\n",
    "print('user query: ', user_query)\n",
    "context = df['measure_new'][i]\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output, df['measure_mql'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8befa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36255f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_500_random = random.choices(list(untrained_index), k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108ceb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b9f8c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [58:00<00:00,  6.96s/it] \n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "for i in tqdm(untrained_500_random):\n",
    "    user_query = df['query'][i]\n",
    "    context = df['measure_new'][i]\n",
    "    output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "    prediction.append([df['measure_mql'][i],output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "425bd348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fb470ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "pred_pred = []\n",
    "\n",
    "for p in prediction:\n",
    "    pred_actual.append(p[0])\n",
    "    pred_pred.append(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89079931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'mql', 'account_id', 'metadata', 'measure', 'dimension',\n",
       "       'derived_measure', 'date', 'measure_mql', 'dimension_mql', 'action_mql',\n",
       "       'date_mql', 'measure_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "778b9fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(untrained_500_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c4aebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_query = list(df['query'][untrained_500_random])\n",
    "pred_measure = list(df['measure_new'][untrained_500_random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7785611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "019032b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['query'] = pred_query\n",
    "pred_df['measure_metadata'] = pred_measure\n",
    "pred_df['actual_mql'] = pred_actual\n",
    "pred_df['pred_mql'] = pred_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea104b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('/data/mistral/query-to-mql/0ct-25/pred_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ee5077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for i,row in pred_df.iterrows():\n",
    "    if row['actual_mql']==row['pred_mql']:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d17dfeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['correct']=correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e37490f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>measure_metadata</th>\n",
       "      <th>actual_mql</th>\n",
       "      <th>pred_mql</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what are fill rate in aug 2022 for cna</td>\n",
       "      <td>{'measure': ['FSP_LONGITUDE', 'FILL_RATE_ASSIG...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is trend of number of requested shifts</td>\n",
       "      <td>{'measure': ['AFS_NUMBER_REQUESTS_FOR_SHIFT', ...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is worked hours in quarter2 2022 vs quart...</td>\n",
       "      <td>{'measure': ['SRD_RATE', 'FPP_LATITUDE', 'AFS_...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is monthly growth rate of number of facil...</td>\n",
       "      <td>{'measure': ['FILL_RATE_OPENED', 'Active Facil...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is daily trend of number of facility in 2023</td>\n",
       "      <td>{'measure': ['FFP_LONGITUDE', 'FOP_LATITUDE'],...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>what will be worked hours in next 6 months</td>\n",
       "      <td>{'measure': ['FFP_NUM_TEAM_MEMBERS', 'AFS_DEFA...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>what is trend of profit</td>\n",
       "      <td>{'measure': ['OPENED_HOURS', 'AFS_CONTRACT_RAT...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>top 5 state contributing to number of provider...</td>\n",
       "      <td>{'measure': ['FFP_LATITUDE', 'PROFIT'], 'measu...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>what is monthly trend of filled hours in texas...</td>\n",
       "      <td>{'measure': ['FPP_LATITUDE', 'COUNT(DISTINCT F...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>what is trend of average hourly rate in last q...</td>\n",
       "      <td>{'measure': ['AFS_CONTRACT_RATE', 'Active Faci...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query  \\\n",
       "0               what are fill rate in aug 2022 for cna   \n",
       "1          what is trend of number of requested shifts   \n",
       "2    what is worked hours in quarter2 2022 vs quart...   \n",
       "3    what is monthly growth rate of number of facil...   \n",
       "4    what is daily trend of number of facility in 2023   \n",
       "..                                                 ...   \n",
       "495         what will be worked hours in next 6 months   \n",
       "496                            what is trend of profit   \n",
       "497  top 5 state contributing to number of provider...   \n",
       "498  what is monthly trend of filled hours in texas...   \n",
       "499  what is trend of average hourly rate in last q...   \n",
       "\n",
       "                                      measure_metadata  \\\n",
       "0    {'measure': ['FSP_LONGITUDE', 'FILL_RATE_ASSIG...   \n",
       "1    {'measure': ['AFS_NUMBER_REQUESTS_FOR_SHIFT', ...   \n",
       "2    {'measure': ['SRD_RATE', 'FPP_LATITUDE', 'AFS_...   \n",
       "3    {'measure': ['FILL_RATE_OPENED', 'Active Facil...   \n",
       "4    {'measure': ['FFP_LONGITUDE', 'FOP_LATITUDE'],...   \n",
       "..                                                 ...   \n",
       "495  {'measure': ['FFP_NUM_TEAM_MEMBERS', 'AFS_DEFA...   \n",
       "496  {'measure': ['OPENED_HOURS', 'AFS_CONTRACT_RAT...   \n",
       "497  {'measure': ['FFP_LATITUDE', 'PROFIT'], 'measu...   \n",
       "498  {'measure': ['FPP_LATITUDE', 'COUNT(DISTINCT F...   \n",
       "499  {'measure': ['AFS_CONTRACT_RATE', 'Active Faci...   \n",
       "\n",
       "                                            actual_mql  \\\n",
       "0                                    {'measure': None}   \n",
       "1                                    {'measure': None}   \n",
       "2    {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "3                                    {'measure': None}   \n",
       "4                                    {'measure': None}   \n",
       "..                                                 ...   \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "496  {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "497                                  {'measure': None}   \n",
       "498                                  {'measure': None}   \n",
       "499                                  {'measure': None}   \n",
       "\n",
       "                                              pred_mql  correct  \n",
       "0                                    {'measure': None}        1  \n",
       "1                                    {'measure': None}        1  \n",
       "2    {'measure': {'worked hours': {'AFS_WORKED_HOUR...        1  \n",
       "3                                    {'measure': None}        1  \n",
       "4                                    {'measure': None}        1  \n",
       "..                                                 ...      ...  \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...        0  \n",
       "496  {'measure': {'profit': {'PROFIT': {'label': 'P...        1  \n",
       "497                                  {'measure': None}        1  \n",
       "498                                  {'measure': None}        1  \n",
       "499                                  {'measure': None}        1  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0601d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "beb0bfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_mql</th>\n",
       "      <th>actual_mql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            actual_mql  \\\n",
       "20   {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "28   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "32   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "35   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "36   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "..                                                 ...   \n",
       "459  {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "462  {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "478  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "480  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "\n",
       "                                            actual_mql  \n",
       "20   {'measure': {'profit': {'PROFIT': {'label': 'P...  \n",
       "28   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "32   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "35   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "36   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "..                                                 ...  \n",
       "459  {'measure': {'profit': {'PROFIT': {'label': 'P...  \n",
       "462  {'measure': {'profit': {'PROFIT': {'label': 'P...  \n",
       "478  {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "480  {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, k in pred_df[pred_df['correct']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbfb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509cf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af68e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d569ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = query_template_v2.format(user_query='brands least profitable in 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b8cc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b1c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.61 s, sys: 135 ms, total: 6.75 s\n",
      "Wall time: 6.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.generate(input_ids=tokens.to('cuda'), max_length= 180, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c00ba884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST]<<SYS>>\\nYou are an advanced template converter that converts user question to a specific template which answers the user question.\\n\\n<</SYS>>\\n\\nbrands least profitable in 2021\\n[/INST]\\n[LUMINTEMPLATE]\\nList of brands with lowest profit in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5 brands based on profit share in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5 brands based on market share in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5 brands based on sales share in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c874042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90dc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2945308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbc306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f88861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88bd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da2299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f2759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
