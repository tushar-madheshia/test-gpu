{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06dcc636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b437fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.34.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7ece4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install -q accelerate peft==0.4.0 bitsandbytes trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57fbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bb11f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/mistral/query-to-mql/training-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219fed17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'MQL', 'Rationale'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8070e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a2a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6b4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c37f45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "#dataset_name = \"\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "#new_model = \"mistral-ft-peft-on-template_and_user_query-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2ceeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83e1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b95b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"/data/mistral/query-to-mql/0ct-25\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 15\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "# fp16 = False\n",
    "fp16 = True # not using quantisation\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 4\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 4\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 1\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine)\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = 1000\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 50\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd83a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36063e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_template_measure = \"\"\"<s>[INST]<<SYS>>\n",
    "Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "\n",
    "<</SYS>>\n",
    "[/INST]\n",
    "[MQL]\n",
    "{mql}\n",
    "[/MQL]\n",
    "\n",
    "the steps and rationale used to achieve above structured output is as below.\n",
    "{rationale}\n",
    "</s>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d534e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query', 'MQL', 'Rationale'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "667cdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a95227",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bc719f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fine_tuning_dataset(row):\n",
    "    mql = row['MQL']\n",
    "    user_query = row['Query']\n",
    "    rationale = row['Rationale']\n",
    "    formated = promt_template_measure.format(context=context,\n",
    "                                             date_input=date_input\n",
    "                                             user_query=user_query,\n",
    "                                             measure_mql=mql,\n",
    "                                            rationale=rationale)\n",
    "    return formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a558ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fine_tuning_dataset']=train_df.apply(create_fine_tuning_dataset_measure, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6859de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['fine_tuning_dataset']=train_df.apply(create_fine_tuning_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4fcb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_df['fine_tuning_dataset']=val_df.apply(create_fine_tuning_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826aee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['fine_tuning_dataset']=val_df.apply(create_fine_tuning_dataset_measure, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0550eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8af15320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['fine_tuning_dataset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffaf5ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e5f8b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = val_df[['fine_tuning_dataset']]\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50718542",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.reset_index(inplace=True)\n",
    "train_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f4c4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af0efa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'fine_tuning_dataset'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "555e910f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'fine_tuning_dataset'],\n",
       "    num_rows: 30\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68cc3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed25c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nf4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_4bit_quant_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6664ecee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e2c3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38e3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f49a0ae",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!sudo pip install -q pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e994711a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpu': [{'fb_memory_usage': {'total': 16384.0,\n",
       "    'free': 15972.9375,\n",
       "    'unit': 'MiB'}}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynvml.smi import nvidia_smi\n",
    "nvsmi = nvidia_smi.getInstance()\n",
    "nvsmi.DeviceQuery('memory.free, memory.total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eec98fb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!df -H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202bb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ca0d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba0a15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cae259bc89455d87c6911918e21bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef60f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6716c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(train_df['fine_tuning_dataset'][i])) for i in range(train_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5bf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75ffc6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85583ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e30b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    eval_steps=50, # requires when eval_dataset is defined\n",
    "    per_device_eval_batch_size=1, # Batch size for evaluation\n",
    "    evaluation_strategy=\"steps\", # requires when eval_dataset is defined\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=1000,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ee91f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory footprint 4.551360512 GB\n",
      "Flops 21843.947814912 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "## Getting FLOPs of model\n",
    "\n",
    "model_flops = (\n",
    "  model.floating_point_ops(\n",
    "    {\n",
    "       \"input_ids\": torch.zeros(\n",
    "           (1, 512)\n",
    "      )\n",
    "    }\n",
    "  )\n",
    "  * training_arguments.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "#print(model)\n",
    "print(\"Memory footprint\", model.get_memory_footprint() / 1e9, \"GB\")\n",
    "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de52effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'fine_tuning_dataset'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9aa438a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8bf5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec87609084a4ad2b6a3e1378619ef6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1808578e50504efc8b8163b4b8a64d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"fine_tuning_dataset\",\n",
    "    max_seq_length=256,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942d91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5769042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 57:11, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>0.551327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.467490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.373558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.278459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>0.239976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.254446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.221894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.227620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.228516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.230014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.213361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.222692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.226286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.219442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.195800</td>\n",
       "      <td>0.215477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.212626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.217037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.218915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.217678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.218816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.268141952611506, metrics={'train_runtime': 3434.8712, 'train_samples_per_second': 1.165, 'train_steps_per_second': 0.291, 'total_flos': 2.7503331250569216e+16, 'train_loss': 0.268141952611506, 'epoch': 4.0})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuned model name\n",
    "new_model_name = \"mistral-ft-peft-v1-lr-64-with-more-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5cbfc1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=1024, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84916548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ad3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name = \"/data/mistral/query-to-mql/0ct-25/checkpoint-800\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e0e40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10ab609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c2b6a91e4e47849ec482edad528877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(new_model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a87991b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b4ad5254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output_merged_dir = os.path.join(new_model_name, \"final_merged_checkpoint\")\n",
    "# model.save_pretrained(output_merged_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d80e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d7fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be81f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"<s>[INST]<<SYS>>\n",
    "Given the CONTEXT:{context}, convert the 'user query' into JSON format which captures basic measures asked by user and maps it to CONTEXT.\n",
    "\n",
    "<</SYS>>\n",
    "User query : {user_query}\n",
    "\n",
    "Converted JSON is as shown below: \n",
    "[/INST]\n",
    "[MEASUREMQL]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbc1fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_to_merge.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4530b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f512be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trend of profit',\n",
       " \"{'measure': 'PROFIT', 'measure_label': 'Profit in Dollars'}\",\n",
       " \"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['query'][0],df['measure'][0],df['measure_mql'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9a2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query, context):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=_inputs.to('cuda'), max_length= 256, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    output_new = output.split('[MEASUREMQL]\\n')[1]\n",
    "    return output_new.split('\\n[/MEASUREMQL]')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a9397c",
   "metadata": {},
   "source": [
    "### Testing on data used for query to intermediate using openai prompt base approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46bdccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  show me the 2 top segments basis sales\n",
      "CPU times: user 6.41 s, sys: 218 ms, total: 6.63 s\n",
      "Wall time: 6.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'show me the 2 top segments basis sales'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Sales', 'PROFIT'], 'measure_label': ['Number Requests For Shift','PROFIT']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a35b829a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  top 2 and bottom 3 segments by sales\n",
      "CPU times: user 6.46 s, sys: 174 ms, total: 6.64 s\n",
      "Wall time: 6.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'top 2 and bottom 3 segments by sales'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Sales', 'PROFIT'], 'measure_label': ['Number Requests For Shift','Sales']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98e0070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  top 2 segments and bottom 3 sub-category basis quantity\n",
      "CPU times: user 8.19 s, sys: 191 ms, total: 8.38 s\n",
      "Wall time: 8.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'top 2 segments and bottom 3 sub-category basis quantity'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Quantity',], 'measure_label': ['Quantity in millions']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab141b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = 'top 2 segments and bottom 3 sub-category basis quantity'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['SCHEDULEDHOURS', 'Quantity',], 'measure_label': ['Quantity in millions']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7c36cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  why did profit changed in may 2023\n",
      "CPU times: user 8.5 s, sys: 184 ms, total: 8.68 s\n",
      "Wall time: 8.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_query = 'why did profit changed in may 2023'\n",
    "print('user query: ', user_query)\n",
    "context = \"{'measure': ['PROFIT'], 'measure_label': ['Number Requests For Shift','PROFIT']}\"\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad45222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4c511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa006df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  trend of profit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:2507: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /home/mosaic-ai/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1442.)\n",
      "  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.88 s, sys: 220 ms, total: 8.1 s\n",
      "Wall time: 8.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\",\n",
       " \"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "user_query = df['query'][i]\n",
    "print('user query: ', user_query)\n",
    "context = df['measure_new'][i]\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output, df['measure_mql'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24ba6a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  why profit change in july 2022\n",
      "CPU times: user 7.12 s, sys: 261 ms, total: 7.38 s\n",
      "Wall time: 7.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\",\n",
       " \"{'measure': {'profit': {'PROFIT': {'label': 'Profit in Dollars', 'order': 'desc', 'operator': 'sum'}}}}\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=2\n",
    "user_query = df['query'][i]\n",
    "print('user query: ', user_query)\n",
    "context = df['measure_new'][i]\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output, df['measure_mql'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb9e971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'query', 'measure_new', 'measure_mql'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b7ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns={'Unnamed: 0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7f3e433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'query', 'measure_new', 'measure_mql'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dc4d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40198b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_index = set(range(df.shape[0]))-set(train_df['index'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65ecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4d65470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user query:  what is growth of number of providers across arizona\n",
      "CPU times: user 5.44 s, sys: 204 ms, total: 5.64 s\n",
      "Wall time: 5.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"{'measure': None}\", \"{'measure': None}\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "i=2000\n",
    "user_query = df['query'][i]\n",
    "print('user query: ', user_query)\n",
    "context = df['measure_new'][i]\n",
    "output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "output, df['measure_mql'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8befa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36255f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_500_random = random.choices(list(untrained_index), k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108ceb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b9f8c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 500/500 [58:00<00:00,  6.96s/it] \n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "for i in tqdm(untrained_500_random):\n",
    "    user_query = df['query'][i]\n",
    "    context = df['measure_new'][i]\n",
    "    output = predict_template_query_v1(user_query=user_query,context=context)\n",
    "    prediction.append([df['measure_mql'][i],output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "425bd348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'measure': None}\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fb470ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_actual = []\n",
    "pred_pred = []\n",
    "\n",
    "for p in prediction:\n",
    "    pred_actual.append(p[0])\n",
    "    pred_pred.append(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89079931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'mql', 'account_id', 'metadata', 'measure', 'dimension',\n",
       "       'derived_measure', 'date', 'measure_mql', 'dimension_mql', 'action_mql',\n",
       "       'date_mql', 'measure_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "778b9fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(untrained_500_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c4aebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_query = list(df['query'][untrained_500_random])\n",
    "pred_measure = list(df['measure_new'][untrained_500_random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7785611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "019032b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['query'] = pred_query\n",
    "pred_df['measure_metadata'] = pred_measure\n",
    "pred_df['actual_mql'] = pred_actual\n",
    "pred_df['pred_mql'] = pred_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea104b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('/data/mistral/query-to-mql/0ct-25/pred_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ee5077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for i,row in pred_df.iterrows():\n",
    "    if row['actual_mql']==row['pred_mql']:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d17dfeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['correct']=correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e37490f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>measure_metadata</th>\n",
       "      <th>actual_mql</th>\n",
       "      <th>pred_mql</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what are fill rate in aug 2022 for cna</td>\n",
       "      <td>{'measure': ['FSP_LONGITUDE', 'FILL_RATE_ASSIG...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is trend of number of requested shifts</td>\n",
       "      <td>{'measure': ['AFS_NUMBER_REQUESTS_FOR_SHIFT', ...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is worked hours in quarter2 2022 vs quart...</td>\n",
       "      <td>{'measure': ['SRD_RATE', 'FPP_LATITUDE', 'AFS_...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is monthly growth rate of number of facil...</td>\n",
       "      <td>{'measure': ['FILL_RATE_OPENED', 'Active Facil...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is daily trend of number of facility in 2023</td>\n",
       "      <td>{'measure': ['FFP_LONGITUDE', 'FOP_LATITUDE'],...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>what will be worked hours in next 6 months</td>\n",
       "      <td>{'measure': ['FFP_NUM_TEAM_MEMBERS', 'AFS_DEFA...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>what is trend of profit</td>\n",
       "      <td>{'measure': ['OPENED_HOURS', 'AFS_CONTRACT_RAT...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>top 5 state contributing to number of provider...</td>\n",
       "      <td>{'measure': ['FFP_LATITUDE', 'PROFIT'], 'measu...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>what is monthly trend of filled hours in texas...</td>\n",
       "      <td>{'measure': ['FPP_LATITUDE', 'COUNT(DISTINCT F...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>what is trend of average hourly rate in last q...</td>\n",
       "      <td>{'measure': ['AFS_CONTRACT_RATE', 'Active Faci...</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>{'measure': None}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query  \\\n",
       "0               what are fill rate in aug 2022 for cna   \n",
       "1          what is trend of number of requested shifts   \n",
       "2    what is worked hours in quarter2 2022 vs quart...   \n",
       "3    what is monthly growth rate of number of facil...   \n",
       "4    what is daily trend of number of facility in 2023   \n",
       "..                                                 ...   \n",
       "495         what will be worked hours in next 6 months   \n",
       "496                            what is trend of profit   \n",
       "497  top 5 state contributing to number of provider...   \n",
       "498  what is monthly trend of filled hours in texas...   \n",
       "499  what is trend of average hourly rate in last q...   \n",
       "\n",
       "                                      measure_metadata  \\\n",
       "0    {'measure': ['FSP_LONGITUDE', 'FILL_RATE_ASSIG...   \n",
       "1    {'measure': ['AFS_NUMBER_REQUESTS_FOR_SHIFT', ...   \n",
       "2    {'measure': ['SRD_RATE', 'FPP_LATITUDE', 'AFS_...   \n",
       "3    {'measure': ['FILL_RATE_OPENED', 'Active Facil...   \n",
       "4    {'measure': ['FFP_LONGITUDE', 'FOP_LATITUDE'],...   \n",
       "..                                                 ...   \n",
       "495  {'measure': ['FFP_NUM_TEAM_MEMBERS', 'AFS_DEFA...   \n",
       "496  {'measure': ['OPENED_HOURS', 'AFS_CONTRACT_RAT...   \n",
       "497  {'measure': ['FFP_LATITUDE', 'PROFIT'], 'measu...   \n",
       "498  {'measure': ['FPP_LATITUDE', 'COUNT(DISTINCT F...   \n",
       "499  {'measure': ['AFS_CONTRACT_RATE', 'Active Faci...   \n",
       "\n",
       "                                            actual_mql  \\\n",
       "0                                    {'measure': None}   \n",
       "1                                    {'measure': None}   \n",
       "2    {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "3                                    {'measure': None}   \n",
       "4                                    {'measure': None}   \n",
       "..                                                 ...   \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "496  {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "497                                  {'measure': None}   \n",
       "498                                  {'measure': None}   \n",
       "499                                  {'measure': None}   \n",
       "\n",
       "                                              pred_mql  correct  \n",
       "0                                    {'measure': None}        1  \n",
       "1                                    {'measure': None}        1  \n",
       "2    {'measure': {'worked hours': {'AFS_WORKED_HOUR...        1  \n",
       "3                                    {'measure': None}        1  \n",
       "4                                    {'measure': None}        1  \n",
       "..                                                 ...      ...  \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...        0  \n",
       "496  {'measure': {'profit': {'PROFIT': {'label': 'P...        1  \n",
       "497                                  {'measure': None}        1  \n",
       "498                                  {'measure': None}        1  \n",
       "499                                  {'measure': None}        1  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0601d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937927a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "beb0bfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_mql</th>\n",
       "      <th>actual_mql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "      <td>{'measure': {'profit': {'PROFIT': {'label': 'P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "      <td>{'measure': {'worked hours': {'AFS_WORKED_HOUR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            actual_mql  \\\n",
       "20   {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "28   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "32   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "35   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "36   {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "..                                                 ...   \n",
       "459  {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "462  {'measure': {'profit': {'PROFIT': {'label': 'P...   \n",
       "478  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "480  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...   \n",
       "\n",
       "                                            actual_mql  \n",
       "20   {'measure': {'profit': {'PROFIT': {'label': 'P...  \n",
       "28   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "32   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "35   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "36   {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "..                                                 ...  \n",
       "459  {'measure': {'profit': {'PROFIT': {'label': 'P...  \n",
       "462  {'measure': {'profit': {'PROFIT': {'label': 'P...  \n",
       "478  {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "480  {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "495  {'measure': {'worked hours': {'AFS_WORKED_HOUR...  \n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, k in pred_df[pred_df['correct']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcbfb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509cf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af68e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d569ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = query_template_v2.format(user_query='brands least profitable in 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b8cc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b1c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.61 s, sys: 135 ms, total: 6.75 s\n",
      "Wall time: 6.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.generate(input_ids=tokens.to('cuda'), max_length= 180, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c00ba884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>[INST]<<SYS>>\\nYou are an advanced template converter that converts user question to a specific template which answers the user question.\\n\\n<</SYS>>\\n\\nbrands least profitable in 2021\\n[/INST]\\n[LUMINTEMPLATE]\\nList of brands with lowest profit in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5 brands based on profit share in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5 brands based on market share in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5 brands based on sales share in 2021\\n[/LUMINTEMPLATE]\\n\\nWhich are the top 5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c874042c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90dc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2945308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbc306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f88861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88bd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da2299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f2759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
