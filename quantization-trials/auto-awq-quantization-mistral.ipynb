{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc95442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo -H pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c4a3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autoawq==0.1.7+cu118\n",
      "\u001b[?25l  Downloading https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp38-cp38-linux_x86_64.whl (20.0MB)\n",
      "\u001b[K     |████████████████████████████████| 20.0MB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.21.0)\n",
      "Collecting texttable\n",
      "  Downloading https://files.pythonhosted.org/packages/24/99/4772b8e00a136f3e01236de33b0efda31ee7077203ba5967fcc76da94d65/texttable-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (4.24.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.1.99)\n",
      "Collecting lm-eval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/e0/05001c2e56e2f8f793189442176432ddb89a2f1f1ef00ea154d0bc00fe37/lm_eval-0.4.0.tar.gz (457kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tokenizers>=0.12.1 in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.15.0)\n",
      "Collecting toml\n",
      "  Downloading https://files.pythonhosted.org/packages/44/6f/7120676b6d73228c96e17f1f794d8ab046fc910d781c8d151120c3f1569e/toml-0.10.2-py2.py3-none-any.whl\n",
      "Collecting attributedict\n",
      "  Downloading https://files.pythonhosted.org/packages/de/db/337b36e8d85a07293f5a792644fa972b53a52b13587f484c627009206697/attributedict-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (2.0.1)\n",
      "Collecting tabulate\n",
      "  Downloading https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (0.15.2)\n",
      "Requirement already satisfied: transformers>=4.35.0 in /opt/conda/lib/python3.8/site-packages (from autoawq==0.1.7+cu118) (4.36.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate->autoawq==0.1.7+cu118) (1.21.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate->autoawq==0.1.7+cu118) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate->autoawq==0.1.7+cu118) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from accelerate->autoawq==0.1.7+cu118) (23.0)\n",
      "Collecting pybind11>=2.6.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/55/9f73c32dda93fa4f539fafa268f9504e83c489f460c380371d94296126cd/pybind11-2.11.1-py3-none-any.whl (227kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 17.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rouge-score>=0.0.4\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/c5/9136736c37022a6ad27fea38f3111eb8f02fe75d067f9a985cc358653102/rouge_score-0.1.2.tar.gz\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (1.3.0)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (0.19.0)\n",
      "Collecting numexpr\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/47/a2ede0e136a8ddc288b447c260aa035f3e75251f808aa61f6454b16dfd04/numexpr-2.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 21.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (2.14.4)\n",
      "Collecting pytablewriter\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/74/b39b823ee7dba155b117634e62733a0dfdfe5aa100a553b435062cee2062/pytablewriter-1.2.0-py3-none-any.whl (111kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 22.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacrebleu>=1.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/ea/025db0a39337b63d4728a900d262c39c3029b0fe76a9876ce6297b1aa6a0/sacrebleu-2.4.0-py3-none-any.whl (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 37.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlitedict\n",
      "  Downloading https://files.pythonhosted.org/packages/12/9a/7620d1e9dcb02839ed6d4b14064e609cdd7a8ae1e47289aa0456796dd9ca/sqlitedict-2.1.0.tar.gz\n",
      "Requirement already satisfied: evaluate>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (0.4.0)\n",
      "Collecting tqdm-multiprocess\n",
      "  Downloading https://files.pythonhosted.org/packages/25/7e/0d889fc6c84e3df6b69aaafe893fc77f69b3d968ac9ce574d1c62c688050/tqdm_multiprocess-0.0.11-py3-none-any.whl\n",
      "Requirement already satisfied: peft>=0.2.0 in /opt/conda/lib/python3.8/site-packages (from lm-eval->autoawq==0.1.7+cu118) (0.6.0.dev0)\n",
      "Collecting jsonlines\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.8/site-packages (from tokenizers>=0.12.1->autoawq==0.1.7+cu118) (0.20.2)\n",
      "Collecting tox>=3.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/88/de28a027acdb3a1b070a8acdff62bd23fdc23ce32acc7ac4b92b088979a4/tox-4.11.4-py3-none-any.whl (153kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 35.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rootpath>=0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/f9/959835686c78b7a95d8d806a97fa0be020c2deccb96de2b60659744319b9/rootpath-0.1.1-py3-none-any.whl\n",
      "Collecting deepdiff>=3.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/8f/a9d39ec15f40e8169cb134317824ee4618b864b2e4b91a9b310d3ef94729/deepdiff-6.7.1-py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 26.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting codecov>=2.0.15\n",
      "  Downloading https://files.pythonhosted.org/packages/af/02/18785edcdf6266cdd6c6dc7635f1cbeefd9a5b4c3bb8aff8bd681e9dd095/codecov-2.1.13-py2.py3-none-any.whl\n",
      "Collecting colour-runner>=0.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/82/ce3250026add1910739dcabc796571ad1d182cb47332716c8bb96ee5d624/colour_runner-0.1.1-py2.py3-none-any.whl\n",
      "Collecting coverage>=4.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/95/83c2429234f40f438e453554844890335c3c67e53bfd6b1e16142da893d0/coverage-7.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 30.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting inspecta>=0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/03/aa/5ad8e223fa564d474b465771710b8b7b23896b59651cf115f510bcfda3ee/inspecta-0.1.3-py3-none-any.whl\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.4.0.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (2.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (4.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (11.7.99)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (3.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.1->autoawq==0.1.7+cu118) (1.12)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->autoawq==0.1.7+cu118) (10.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision->autoawq==0.1.7+cu118) (2.29.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (0.3.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (2023.8.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.35.0->autoawq==0.1.7+cu118) (4.65.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.8/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq==0.1.7+cu118) (1.4.0)\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 36.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.8/site-packages (from rouge-score>=0.0.4->lm-eval->autoawq==0.1.7+cu118) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7+cu118) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7+cu118) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.24.1->lm-eval->autoawq==0.1.7+cu118) (1.10.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (0.70.15)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2.0.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (3.3.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (3.8.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2023.6.0)\n",
      "Collecting typepy[datetime]<2,>=1.3.2\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/10/0d6dc654bb4e0eca017bbaf43a315b464c888576a68a2883cd4a74bd1b6b/typepy-1.3.2-py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.8/site-packages (from pytablewriter->lm-eval->autoawq==0.1.7+cu118) (67.8.0)\n",
      "Collecting tcolorpy<1,>=0.0.5\n",
      "  Downloading https://files.pythonhosted.org/packages/34/d0/8a701df46bf546fd155da02934b0bb2ac6ad4186e29f4a3297e744ab259d/tcolorpy-0.1.4-py3-none-any.whl\n",
      "Collecting tabledata<2,>=1.3.1\n",
      "  Downloading https://files.pythonhosted.org/packages/06/e2/96b10ebc00d20b55967200e3d95c2137d91f58af1af672627683431c9d5c/tabledata-1.3.3-py3-none-any.whl\n",
      "Collecting pathvalidate<4,>=2.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/ab/673cce13ab635fd755d206b18c0a371ef6e28ddbe25fadba9ae6c59f22a5/pathvalidate-3.2.0-py3-none-any.whl\n",
      "Collecting DataProperty<2,>=1.0.1\n",
      "  Downloading https://files.pythonhosted.org/packages/b1/3b/90ebd66ad57c588d6087e86e327436343e9cc60776a9445b79c6e80a022d/DataProperty-1.0.1-py3-none-any.whl\n",
      "Collecting mbstrdecoder<2,>=1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/0f/726229136022b154895138bb10ba35e8435c4143f614cb5ad4d4e3fc21ec/mbstrdecoder-1.1.3-py3-none-any.whl\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl\n",
      "Collecting portalocker\n",
      "  Downloading https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl\n",
      "Collecting lxml\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/08/8cb09c9a0d77e7b615ace332a76e6460f4c3b0a50654c181755c619c383e/lxml-5.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.0MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0MB 64.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from evaluate>=0.4.0->lm-eval->autoawq==0.1.7+cu118) (0.18.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.8/site-packages (from jsonlines->lm-eval->autoawq==0.1.7+cu118) (23.1.0)\n",
      "Collecting chardet>=5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl (199kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 106.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting platformdirs>=3.10\n",
      "  Downloading https://files.pythonhosted.org/packages/be/53/42fe5eab4a09d251a76d0043e018172db324a23fcdac70f77a551c11f618/platformdirs-4.1.0-py3-none-any.whl\n",
      "Collecting pyproject-api>=1.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/b4/39eea50542e50e93876ebc09c4349a9c9eee9f6b9c9d30f88c7dc5433db8/pyproject_api-1.6.1-py3-none-any.whl\n",
      "Collecting virtualenv>=20.24.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/22/54b1180756d2d6194bcafb7425d437c3034c4bff92129c3e1e633079e2c4/virtualenv-20.25.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 101.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tomli>=2.0.1; python_version < \"3.11\"\n",
      "  Downloading https://files.pythonhosted.org/packages/97/75/10a9ebee3fd790d20926a90a2547f0bf78f371b2f13aa822c759680ca7b9/tomli-2.0.1-py3-none-any.whl\n",
      "Collecting pluggy>=1.3\n",
      "  Downloading https://files.pythonhosted.org/packages/05/b8/42ed91898d4784546c5f06c60506400548db3f7a4b3fb441cba4e5c17952/pluggy-1.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: cachetools>=5.3.1 in /opt/conda/lib/python3.8/site-packages (from tox>=3.0.0->attributedict->autoawq==0.1.7+cu118) (5.3.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl\n",
      "Collecting coloredlogs>=10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 30.6MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: pygments>=2.2.0 in /opt/conda/lib/python3.8/site-packages (from rootpath>=0.1.0->attributedict->autoawq==0.1.7+cu118) (2.15.1)\n",
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading https://files.pythonhosted.org/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl\n",
      "Collecting blessings\n",
      "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=2.0.1->autoawq==0.1.7+cu118) (2.1.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=2.0.1->autoawq==0.1.7+cu118) (0.38.1)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=2.0.1->autoawq==0.1.7+cu118) (3.27.1)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=2.0.1->autoawq==0.1.7+cu118) (16.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=2.0.1->autoawq==0.1.7+cu118) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->autoawq==0.1.7+cu118) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->autoawq==0.1.7+cu118) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->autoawq==0.1.7+cu118) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision->autoawq==0.1.7+cu118) (1.26.15)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk->rouge-score>=0.0.4->lm-eval->autoawq==0.1.7+cu118) (8.1.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (2023.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->lm-eval->autoawq==0.1.7+cu118) (1.4.0)\n",
      "Collecting distlib<1,>=0.3.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/41/9307e4f5f9976bc8b7fea0b66367734e8faf3ec84bc0d412d8cfabbb66cd/distlib-0.3.8-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 108.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 48.0MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lm-eval\n",
      "  Building wheel for lm-eval (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lm-eval: filename=lm_eval-0.4.0-cp38-none-any.whl size=994996 sha256=95b8fa3665066c6f5e9b265fd92977b8bd17c5705244f77bc0a3e04dc752ed54\n",
      "  Stored in directory: /root/.cache/pip/wheels/60/08/c8/cc3a820545d8c8990dc313dfd01c0ee280999cd9e796973e35\n",
      "Successfully built lm-eval\n",
      "Building wheels for collected packages: rouge-score, sqlitedict\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-cp38-none-any.whl size=24937 sha256=d690c8766954a6e422dbc395872d759251136ff2f5a486812eb13f63602fe184\n",
      "  Stored in directory: /root/.cache/pip/wheels/df/aa/59/74f33db3bbedf322bcaadca4a43750ea5eb523bbe742d78b25\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-cp38-none-any.whl size=16865 sha256=4bf2e70434852c52511a33fafe78e80af6c7ed63bdaa61af18fdd01ce385239b\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/10/02/9725042cf8a987b45e38bcfb106f4b0cdcc9d8968e248b93e1\n",
      "Successfully built rouge-score sqlitedict\n",
      "\u001b[31mERROR: pyproject-api 1.6.1 has requirement packaging>=23.1, but you'll have packaging 23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tox 4.11.4 has requirement filelock>=3.12.3, but you'll have filelock 3.12.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tox 4.11.4 has requirement packaging>=23.1, but you'll have packaging 23.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: texttable, pybind11, nltk, rouge-score, numexpr, chardet, mbstrdecoder, typepy, tcolorpy, DataProperty, tabledata, pathvalidate, pytablewriter, colorama, tabulate, portalocker, lxml, sacrebleu, sqlitedict, tqdm-multiprocess, jsonlines, lm-eval, toml, platformdirs, tomli, pyproject-api, distlib, virtualenv, pluggy, tox, ordered-set, deepdiff, coverage, codecov, blessings, colour-runner, termcolor, humanfriendly, coloredlogs, rootpath, inspecta, attributedict, autoawq\n",
      "  Found existing installation: platformdirs 3.6.0\n",
      "    Uninstalling platformdirs-3.6.0:\n",
      "      Successfully uninstalled platformdirs-3.6.0\n",
      "  Found existing installation: pluggy 1.0.0\n",
      "    Uninstalling pluggy-1.0.0:\n",
      "      Successfully uninstalled pluggy-1.0.0\n",
      "Successfully installed DataProperty-1.0.1 attributedict-0.3.0 autoawq-0.1.7+cu118 blessings-1.7 chardet-5.2.0 codecov-2.1.13 colorama-0.4.6 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.4.0 deepdiff-6.7.1 distlib-0.3.8 humanfriendly-10.0 inspecta-0.1.3 jsonlines-4.0.0 lm-eval-0.4.0 lxml-5.1.0 mbstrdecoder-1.1.3 nltk-3.8.1 numexpr-2.8.6 ordered-set-4.1.0 pathvalidate-3.2.0 platformdirs-4.1.0 pluggy-1.3.0 portalocker-2.8.2 pybind11-2.11.1 pyproject-api-1.6.1 pytablewriter-1.2.0 rootpath-0.1.1 rouge-score-0.1.2 sacrebleu-2.4.0 sqlitedict-2.1.0 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.4 termcolor-2.4.0 texttable-1.7.0 toml-0.10.2 tomli-2.0.1 tox-4.11.4 tqdm-multiprocess-0.0.11 typepy-1.3.2 virtualenv-20.25.0\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc85cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29fd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2133988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/93/454ada0d1b289a0f4a86ac88dbdeab54921becabac45da3da787d136628f/datasets-2.16.1-py3-none-any.whl\n",
      "Collecting multiprocess\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/a6/c5cb599d917904878f220a4dbdfdcc4ef291dd3956c35b3b0dc6fc42fb6d/multiprocess-0.70.15-py38-none-any.whl\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/7a/b8d5b40870349e468b08e1ecb65a500b0ed1fe4937cf6bda01e7b85c8cb4/pyarrow-14.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/6b/6600ac24725c7388255b2f5add93f91e58a5d7efaf4af244fdbcc11a541b/PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting requests>=2.19.0\n",
      "  Using cached https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl\n",
      "Collecting pyarrow-hotfix\n",
      "  Using cached https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl\n",
      "Collecting pandas\n",
      "  Using cached https://files.pythonhosted.org/packages/f8/7f/5b047effafbdd34e52c9e2d7e44f729a0655efafb22198c45cf692cdc157/pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting tqdm>=4.62.1\n",
      "  Using cached https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl\n",
      "Collecting xxhash\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/80/8fc9a4d76b259c901f2c85ed10f330a8fb51993a577bddfd53a852595e12/xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting huggingface-hub>=0.19.4\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/0a/aed3253a9ce63d9c90829b1d36bc44ad966499ff4f5827309099c8c9184b/huggingface_hub-0.20.2-py3-none-any.whl\n",
      "Collecting packaging\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl\n",
      "Collecting aiohttp\n",
      "  Using cached https://files.pythonhosted.org/packages/25/19/91b9f2b737c9117cf8f622ee02a84788ac6fcda0aa4b736dad1321c6dd93/aiohttp-3.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting numpy>=1.17\n",
      "  Using cached https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting filelock\n",
      "  Using cached https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached https://files.pythonhosted.org/packages/3d/09/d82fe4a34c5f0585f9ea1df090e2a71eb9bb1e469723053e1ee9f57c16f3/charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/fb/52b62131e21b24ee297e4e95ed41eba29647dad0e0051a92bb66b43c70ff/tzdata-2023.4-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached https://files.pythonhosted.org/packages/58/c0/8d9a1c02f217f900f248e0ee31377849f4041aff3d36b71b1f30b4a0fa33/yarl-1.9.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl\n",
      "Collecting async-timeout<5.0,>=4.0; python_version < \"3.11\"\n",
      "  Using cached https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached https://files.pythonhosted.org/packages/45/4d/175b16d42daae8013bb1872f6d0870abd87da93e0a36706da4c9ba655d19/frozenlist-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached https://files.pythonhosted.org/packages/fe/0c/8469202f8f4b0e65816f91c3febc4bda7316c995b59ecdf3b15c574f7a24/multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting six>=1.5\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement PyYAML==6.0, but you'll have pyyaml 6.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: refractml 1.0.3 has requirement urllib3==1.26.15, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mosaic-utils 1.0.2 has requirement scikit-learn==1.2.1; python_version >= \"3.8\", but you'll have scikit-learn 1.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.23.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-auth 2.22.0 has requirement urllib3<2.0, but you'll have urllib3 2.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: dill, multiprocess, numpy, pyarrow, pyyaml, charset-normalizer, idna, certifi, urllib3, requests, multidict, yarl, attrs, async-timeout, frozenlist, aiosignal, aiohttp, fsspec, pyarrow-hotfix, pytz, tzdata, six, python-dateutil, pandas, tqdm, xxhash, packaging, typing-extensions, filelock, huggingface-hub, datasets\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 certifi-2023.11.17 charset-normalizer-3.3.2 datasets-2.16.1 dill-0.3.7 filelock-3.13.1 frozenlist-1.4.1 fsspec-2023.10.0 huggingface-hub-0.20.2 idna-3.6 multidict-6.0.4 multiprocess-0.70.15 numpy-1.24.4 packaging-23.2 pandas-2.0.3 pyarrow-14.0.2 pyarrow-hotfix-0.6 python-dateutil-2.8.2 pytz-2023.3.post1 pyyaml-6.0.1 requests-2.31.0 six-1.16.0 tqdm-4.66.1 typing-extensions-4.9.0 tzdata-2023.4 urllib3-2.1.0 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac0ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "603676d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684c1b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvidia-cuda-cupti-cu11   11.7.101    \r\n",
      "nvidia-cuda-nvrtc-cu11   11.7.99     \r\n",
      "nvidia-cuda-runtime-cu11 11.7.99     \r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb53d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffccfab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aee117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/mistral/query-to-mql/exp-10/nov-20/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c42249",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_path = '/data/mistral/query-to-mql/exp-10/nov-20/quant-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89d01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = {\"zero_point\":True,\n",
    "               \"q_group_size\": 128,\n",
    "               \"w_bit\": 4,\n",
    "               \"version\": \"GEMM\"\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f853010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fd31cb02324c40b400db3c57c59cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load model\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path, **{\"low_cpu_mem_usage\":True})\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path, safetensors=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e50621ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6689cedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de8217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_split_size_mb:512\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef6c9cb5ef489faaf6ab59af4b72c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02337bbab94142e1ae4dce2faf31209a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AWQ:   3%|▎         | 1/32 [01:14<38:31, 74.55s/it]"
     ]
    }
   ],
   "source": [
    "#Quantize\n",
    "# dont run it again\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb126257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:`quant_config.json` is being deprecated in the future in favor of quantization_config in config.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/data/quantization-trials/quant-model/tokenizer_config.json',\n",
       " '/data/quantization-trials/quant-model/special_tokens_map.json',\n",
       " '/data/quantization-trials/quant-model/vocab.json',\n",
       " '/data/quantization-trials/quant-model/merges.txt',\n",
       " '/data/quantization-trials/quant-model/added_tokens.json',\n",
       " '/data/quantization-trials/quant-model/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_quantized(quant_path)\n",
    "#tokenizer.save_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac71427",
   "metadata": {},
   "source": [
    "### Inference on quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fc875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "quant_path = '/data/quantization-trials/quant-model'\n",
    "model_path = '/data/quantization-trials/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ed7b2db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = quant_path\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "def predict_from_quant(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = quant_model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "574a42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ace8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 21.147445678710938\n"
     ]
    }
   ],
   "source": [
    "# Using quant model\n",
    "start = time.time()\n",
    "output1 = predict_from_quant(\"what is art\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "484f1d27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is art?\n",
      "\n",
      "Art is a way of expressing one's self. It is a way of expressing one's thoughts, feelings, and ideas. It is a way of expressing one's self through the use of various media.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to describe a wide variety of art forms.\n",
      "\n",
      "The term art is used to describe a wide variety of art forms. The term art is used to\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3fee82",
   "metadata": {},
   "source": [
    "### Inference on un-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba90fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/quantization-trials/merged-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a6c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = model_path\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "def predict_from_normal(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "010b00db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 23.784337282180786\n"
     ]
    }
   ],
   "source": [
    "# Using unquant model\n",
    "import time\n",
    "start = time.time()\n",
    "output2 = predict_from_normal(\"what is art\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5b6f9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is art?\n",
      "\n",
      "Art is a creative expression of the human mind. It is a way of expressing the human mind through the use of various media.\n",
      "\n",
      "The word art is derived from the Latin word artus, which means \"to make\". The word art is used in many different contexts, including:\n",
      "\n",
      "- to describe the beauty of a work of art\n",
      "\n",
      "- to describe the meaning of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of art\n",
      "\n",
      "- to describe the structure of a work of\n"
     ]
    }
   ],
   "source": [
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0949f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
       "      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f139bb23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n",
       "      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTAttention(\n",
       "            (k_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "            (v_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "            (q_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "            (out_proj): WQLinear_GEMM(in_features=2048, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): WQLinear_GEMM(in_features=2048, out_features=8192, bias=True, w_bit=4, group_size=512)\n",
       "          (fc2): WQLinear_GEMM(in_features=8192, out_features=2048, bias=True, w_bit=4, group_size=512)\n",
       "          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
