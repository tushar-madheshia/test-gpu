{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13adff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ref : https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/optimize-llama-2-gptq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669fcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install -q transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add5cdb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-gptq\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/6811dc63a4b51ad23c6e5547f1622fe433c50d3ed6f254674f7fc51178d5/auto_gptq-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8MB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (0.1.99)\n",
      "Requirement already satisfied: peft>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (0.6.0.dev0)\n",
      "Collecting accelerate>=0.22.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/fc/c55e5a2da345c9a24aa2e1e0f60eb2ca290b6a41be82da03a6d4baec4f99/accelerate-0.25.0-py3-none-any.whl (265kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 107.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (4.65.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (2.14.4)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (4.36.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (0.3.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (2.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from auto-gptq) (1.21.1)\n",
      "Collecting gekko\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/d1/cdb977d024b2d7212bea0d6aa939dfdd15c6fb22deacbfb07fd9d8a77734/gekko-1.0.6-py3-none-any.whl (12.2MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2MB 109.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rouge\n",
      "  Downloading https://files.pythonhosted.org/packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from peft>=0.5.0->auto-gptq) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from peft>=0.5.0->auto-gptq) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from peft>=0.5.0->auto-gptq) (5.9.5)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from accelerate>=0.22.0->auto-gptq) (0.20.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (2.29.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (12.0.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (3.3.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (2023.6.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (0.70.15)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (2.0.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->auto-gptq) (3.8.5)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.31.0->auto-gptq) (0.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers>=4.31.0->auto-gptq) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers>=4.31.0->auto-gptq) (2023.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (4.1.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.99)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (3.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (8.5.0.96)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (11.7.91)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->auto-gptq) (2.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->auto-gptq) (4.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (67.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (16.0.6)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.13.0->auto-gptq) (3.27.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\n",
      "Installing collected packages: accelerate, gekko, rouge, auto-gptq\n",
      "  Found existing installation: accelerate 0.21.0\n",
      "    Uninstalling accelerate-0.21.0:\n",
      "      Successfully uninstalled accelerate-0.21.0\n",
      "Successfully installed accelerate-0.25.0 auto-gptq-0.6.0 gekko-1.0.6 rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install auto-gptq --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0807a555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/03/df00e4553653ae038e8869e1bd6999398112be41f50b19acf999d7c706c0/optimum-1.16.1-py3-none-any.whl (403kB)\n",
      "\u001b[K     |████████████████████████████████| 409kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from optimum) (0.20.1)\n",
      "Requirement already satisfied, skipping upgrade: datasets in /opt/conda/lib/python3.8/site-packages (from optimum) (2.14.4)\n",
      "Requirement already satisfied, skipping upgrade: coloredlogs in /opt/conda/lib/python3.8/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied, skipping upgrade: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.8/site-packages (from optimum) (4.36.2)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.9 in /opt/conda/lib/python3.8/site-packages (from optimum) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: sympy in /opt/conda/lib/python3.8/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /opt/conda/lib/python3.8/site-packages (from optimum) (23.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.8/site-packages (from optimum) (1.21.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum) (2.29.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=2023.5.0 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum) (2023.6.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum) (4.65.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.8.0->optimum) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (0.3.7)\n",
      "Requirement already satisfied, skipping upgrade: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (0.70.15)\n",
      "Requirement already satisfied, skipping upgrade: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (3.8.5)\n",
      "Requirement already satisfied, skipping upgrade: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (12.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->optimum) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: humanfriendly>=9.1 in /opt/conda/lib/python3.8/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied, skipping upgrade: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (2023.8.8)\n",
      "Requirement already satisfied, skipping upgrade: sentencepiece!=0.1.92,>=0.1.91; extra == \"sentencepiece\" in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\n",
      "Requirement already satisfied, skipping upgrade: protobuf; extra == \"sentencepiece\" in /opt/conda/lib/python3.8/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.24.0)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.99)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.4.91)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.91)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.99)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (8.5.0.96)\n",
      "Requirement already satisfied, skipping upgrade: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.10.3.66)\n",
      "Requirement already satisfied, skipping upgrade: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (3.1)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (11.7.101)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (10.9.0.58)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (3.1.2)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (10.2.10.91)\n",
      "Requirement already satisfied, skipping upgrade: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /opt/conda/lib/python3.8/site-packages (from torch>=1.9->optimum) (2.14.3)\n",
      "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2023.5.7)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.15)\n",
      "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (1.9.2)\n",
      "Requirement already satisfied, skipping upgrade: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (23.1.0)\n",
      "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: tzdata>=2022.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.2 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->optimum) (2023.3)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /opt/conda/lib/python3.8/site-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (0.38.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.8/site-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (67.8.0)\n",
      "Requirement already satisfied, skipping upgrade: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (3.27.1)\n",
      "Requirement already satisfied, skipping upgrade: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.9->optimum) (16.0.6)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: optimum\n",
      "Successfully installed optimum-1.16.1\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install --upgrade optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70204a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from optimum.gptq import GPTQQuantizer, load_quantized_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991f18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f22c8368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423bb673104740ffa9e1ed49b01d6dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df73b3d2e9474cba8d70d402d126d454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb1dc4861fa490286eb2db3fcf42e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34365f190f564b9c82902146e09e5ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae68bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec882b0bdf499e85f82e749514deaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0892401196d4475099d220069eb41c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a3d3922884414c8e7b18051888a1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c68e3e3c1b64b88afed2a8a6adf69b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d08331b0d0f4900b43ab9cb83b5c275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4310d3964d4fedb5c4c1d9bc11b07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae541b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = GPTQQuantizer(bits=4, dataset=\"wikitext2\")\n",
    "quantizer.quant_method = \"gptq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9195933b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3474a6a5e4f545c9bf412c72f31c7eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/8.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fcf8d7cda44fccbc21cfbdfc1896df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/6.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a984797e664a918050fe24de2c8824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afed031e629447d9767faa417855d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bb6322b50a4e87a1b99ed9ed4c5cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4581d192c2a941bba763f39669c2df2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73c4c7273884fce83a209ab12aa04e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827f4297388f42368dbaea97bd89c38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing model.decoder.layers blocks :   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found modules on cpu/disk. Using Exllama/Exllamav2 backend requires all the modules to be on GPU. Setting `disable_exllama=True`\n"
     ]
    }
   ],
   "source": [
    "quantized_model = quantizer.quantize_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9e07f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_path = \"/data/quantization-trials/GPTQ-quantized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "890c000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the quantize model to disk\n",
    "\n",
    "quantized_model.save_pretrained(quant_path, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1c26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed91b14b",
   "metadata": {},
   "source": [
    "### Inference on quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83ca527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bddca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"
     ]
    }
   ],
   "source": [
    "gptq_config = GPTQConfig(bits=4, use_exllama=True)\n",
    "\n",
    "model_id = \"/data/quantization-trials/GPTQ-quantized\"\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99bf71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_quant(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = quant_model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec86999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 133.77150201797485\n"
     ]
    }
   ],
   "source": [
    "# Using quant model\n",
    "start = time.time()\n",
    "output1 = predict_from_quant(\"what is science\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1656bd41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is science?\n",
      "\n",
      "Science is the study of the world around us. It is the study of the physical, chemical, and biological world around us. It is the study of the world around us.\n",
      "\n",
      "What is the world around us?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the physical, chemical, and biological world around us.\n",
      "\n",
      "What is the world around us made of?\n",
      "\n",
      "The world around us is made up of the physical, chemical, and biological world around us. The world around us is made up of the\n"
     ]
    }
   ],
   "source": [
    "print(output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84539d4",
   "metadata": {},
   "source": [
    "### Inference on un-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bd366b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/data/quantization-trials/merged-model\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda\", torch_dtype=torch.float16)\n",
    "\n",
    "def predict_from_normal(user_query):\n",
    "    _inputs = tokenizer.encode(user_query, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(input_ids=_inputs, max_length= 1000, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586d4b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken is : 23.793633222579956\n"
     ]
    }
   ],
   "source": [
    "# Using unquant model\n",
    "start = time.time()\n",
    "output2 = predict_from_normal(\"what is science\")\n",
    "print(\"time taken is :\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb75d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>what is science?\n",
      "\n",
      "The word \"science\" is used to describe a variety of fields of study, including:\n",
      "\n",
      "biology\n",
      "\n",
      "chemistry\n",
      "\n",
      "biology of the brain\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the nervous system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the nervous system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the nervous system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the immune system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology of the reproductive system\n",
      "\n",
      "biology\n"
     ]
    }
   ],
   "source": [
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5dd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572c6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8158b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
