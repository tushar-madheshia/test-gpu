{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f991b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Subscription Management repositories.\n",
      "Unable to read consumer identity\n",
      "Subscription Manager is operating in container mode.\n",
      "\n",
      "This system is not registered with an entitlement server. You can use subscription-manager to register.\n",
      "\n",
      "Red Hat Universal Base Image 9 (RPMs) - BaseOS   14 kB/s | 3.8 kB     00:00    \n",
      "Red Hat Universal Base Image 9 (RPMs) - BaseOS  417 kB/s | 514 kB     00:01    \n",
      "Red Hat Universal Base Image 9 (RPMs) - AppStre  18 kB/s | 4.2 kB     00:00    \n",
      "Red Hat Universal Base Image 9 (RPMs) - AppStre 2.0 MB/s | 1.8 MB     00:00    \n",
      "Red Hat Universal Base Image 9 (RPMs) - CodeRea  21 kB/s | 4.2 kB     00:00    \n",
      "Red Hat Universal Base Image 9 (RPMs) - CodeRea 162 kB/s | 192 kB     00:01    \n",
      "Last metadata expiration check: 0:00:01 ago on Thu Dec 14 05:52:18 2023.\n",
      "Dependencies resolved.\n",
      "================================================================================\n",
      " Package            Arch      Version             Repository               Size\n",
      "================================================================================\n",
      "Installing:\n",
      " \u001b[1m\u001b[32mgcc-c++           \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-appstream-rpms     13 M\n",
      "Upgrading:\n",
      " \u001b[1m\u001b[32mcpp               \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-appstream-rpms     11 M\n",
      " \u001b[1m\u001b[32mgcc               \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-appstream-rpms     32 M\n",
      " \u001b[1m\u001b[32mlibgcc            \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-baseos-rpms        98 k\n",
      " \u001b[1m\u001b[32mlibgomp           \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-baseos-rpms       273 k\n",
      " \u001b[1m\u001b[32mlibstdc++         \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-baseos-rpms       744 k\n",
      "Installing dependencies:\n",
      " \u001b[1m\u001b[32mlibstdc++-devel   \u001b[m x86_64    11.4.1-2.1.el9      ubi-9-appstream-rpms    2.4 M\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  2 Packages\n",
      "Upgrade  5 Packages\n",
      "\n",
      "Total download size: 59 M\n",
      "Downloading Packages:\n",
      "(1/7): libgcc-11.4.1-2.1.el9.x86_64.rpm         867 kB/s |  98 kB     00:00    \n",
      "(2/7): libgomp-11.4.1-2.1.el9.x86_64.rpm        8.8 MB/s | 273 kB     00:00    \n",
      "(3/7): libstdc++-11.4.1-2.1.el9.x86_64.rpm       16 MB/s | 744 kB     00:00    \n",
      "(4/7): libstdc++-devel-11.4.1-2.1.el9.x86_64.rp 4.2 MB/s | 2.4 MB     00:00    \n",
      "(5/7): cpp-11.4.1-2.1.el9.x86_64.rpm             16 MB/s |  11 MB     00:00    \n",
      "(6/7): gcc-c++-11.4.1-2.1.el9.x86_64.rpm         12 MB/s |  13 MB     00:01    \n",
      "(7/7): gcc-11.4.1-2.1.el9.x86_64.rpm             21 MB/s |  32 MB     00:01    \n",
      "--------------------------------------------------------------------------------\n",
      "Total                                            28 MB/s |  59 MB     00:02     \n",
      "Running transaction check\n",
      "Transaction check succeeded.\n",
      "Running transaction test\n",
      "Transaction test succeeded.\n",
      "Running transaction\n",
      "  Preparing        :                                                        1/1 \n",
      "  Upgrading        : libgcc-11.4.1-2.1.el9.x86_64                          1/12 \n",
      "  Running scriptlet: libgcc-11.4.1-2.1.el9.x86_64                          1/12 \n",
      "  Upgrading        : libstdc++-11.4.1-2.1.el9.x86_64                       2/12 \n",
      "  Installing       : libstdc++-devel-11.4.1-2.1.el9.x86_64                 3/12 \n",
      "  Upgrading        : cpp-11.4.1-2.1.el9.x86_64                             4/12 \n",
      "  Upgrading        : libgomp-11.4.1-2.1.el9.x86_64                         5/12 \n",
      "  Upgrading        : gcc-11.4.1-2.1.el9.x86_64                             6/12 \n",
      "  Installing       : gcc-c++-11.4.1-2.1.el9.x86_64                         7/12 \n",
      "  Cleanup          : gcc-11.3.1-4.3.el9.x86_64                             8/12 \n",
      "  Cleanup          : libstdc++-11.3.1-4.3.el9.x86_64                       9/12 \n",
      "  Cleanup          : libgcc-11.3.1-4.3.el9.x86_64                         10/12 \n",
      "  Running scriptlet: libgcc-11.3.1-4.3.el9.x86_64                         10/12 \n",
      "  Cleanup          : cpp-11.3.1-4.3.el9.x86_64                            11/12 \n",
      "  Cleanup          : libgomp-11.3.1-4.3.el9.x86_64                        12/12 \n",
      "  Running scriptlet: libgomp-11.3.1-4.3.el9.x86_64                        12/12 \n",
      "  Verifying        : gcc-c++-11.4.1-2.1.el9.x86_64                         1/12 \n",
      "  Verifying        : libstdc++-devel-11.4.1-2.1.el9.x86_64                 2/12 \n",
      "  Verifying        : libgcc-11.4.1-2.1.el9.x86_64                          3/12 \n",
      "  Verifying        : libgcc-11.3.1-4.3.el9.x86_64                          4/12 \n",
      "  Verifying        : libgomp-11.4.1-2.1.el9.x86_64                         5/12 \n",
      "  Verifying        : libgomp-11.3.1-4.3.el9.x86_64                         6/12 \n",
      "  Verifying        : libstdc++-11.4.1-2.1.el9.x86_64                       7/12 \n",
      "  Verifying        : libstdc++-11.3.1-4.3.el9.x86_64                       8/12 \n",
      "  Verifying        : cpp-11.4.1-2.1.el9.x86_64                             9/12 \n",
      "  Verifying        : cpp-11.3.1-4.3.el9.x86_64                            10/12 \n",
      "  Verifying        : gcc-11.4.1-2.1.el9.x86_64                            11/12 \n",
      "  Verifying        : gcc-11.3.1-4.3.el9.x86_64                            12/12 \n",
      "Installed products updated.\n",
      "\n",
      "Upgraded:\n",
      "  cpp-11.4.1-2.1.el9.x86_64               gcc-11.4.1-2.1.el9.x86_64            \n",
      "  libgcc-11.4.1-2.1.el9.x86_64            libgomp-11.4.1-2.1.el9.x86_64        \n",
      "  libstdc++-11.4.1-2.1.el9.x86_64        \n",
      "Installed:\n",
      "  gcc-c++-11.4.1-2.1.el9.x86_64      libstdc++-devel-11.4.1-2.1.el9.x86_64     \n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "!sudo dnf install gcc-c++ -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d58333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Subscription Management repositories.\n",
      "Unable to read consumer identity\n",
      "Subscription Manager is operating in container mode.\n",
      "\n",
      "This system is not registered with an entitlement server. You can use subscription-manager to register.\n",
      "\n",
      "Last metadata expiration check: 0:00:09 ago on Thu Dec 14 05:52:18 2023.\n",
      "Dependencies resolved.\n",
      "================================================================================\n",
      " Package            Arch     Version               Repository              Size\n",
      "================================================================================\n",
      "Installing:\n",
      " \u001b[1m\u001b[32mcmake             \u001b[m x86_64   3.20.2-9.el9_3        ubi-9-appstream-rpms   6.7 M\n",
      "Installing dependencies:\n",
      " \u001b[1m\u001b[32mcmake-data        \u001b[m noarch   3.20.2-9.el9_3        ubi-9-appstream-rpms   2.1 M\n",
      " \u001b[1m\u001b[32mcmake-filesystem  \u001b[m x86_64   3.20.2-9.el9_3        ubi-9-appstream-rpms    22 k\n",
      " \u001b[1m\u001b[32mcmake-rpm-macros  \u001b[m noarch   3.20.2-9.el9_3        ubi-9-appstream-rpms    12 k\n",
      " \u001b[1m\u001b[32mlibuv             \u001b[m x86_64   1:1.42.0-1.el9        ubi-9-appstream-rpms   153 k\n",
      " \u001b[1m\u001b[32mvim-filesystem    \u001b[m noarch   2:8.2.2637-20.el9_1   ubi-9-baseos-rpms       22 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  6 Packages\n",
      "\n",
      "Total download size: 9.1 M\n",
      "Installed size: 34 M\n",
      "Downloading Packages:\n",
      "(1/6): vim-filesystem-8.2.2637-20.el9_1.noarch. 246 kB/s |  22 kB     00:00    \n",
      "(2/6): libuv-1.42.0-1.el9.x86_64.rpm            362 kB/s | 153 kB     00:00    \n",
      "(3/6): cmake-data-3.20.2-9.el9_3.noarch.rpm     5.6 MB/s | 2.1 MB     00:00    \n",
      "(4/6): cmake-3.20.2-9.el9_3.x86_64.rpm          8.5 MB/s | 6.7 MB     00:00    \n",
      "(5/6): cmake-rpm-macros-3.20.2-9.el9_3.noarch.r  36 kB/s |  12 kB     00:00    \n",
      "(6/6): cmake-filesystem-3.20.2-9.el9_3.x86_64.r  58 kB/s |  22 kB     00:00    \n",
      "--------------------------------------------------------------------------------\n",
      "Total                                            11 MB/s | 9.1 MB     00:00     \n",
      "Running transaction check\n",
      "Transaction check succeeded.\n",
      "Running transaction test\n",
      "Transaction test succeeded.\n",
      "Running transaction\n",
      "  Preparing        :                                                        1/1 \n",
      "  Installing       : cmake-rpm-macros-3.20.2-9.el9_3.noarch                 1/6 \n",
      "  Installing       : cmake-filesystem-3.20.2-9.el9_3.x86_64                 2/6 \n",
      "  Installing       : libuv-1:1.42.0-1.el9.x86_64                            3/6 \n",
      "  Installing       : vim-filesystem-2:8.2.2637-20.el9_1.noarch              4/6 \n",
      "  Installing       : cmake-3.20.2-9.el9_3.x86_64                            5/6 \n",
      "  Installing       : cmake-data-3.20.2-9.el9_3.noarch                       6/6 \n",
      "  Running scriptlet: cmake-data-3.20.2-9.el9_3.noarch                       6/6 \n",
      "  Verifying        : vim-filesystem-2:8.2.2637-20.el9_1.noarch              1/6 \n",
      "  Verifying        : libuv-1:1.42.0-1.el9.x86_64                            2/6 \n",
      "  Verifying        : cmake-3.20.2-9.el9_3.x86_64                            3/6 \n",
      "  Verifying        : cmake-data-3.20.2-9.el9_3.noarch                       4/6 \n",
      "  Verifying        : cmake-filesystem-3.20.2-9.el9_3.x86_64                 5/6 \n",
      "  Verifying        : cmake-rpm-macros-3.20.2-9.el9_3.noarch                 6/6 \n",
      "Installed products updated.\n",
      "\n",
      "Installed:\n",
      "  cmake-3.20.2-9.el9_3.x86_64                                                   \n",
      "  cmake-data-3.20.2-9.el9_3.noarch                                              \n",
      "  cmake-filesystem-3.20.2-9.el9_3.x86_64                                        \n",
      "  cmake-rpm-macros-3.20.2-9.el9_3.noarch                                        \n",
      "  libuv-1:1.42.0-1.el9.x86_64                                                   \n",
      "  vim-filesystem-2:8.2.2637-20.el9_1.noarch                                     \n",
      "\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "!sudo dnf install cmake -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2fb0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 8.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-23.3.1\n"
     ]
    }
   ],
   "source": [
    "!sudo -H pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228fa786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/mosaic-ai/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mWriting to /home/mosaic-ai/.config/pip/pip.conf\r\n"
     ]
    }
   ],
   "source": [
    "!pip config unset global.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c49439ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.23.tar.gz (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.8/site-packages (from llama-cpp-python) (1.21.1)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.23-cp38-cp38-manylinux_2_34_x86_64.whl size=2038666 sha256=e619eecbe842990e5aac1962750ef587da933adfe99c253807cebcc9cf1b4c7d\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/95/31/5ed564e283361f552d495434685789c26cf14c29d7ec84b915\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, diskcache, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.1.1\n",
      "    Uninstalling typing_extensions-4.1.1:\n",
      "      Successfully uninstalled typing_extensions-4.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 3.2.4 requires jupyter-server~=1.4, but you have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.2.23 typing-extensions-4.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!sudo pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e84b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fc2c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"/data/mistral/query-to-mql/exp-10/nov-20/merged-model/ggml-model-q4_0/ggml-model-q4_0.gguf\",\n",
    "            n_threads=8,\n",
    "           n_ctx=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44bcdfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template_v1 = \"\"\"Given the context : {context} and date reference: {date_input}, the query: {user_query}, is converted into below shown structured output.\n",
    "[MQL]\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"{\n",
    "    \"MEASURE\": [{\"ENTITY\": \"Discount\", \"other names\": [\"discount\", \"discount rate\", \"discount value\", \"deduction\"]},\n",
    "                {\"ENTITY\": \"Purchase Vol\", \"other names\": [\"purchase\", \"purchase value\", \"purchase model\"]},\n",
    "                {\"ENTITY\": \"Quantity\", \"other names\": [\"quantity\", \"volume\"]},\n",
    "                {\"ENTITY\": \"Sales\", \"other names\": [\"sales\", \"sale\"]}],\n",
    "    \"DIMENSION\": [{\"ENTITY\": \"Sub-Category\", \"other names\": [\"sub-category\", \"sub category\", \"categories\", \"section\"]},\n",
    "                  {\"ENTITY\": \"Segment\", \"other names\": [\"segment\", \"segments\", \"units\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Parts\", \"other names\": [\"parts\", \"part\", \"section\", \"divisions\"]},\n",
    "                  {\"ENTITY\": \"Country\", \"other names\": [\"country\", \"countries\"]}],\n",
    "    \"FILTER\": [{\"ENTITY\": \"Consumer\", \"other names\": [\"consumers\", \"consumer\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"Phone\", \"other names\": [\"phone\", \"phones\", \"mobile phones\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Binder\", \"other names\": [\"binders\", \"binder\"], \"parent\": \"Sub-Category\"},\n",
    "               {\"ENTITY\": \"Corporate\", \"other names\": [\"corporates\", \"corporate\"], \"parent\": \"Segment\"},\n",
    "               {\"ENTITY\": \"India\", \"other names\": [\"india\"], \"parent\": \"Country\"},\n",
    "               {\"ENTITY\": \"Dubai\", \"other names\": [\"dubai\"], \"parent\": \"Country\"}],\n",
    "    \"DERIVED MEASURE\": [{\"ENTITY\": \"Ratio\",\n",
    "             \"other names\": [\"ratio\", \"share\", \"contribution\", \"percentage\", \"proportion\", \"contributing\"]},\n",
    "            {\"ENTITY\": \"Why\", \"other names\": [\"why\", \"cause of\", \"reason for\", \"diagnose\"]},\n",
    "            {\"ENTITY\": \"contribution_to_growth\", \"other names\": [\"contribution to growth\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"kda_transactional\", \"other names\": [\"kda\", \"key drivers\", \"key driver\", \"drivers\", \"driver\"]},\n",
    "            {\"ENTITY\": \"Growth Rate\", \"other names\": [\"growth rate\", \"growth\", \"grown\"]},\n",
    "            {\"ENTITY\": \"correlation\",\n",
    "             \"other names\": [\"associate\", \"associated\", \"association\", \"associations\", \"correlate\", \"correlated\",\n",
    "                             \"correlation\", \"correlations\", \"relate\", \"related\", \"relation\", \"relations\",\n",
    "                             \"relationship\",\n",
    "                             \"relationships\"]}\n",
    "            ],\n",
    "    \"DATE VARIABLE\": [{\"ENTITY\": \"Order Date\", \"other names\": [\"order date\", \"date\", \"trend\", \"time\", \"when\", \"mom\", \"yoy\"]}]\n",
    "    }\"\"\"\n",
    "\n",
    "\n",
    "date_input = {\n",
    "    \"start_date\": \"01/01/2020\",\n",
    "    \"end_date\": \"15/09/2023\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee1b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf20ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/mistral/query-to-mql/exp-10/training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec376dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57328737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a11d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424a941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:26, 146.40s/it]Llama.generate: prefix-match hit\n",
      "2it [03:33, 99.63s/it] Llama.generate: prefix-match hit\n",
      "3it [05:38, 111.11s/it]Llama.generate: prefix-match hit\n",
      "4it [07:39, 115.05s/it]Llama.generate: prefix-match hit\n",
      "5it [08:42, 96.56s/it] Llama.generate: prefix-match hit\n",
      "6it [10:45, 105.54s/it]Llama.generate: prefix-match hit\n",
      "7it [11:59, 94.98s/it] Llama.generate: prefix-match hit\n",
      "8it [12:49, 80.88s/it]Llama.generate: prefix-match hit\n",
      "9it [15:08, 98.97s/it]Llama.generate: prefix-match hit\n",
      "10it [16:22, 91.12s/it]Llama.generate: prefix-match hit\n",
      "11it [18:22, 100.03s/it]Llama.generate: prefix-match hit\n",
      "12it [20:25, 107.18s/it]Llama.generate: prefix-match hit\n",
      "13it [21:32, 94.76s/it] Llama.generate: prefix-match hit\n",
      "14it [22:27, 82.76s/it]Llama.generate: prefix-match hit\n",
      "15it [23:20, 73.81s/it]Llama.generate: prefix-match hit\n",
      "16it [25:23, 88.74s/it]Llama.generate: prefix-match hit\n",
      "17it [27:33, 101.13s/it]Llama.generate: prefix-match hit\n",
      "18it [30:07, 117.12s/it]Llama.generate: prefix-match hit\n",
      "19it [32:11, 119.03s/it]Llama.generate: prefix-match hit\n",
      "20it [35:39, 145.69s/it]Llama.generate: prefix-match hit\n",
      "21it [37:18, 131.73s/it]Llama.generate: prefix-match hit\n",
      "22it [38:21, 111.21s/it]Llama.generate: prefix-match hit\n",
      "23it [39:15, 93.95s/it] Llama.generate: prefix-match hit\n",
      "24it [40:29, 88.12s/it]Llama.generate: prefix-match hit\n",
      "25it [41:20, 76.90s/it]Llama.generate: prefix-match hit\n",
      "26it [42:15, 70.15s/it]Llama.generate: prefix-match hit\n",
      "27it [43:48, 77.10s/it]Llama.generate: prefix-match hit\n",
      "28it [46:24, 100.72s/it]Llama.generate: prefix-match hit\n",
      "29it [48:25, 106.93s/it]Llama.generate: prefix-match hit\n",
      "30it [50:28, 111.62s/it]Llama.generate: prefix-match hit\n",
      "31it [51:24, 95.10s/it] Llama.generate: prefix-match hit\n",
      "32it [52:29, 85.95s/it]Llama.generate: prefix-match hit\n",
      "33it [53:51, 84.71s/it]Llama.generate: prefix-match hit\n",
      "34it [55:09, 82.68s/it]Llama.generate: prefix-match hit\n",
      "35it [56:20, 79.43s/it]Llama.generate: prefix-match hit\n",
      "36it [57:10, 70.33s/it]Llama.generate: prefix-match hit\n",
      "37it [58:04, 65.49s/it]Llama.generate: prefix-match hit\n",
      "38it [59:07, 64.72s/it]Llama.generate: prefix-match hit\n",
      "39it [1:00:23, 68.31s/it]Llama.generate: prefix-match hit\n",
      "40it [1:02:24, 83.96s/it]Llama.generate: prefix-match hit\n",
      "41it [1:04:22, 94.35s/it]Llama.generate: prefix-match hit\n",
      "42it [1:06:22, 101.82s/it]Llama.generate: prefix-match hit\n",
      "43it [1:07:50, 97.72s/it] Llama.generate: prefix-match hit\n",
      "44it [1:09:49, 104.25s/it]Llama.generate: prefix-match hit\n",
      "45it [1:10:50, 91.06s/it] Llama.generate: prefix-match hit\n",
      "46it [1:11:54, 83.14s/it]Llama.generate: prefix-match hit\n",
      "47it [1:13:52, 93.61s/it]Llama.generate: prefix-match hit\n",
      "48it [1:15:51, 101.09s/it]Llama.generate: prefix-match hit\n",
      "49it [1:17:48, 105.79s/it]Llama.generate: prefix-match hit\n",
      "50it [1:19:10, 98.85s/it] Llama.generate: prefix-match hit\n",
      "51it [1:21:10, 105.17s/it]Llama.generate: prefix-match hit\n",
      "52it [1:22:27, 96.66s/it] Llama.generate: prefix-match hit\n",
      "53it [1:23:40, 89.60s/it]Llama.generate: prefix-match hit\n",
      "54it [1:24:41, 80.91s/it]Llama.generate: prefix-match hit\n",
      "55it [1:25:41, 74.83s/it]Llama.generate: prefix-match hit\n",
      "56it [1:26:48, 72.48s/it]Llama.generate: prefix-match hit\n",
      "57it [1:28:48, 86.72s/it]Llama.generate: prefix-match hit\n",
      "58it [1:29:53, 80.13s/it]Llama.generate: prefix-match hit\n",
      "59it [1:31:03, 77.15s/it]Llama.generate: prefix-match hit\n",
      "60it [1:33:04, 90.09s/it]Llama.generate: prefix-match hit\n",
      "61it [1:33:58, 79.35s/it]Llama.generate: prefix-match hit\n",
      "62it [1:35:05, 75.83s/it]Llama.generate: prefix-match hit\n",
      "63it [1:36:21, 75.77s/it]Llama.generate: prefix-match hit\n",
      "64it [1:37:58, 81.97s/it]Llama.generate: prefix-match hit\n",
      "65it [1:38:56, 74.83s/it]Llama.generate: prefix-match hit\n",
      "66it [1:40:04, 72.98s/it]Llama.generate: prefix-match hit\n",
      "67it [1:41:04, 68.83s/it]Llama.generate: prefix-match hit\n",
      "68it [1:42:07, 67.31s/it]Llama.generate: prefix-match hit\n",
      "69it [1:43:11, 66.38s/it]Llama.generate: prefix-match hit\n",
      "70it [1:44:13, 65.01s/it]Llama.generate: prefix-match hit\n",
      "71it [1:45:25, 66.99s/it]Llama.generate: prefix-match hit\n",
      "72it [1:46:23, 64.40s/it]Llama.generate: prefix-match hit\n",
      "73it [1:47:25, 63.58s/it]Llama.generate: prefix-match hit\n",
      "74it [1:48:25, 62.65s/it]Llama.generate: prefix-match hit\n",
      "75it [1:50:27, 80.25s/it]Llama.generate: prefix-match hit\n",
      "76it [1:52:23, 91.17s/it]Llama.generate: prefix-match hit\n",
      "77it [1:53:19, 80.47s/it]Llama.generate: prefix-match hit\n",
      "78it [1:54:25, 76.27s/it]Llama.generate: prefix-match hit\n",
      "79it [1:55:35, 74.15s/it]Llama.generate: prefix-match hit\n",
      "80it [1:56:38, 70.88s/it]Llama.generate: prefix-match hit\n",
      "81it [1:57:45, 69.67s/it]Llama.generate: prefix-match hit\n",
      "82it [1:58:42, 66.00s/it]Llama.generate: prefix-match hit\n",
      "83it [1:59:41, 63.96s/it]Llama.generate: prefix-match hit\n",
      "84it [2:00:35, 60.90s/it]Llama.generate: prefix-match hit\n",
      "85it [2:01:35, 60.55s/it]Llama.generate: prefix-match hit\n",
      "86it [2:02:38, 61.41s/it]Llama.generate: prefix-match hit\n",
      "87it [2:03:40, 61.46s/it]Llama.generate: prefix-match hit\n",
      "88it [2:04:55, 65.68s/it]Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "predicted_mql = {}\n",
    "\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    user_query = row['Query']\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)\n",
    "    output = llm(inp, # Prompt\n",
    "                 max_tokens=1700,\n",
    "                 echo=True,\n",
    "                 temperature=0)\n",
    "    predicted_mql[user_query]=output['choices'][0]['text'].split('[MQL]\\n')[1].split('\\n[/MQL]')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(predicted_mql.items(), columns=['query', 'predicted_mql'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"predicted_mql_llama-cpp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import writer class from csv module\n",
    "from csv import writer\n",
    "\n",
    "# List that we want to add as a new row\n",
    "List = [6, 'William', 5532, 1, 'UAE']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a66ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_row(row: List)->None:\n",
    "    # Open our existing CSV file in append mode\n",
    "    # Create a file object for this file\n",
    "    with open('predicted_mql_llama-cpp.csv', 'a') as f_object:\n",
    "\n",
    "        # Pass this file object to csv.writer()\n",
    "        # and get a writer object\n",
    "        writer_object = writer(f_object)\n",
    "\n",
    "        # Pass the list as an argument into\n",
    "        # the writerow()\n",
    "        writer_object.writerow(row)\n",
    "\n",
    "        # Close the file object\n",
    "        f_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289900c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0012449",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = 'sales in nov 2020'\n",
    "\n",
    "inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf56329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efdc371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken :  56.41283392906189\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = llm(\n",
    "    inp, # Prompt\n",
    "    max_tokens=1000,\n",
    "    echo=True,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"time taken : \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2486b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f32f5d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE VARIABLE': {'nov 2020': [{'CONVERTED TIME ELEMENT': 'november 2020', 'DATE RANGE': '2020/11/01 - 2020/11/30', 'ENTITY': 'Order Date'}]}, 'MEASURE': {'sales': [{'ENTITY': 'Sales'}]}}\n"
     ]
    }
   ],
   "source": [
    "print(output['choices'][0]['text'].split('[MQL]\\n')[1].split('\\n[/MQL]')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc390290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69839631",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "1. Install c++ compile\n",
    "    sudo dnf install gcc-c++ -y\n",
    "2. Install cmake\n",
    "    sudo dnf install cmake -y\n",
    "3. clone and build llama.cpp from - https://github.com/ggerganov/llama.cpp\n",
    "\n",
    "4. Install llama.cpp python client\n",
    "    a. pip install --upgrade pip\n",
    "    b. remove any content from pip.conf/pip.ini as it creates issue during building wheel for llama-cpp-python.\n",
    "    c. pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef6c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on un-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f5d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo -H pip install -Uq transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae80b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaabbba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc03da3ad69d45a1a9bd70c697bea024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unq_model = AutoModelForCausalLM.from_pretrained(\"/data/mistral/query-to-mql/exp-10/nov-20/merged-model\",\n",
    "                                                 torch_dtype= torch.bfloat16, device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a335062",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/mistral/query-to-mql/exp-10/nov-20/merged-model\",\n",
    "                                          trust_remote_code=True,\n",
    "                                          # add_eos_token=True,\n",
    "                                          use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4079ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_template_query_v1(user_query):\n",
    "    inp = query_template_v1.format(context=context,\n",
    "                                   user_query=user_query,\n",
    "                                  date_input=date_input)\n",
    "    _inputs = tokenizer.encode(inp, return_tensors=\"pt\")\n",
    "    print(\"generating ouput\")\n",
    "    outputs = unq_model.generate(input_ids=_inputs, max_length= 500, pad_token_id=tokenizer.eos_token_id)\n",
    "    output = tokenizer.decode(outputs[0])\n",
    "    return output\n",
    "#     output_new = output.split('[MQL]\\n')[1]\n",
    "#     return output_new.split('\\n[/MQL]')[0], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc3b198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ouput\n",
      "time taken:  301.7619378566742\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "user_query = 'sales in nov 2020'\n",
    "start = time.time()\n",
    "output = predict_template_query_v1(user_query)\n",
    "print(\"time taken: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "46 -> [0.1,0.3,0,000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
